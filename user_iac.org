# Time-stamp: <2023-02-17 22:28:01 angelv> 

#+TITLE:   HTCondor IAC User's Manual
#+AUTHOR:  √Ångel de Vicente
#+EMAIL:   angel.de.vicente@iac.es

#+OPTIONS:   H:6 num:6 toc:4 author:t email:t title:t

#+LATEX_CLASS_OPTIONS: [a4paper,10pt]
#+LaTeX_HEADER: \usepackage[left=2cm, right=2cm, top=1.5cm, bottom=2cm]{geometry}

# To be able to create boxes around text. From
# https://emacs.stackexchange.com/questions/22092/how-to-place-a-box-around-a-piece-of-text-in-org-mode

#+LATEX_HEADER_EXTRA:  \usepackage{mdframed}
#+LATEX_HEADER_EXTRA: \BeforeBeginEnvironment{minted}{\begin{mdframed}}
#+LATEX_HEADER_EXTRA: \AfterEndEnvironment{minted}{\end{mdframed}}

#+latex: \small

* Users' documentation for the IAC HTCondor Pool

** An Overview of the HTCondor System

*** On High-Throughput Computing

For many scientists, the quality of their research is heavily dependent on
computing throughput. It is not uncommon to find problems that require weeks or
months of computation to solve. Scientists involved in this type of research
need a computing environment that delivers large amounts of computational power
over a long period of time. Such an environment is called a High-Throughput
Computing (HTC) environment. In contrast, High-Performance Computing (HPC)
environments deliver a tremendous amount of power over a short period of time.
HPC environments are often measured in terms of FLoating point OPerations per
Second (FLOPS). Many scientists today do not care about FLOPS; their problems
are on a much larger scale. These people are concerned with floating point
operations per month or per year. They are interested in how many jobs they can
complete over a long period of time.

A key to high throughput is the efficient use of available resources. Years
ago, the scientific community relied on large mainframe computers to do
computational work. A large number of individuals and groups would have to pool
their financial resources to afford such a computer. It was not uncommon to
find just one such machine at even the largest research institutions.
Scientists would wait their turn for mainframe time, and they would be allocated
a specific amount of time. Scientists limited the size and scope of their
problems to ensure completion. While this environment was inconvenient for the
users, it was very efficient, because the mainframe was busy nearly all the
time.

As computers became smaller, faster and less expensive, scientists moved
away from mainframes and purchased personal computers or workstations. An
individual or a small group could afford a computing resource that was available
whenever they wanted it. The resource might be slower than the mainframe, but
it provided exclusive access. Recently, instead of one large computer for an
institution, there are many workstations. Each workstation is owned by its
user. This is distributed ownership. While distributed ownership is more
convenient for the users, it is also less efficient. Machines sit idle for long
periods of time, often while their users are busy doing other things.
*Condor takes this wasted computation time and puts it to good use.* The
situation today matches that of yesterday, with the addition of clusters in the
list of resources. These machines are often dedicated to tasks. Condor manages
a cluster's effort efficiently, as well as handling other resources.

To achieve the highest throughput, Condor provides two important functions.
First, it makes available resources more efficient by putting idle machines to
work. Second, it expands the resources available to users, by functioning well
in an environment of distributed ownership.

*** Why use Condor?

Condor takes advantage of computing resources that would otherwise be wasted
and puts them to good use. Condor streamlines the scientist's tasks by allowing
the submission of many jobs at the same time. In this way, tremendous amounts
of computation can be done with very little intervention from the user.
Moreover, Condor allows users to take advantage of idle machines that they would
not otherwise have access to.

Condor provides other important features to its users. Source code does not
have to be modified in any way to take advantage of these benefits. Code that
can be re-linked with the Condor libraries gains two further abilities: the jobs
can produce checkpoints and they can perform remote system calls.

A checkpoint is the complete set of information that comprises a program's
state. Given a checkpoint, a program can use the checkpoint to resume
execution. For long-running computations, the ability to produce and use
checkpoints can save days, or even weeks of accumulated computation time. If a
machine crashes, or must be rebooted for an administrative task, a checkpoint
preserves computation already completed. Condor makes checkpoints of jobs,
doing so periodically, or when the machine on which a job is executing will
shortly become unavailable. In this way, the job can be continued on another
machine (of the same platform); this is known as process migration.

A user submits a job to Condor. The job is executed on a remote machine
within the pool of machines available to Condor. Minimal impact on and the
security of the remote machine are preserved by Condor through remote system
calls. When the job does a system call, for example to do an input or output
function, the data is maintained on the machine where the job was submitted.
The data is not on the remote machine, where it could be an imposition.

By linking in a set of Condor libraries, system calls are caught and
performed by Condor, instead of by the remote machine's operating system.
Condor sends the system call from the remote machine to the machine where the
jobs was submitted. The system call's function executes, and Condor sends the
result back to the remote machine.

This implementation has the added benefit that a user submitting jobs to
Condor does not need an account on the remote machine.

*** Small Businesses Like Condor


Condor starts with the assumption that you have relatively long running tasks
that do not require user interaction. While this is not common in small
business environments, it does occur. To take examples from businesses that we
know are using Condor, tasks involve rendering 3D scenes for a movie, performing
a nightly build and regression test on software under development, simulating
and analyzing stock market behavior, and simulating the effects of various
political decisions. Modern video codecs often take a long time to encode, and
any business generating video files could use Condor to manage the process. A
small biotechnology company might want to use Condor to manage the long running
pattern searches over the human genome. A small engineering company might have
similar needs with long running simulations of stress on a building, wind tunnel
simulations for cars, or circuit simulations for new electronics devices.

Condor helps those businesses with long running tasks. Such businesses may be
using some sort of batch system already, or operate by starting the program each
evening, hoping that it finishes before they return in the morning. This is the
sort of situation in which Condor excels. Condor also saves time and effort
when the time it takes a user to get jobs executing is longer than a few
moments, or when a large number of jobs (of any size) must be started.

Condor allows almost any application that can run without user interaction to be
managed. This is different from systems like SETI@Home and ProteinFolding@Home.
These programs are custom written. Most small companies will not have the
resources to custom build an opportunistic batch processing system.
Fortunately, Condor provides a general solution.

Condor can be useful on a range of network sizes, from small to large. On a
single machine, Condor can act as a monitoring tool that pauses the job when the
user uses the machine for other purposes, and it restarts the job if the machine
reboots. On a small dedicated cluster, Condor functions well as a cluster
submission tool. If you have long running jobs but can not afford to purchase
dedicated machines to run the jobs, you can use Condor's opportunistic behavior
to scavenge cycles from desktop machines when their users are not using the
machines (for example, in the evening or during lunch).

In a typical business these desktop machines are unused for twelve or more hours
per day. This processing time is available at no extra cost under Condor. A
long running job expected to require the exclusive use of a workstation for two
days may be able to produce results overnight.

Condor's functionality called DAGMan, manages the submission of a large number
of jobs with simple or complex dependencies on each other. A simple example is
that job A and B must complete before job C can start. A rendering example of
this would be that job A renders a 3D special effect, job B renders the
background, and job C superimposes the special effect onto the background.
Condor DAGMan can also be used to run a series of jobs (linearly).

If the small business is using Globus grid resources to gain access to more
computing power than it has available in house, Condor-G provides reliability
and job management to their jobs. Or, with Condor glidein, remote Globus grid
resources can transparently become part of a virtual Condor cluster.

*** Everyone Benefits

As more machines join a Condor pools, the quantity of computational
resources available to the users grows. While Condor can efficiently manage the
queuing of jobs where the pool consists of a single machine, Condor works
extremely well when the pool contains hundreds of machines.

A contributor to Condor's success is its ClassAd mechanism. Jobs want to
find machines upon which they can execute. A job will require a specific
platform on which to execute. Machines have specific resources available, such
as the platform and the amount of available memory. A separate ClassAd is
produced for each job and machine, listing all attributes. Condor acts as a
matchmaker between the jobs and the machines by pairing the ClassAd of a job
with the ClassAd of a machine.

This mechanism is much more flexible than the simple example of matching the
platforms of jobs with those of machines. A job may also prefer to execute on a
machine with better floating point facilities, or it may prefer to execute on a
specific set of machines. These preferences are also expressed in the ClassAd.
Further, a machine owner has great control over which jobs are executed under
what circumstances on the machine. The owner writes a configuration file that
specifies both requirements and preferences for the jobs. The owner may allow
jobs to execute when the machine is idle (identified by low load and no keyboard
activity), or allow jobs only on Tuesday evenings. There may be a requirement
that only jobs from a specific group of users may execute. Alternatively, any
of these may be expressed as a preference, for example where the machine prefers
the jobs of a select group, but will accept the jobs of others if there are no
jobs from the select group.

In this way, machine owners have extensive control over their machine. And,
with this control, more machine owners are happy to participate by joining a
Condor pool. 


** Condor Code of Conduct

Condor is a terrific tool for performing parametric studies and other type of
jobs that can run simultaneously and independently in a number of
machines. Nevertheless, under certain circumstances, if you are not careful you
can bring the network to a crawl. To avoid these situations, please stick to
this simple code of conduct:

+ Submit jobs only from your machine or from a machine whose owner you have
  contacted and is aware of the extra load that you will put on it. No
  submission from public machines, sorry! (For each Condor running job, there is
  a process running in the submitting machine, plus lots of network connections,
  so the submitting machine pays a big toll, which is not fair to pass it to
  someone else unawares).

+ If you plan to run I/O intensive code (i.e. code that reads or writes to disk
  very large files, or small ones but very often), get in touch with me
  first. Depending on how I/O intensive your code is, it might not be worth it
  to use Condor, or I might be able to offer you counsel on how to best do
  it. Hopefully your Condor submission will perform faster if we take this into
  account.

+ Test your submission. Don't go nuts and submit a 10000 jobs submission without
  first making sure the whole thing will work with a smaller subset. Start
  small, verify that things are going OK, check the logs to see that the jobs
  can access all the necessary files, etc. and only when you are satisfied that
  things are working go for the big submission.

Please stick to these basic rules so that we can avoid Condor affecting other
users' work.




** Manual del usuario de Condor (Adri√°n Santos Marrero)

*** ¬øQu√© es Condor?

Condor es un proyecto de la Universidad de Wisconsin-Madison (UW-Madison). Est√°
ideado para aprovechar al m√°ximo la capacidad computacional de una red de
ordenadores.  Normalmente s√≥lo disponemos de la potencia del ordenador que
estamos usando para ejecutar nuestros trabajos, y si, por ejemplo, tuvi√©ramos
que lanzar 100 veces un mismo programa con distinta entrada, tendr√≠amos que
hacerlo secuencialmente con la consecuente p√©rdida de tiempo. Condor nos permite
ejecutar nuestro trabajo en tantas m√°quinas como haya disponibles, por lo que,
en el mejor de los casos, nuestro trabajo finalizar√° en el tiempo que tarda en
ejecutarse el m√°s lento de nuestros procesos.

Condor pone a nuestra disposici√≥n toda la capacidad de c√°lculo desaprovechada en
nuestra red, de esta manera, los recursos disponibles se incrementan
considerablemente.

Condor nos ser√° √∫til siempre que necesitemos ejecutar un trabajo intenso, tanto
computacionalmente como en el tiempo. Al aprovechar solamente recursos ociosos
no influye en el uso cotidiano de los ordenadores (ver secci√≥n "¬øC√≥mo
funciona?").

Adem√°s, nos permite:
+ Conocer el estado de nuestros trabajos en cada momento
+ Implementar nuestras propias pol√≠ticas de orden de ejecuci√≥n
+ Mantener un registro de la actividad de nuestros trabajos
+ A√±adir tolerancia a fallos a nuestros trabajos

*** ¬øC√≥mo funciona?

B√°sicamente, enviamos un trabajo a Condor, este lo pone en una cola, lo ejecuta y 
finalmente nos avisa del resultado.

Vamos a verlo un poco m√°s de cerca para intentar comprender como funciona:

+ Normalmente usaremos Condor porque queremos ejecutar repetidas veces un
  programa (posiblemente con diferente entrada) o porque se requiere mucho
  tiempo para su finalizaci√≥n y, mientras tanto, necesitamos seguir usando
  nuestra m√°quina.
+ Inicialmente nuestro trabajo no necesita ninguna modificaci√≥n para ser enviado
  a Condor. Sin embargo, tenemos que escribir un archivo de descripci√≥n del
  env√≠o (ver secci√≥n \ref{sec::submit_file}). 
+ Una vez enviado a Condor, podemos seguirle la pista a nuestro trabajo con el
  comando {\tt condor\_q} (ver secci√≥n \ref{sec::condor_q}) o mediante un
  registro de actividad (fichero {\tt Log}). 
+ Condor realiza peri√≥dicamente b√∫squeda de trabajos nuevos e intenta casarlos
  con recursos disponibles. Si no hay disponibles, el trabajo se quedar√° a la
  espera del pr√≥ximo ciclo. 
+ Una vez Condor ha encontrado una m√°quina capaz de ejecutar el trabajo
  pendiente, lo env√≠a y empieza la ejecuci√≥n. Pueden ocurrir varias cosas
  mientras se est√° ejecutando un trabajo:
  + Lo m√°s deseable ser√≠a que finalizara con √©xito. Si esto ocurriera se
    enviar√≠an las salidas del trabajo a donde haya especificado el usuario y se
    mandar√≠a un correo electr√≥nico al mismo con un resumen de lo ocurrido. 
  + En el caso de que la m√°quina deje de estar utilizable (porque ha vuelto el
    usuario o alguno de los motivos explicados m√°s abajo) el proceso deber√°
    abandonarla. Si se estaba ejecutando en el universo ``standard'', se
    realizar√≠a una imagen del estado actual del proceso ({\em checkpoint}) (ver
    sec.  \ref{sec::universos}) y se finalizar√≠a su ejecuci√≥n. En el resto de
    universos, simplemente se instar√° al trabajo a que finalize su ejecuci√≥n
    (para ello se le env√≠a la se√±al SIGTERM y si, pasado un cierto tiempo, no
    muere se le env√≠a SIGKILL). 
  + Otra posibilidad es que el propietario del trabajo haya decidido borrarlo
    de Condor (ver secci√≥n \ref{sec::condor_rm}) con lo que finalizar√° su
    ejecuci√≥n inmediatamente. 

A la hora de enviar nuestro trabajo hemos de tomar algunas precauciones:
+ Tenemos que elegir un ``universo'' adecuado: en la mayor√≠a de los casos nos
  bastar√° con el universo ``vanilla'' (ver sec. \ref{sec::universos}). 
+ Nuestro trabajo ha de ser capaz de ejecutarse en un sistema de procesamiento
  por lotes: 
  + Ha de ser capaz de ejecutarse en ``background''. No ha de solicitar
    informaci√≥n interactivamente.
  + Puede usar STDIN, STDOUT y STDERR, pero estos ser√°n archivos en vez de los
    perif√©ricos habituales (teclado y pantalla). 
  + Ha de organizar sus archivos de datos. Por ejemplo, separados por ejecuciones.

Notar que Condor no influye en el uso cotidiano de nuestros ordenadores, ya que solo 
utilizar√° m√°quinas ociosas, o lo que es lo mismo, las que cumplan los siguientes
puntos: 
+ No se est√° usando el rat√≥n o teclado
+ No se est√° usando la m√°quina remotamente
+ No se est√° usando para ejecutar ning√∫n otro trabajo.

*** ¬øC√≥mo lo uso?

Condor est√° compuesto de varias aplicaciones que nos permiten:
+ Enviar trabajos a Condor: {\em condor\_submit}.
+ Controlar el estado de nuestros trabajos: {\em condor\_q}.
+ Borrar un trabajo: {\em condor\_rm}.
+ Obtener informaci√≥n del estado de Condor: {\em condor\_status}.

**** Enviando trabajos. {\em condor\_submit}

Para realizar el env√≠o tenemos que especificar algunas opciones para que Condor
sea capaz de manejar adecuadamente nuestro trabajo. Estas opciones incluyen qu√©
comando se va a ejecutar, cuantas veces y con qu√© entrada, donde ir√° la salida
de cada comando, requisitos de la m√°quina donde se ha de ejecutar, etc. Esta
informaci√≥n se especifica en un fichero de texto que llamaremos fichero de
descripci√≥n del env√≠o. La sintaxis a seguir la veremos a continuaci√≥n.

***** Fichero de descripci√≥n del env√≠o

Este archivo ser√° la entrada al comando {\em condor\_submit}. Un ejemplo de
fichero de env√≠o se puede ver en el siguiente ejemplo:

#+begin_example
############################
#
# foo.submit
# 
# Ejemplo 1: Archivo simple de descripci√≥n del env√≠o.
#
############################

Executable   = foo
Universe     = vanilla
input        = test.data
output       = foo.out
error        = foo.err
Log          = foo.log
Queue
#+end_example

Una vez guardado este fichero, le indicamos a Condor que lo ejecute de la
siguiente manera: 

#+begin_example
[adrians@trevina ~]$ condor_submit foo.submit
Submitting job(s).
Logging submit event(s).
1 job(s) submitted to cluster 3.
#+end_example

Veamos con m√°s detalle el contenido del archivo:

+ *Executable*: Especificamos la ruta y el nombre del archivo ejecutable. En el
  ejemplo solo se ha especificado el nombre, por lo que se espera que {\tt foo} y {\tt foo.submit} est√©n en el mismo directorio.
+ *Universe*: Elegimos un universo, por defecto se usar√° el universo
  ``vanilla''. Ver secci√≥n \ref{sec::universos}.} 
+ *input*: Archivo desde donde se leer√° la entrada por defecto (stdin). Si no se
  especifica, se utilizar√° el archivo {\tt /dev/null}. 
+ *output*: Archivo donde se escribir√° la salida del comando (stdout). Si no se especifica, se utilizar√° el archivo {\tt /dev/null}.
+ *error*: Archivo donde se escribir√° la salida de error del comando
  (stderr). Si no se especifica, se utilizar√° el archivo {\tt /dev/null}.
+ *Log*: Archivo donde Condor almacenar√° un hist√≥rico de lo que le ha ocurrido a
  nuestro trabajo e informaci√≥n como su c√≥digo de salida, errores relacionados con Condor, etc.
+ *Queue*: Indica que Condor va a ejecutar una vez este trabajo, podemos
  especificar un n√∫mero (por ejemplo {\tt Queue 10} o escribir varias veces {\tt
  Queue} con lo que se ejecutar√° tantas veces como hayamos escrito). Podemos
  especificar opciones para cada ejecuci√≥n, por ejemplo: podemos tener un fichero de entrada ({\tt input}) para cada ejecuci√≥n de nuestro trabajo.

Veamos ahora otro ejemplo, esta vez un poco m√°s complicado:

#+begin_example
############################
#
# complex.submit
# 
# Ejemplo 2: Archivo de descripci√≥n del env√≠o usando 
# Requirements y Rank.
#
############################

Executable   = complex
Universe     = vanilla
Requirements = Memory >= 64 && OpSys == "Linux" && Arch == "INTEL"
Rank         = Memory
input        = data.$(Process)
output       = out.$(Process)
error        = err.$(Process)
Log          = complex.log
Queue 10
#+end_example

En este ejemplo introducimos algunas opciones nuevas:
\begin{description}
	\item[Requirements:]{Especificamos los requisitos que se han de cumplir para que nuestro
trabajo se ejecute. En el ejemplo obligamos a que la m√°quina candidata tenga un procesador INTEL
o compatible, est√© ejecutando Linux y, adem√°s, no permitimos que tenga menos de 64MB de memoria RAM.
%Notar que Condor siempre completa estas expresiones y, por ejemplo, obliga a que nuestros trabajos se
%ejecuten en la misma arquitectura y sistema operativo que desde el que se realiz√≥ el env√≠o (siempre y 
%cuando no especifiquemos lo contrario).
En el caso de que no especifiquemos expl√≠citamente los requisitos sobre
arquitectura y sistema operativo, Condor los crear√° autom√°ticamente para que
nuestros trabajos se ejecuten en m√°quinas con la misma arquitectura y el mismo
sistema operativo que la m√°quina desde donde se envi√≥ el trabajo.
Para ver los requisitos finales de nuestro trabajo (una vez 
enviado a Condor) podemos ejecutar {\tt condor\_q -l}, este comando nos mostrar√° informaci√≥n detallada
de cada trabajo enviado.}
	\item[Rank:]{Define un valor num√©rico que expresa preferencia, es decir, dadas todas las m√°quinas
candidatas a ejecutar nuestro trabajo, Condor eval√∫a esta expresi√≥n en cada una
de ellas y elegir√° aquellas donde su valor sea mayor. En el ejemplo, preferimos
aquellas m√°quinas que tengan mayor cantidad de memoria RAM.}
\end{description}
Para obtener m√°s informaci√≥n acerca del uso de {\tt Requirements} y {\tt Rank} vea la \htmladdnormallink
{secci√≥n 2.5.2}{http://goya/inves/SINFIN/Condor/v6.6/2\_5Submitting\_Job.html\#SECTION00352000000000000000}
del manual de Condor.

En el ejemplo 2 tambi√©n hemos usado unos nombres de archivo un tanto especiales
en las opciones {\tt input}, {\tt output} y {\tt error}. El uso de la cadena
``\$(Process)'' implica que all√≠ donde aparezca ser√° sustituido por el n√∫mero
del trabajo que se va a ejecutar, es decir, en el ejemplo se crean 10 trabajos
({\tt Queue 10}) y cada uno de ellos tendr√° como entrada el archivo data.0, data.1,
\ldots~dependiendo de que n√∫mero de trabajo sea. Lo mismo ocurrir√° con los
archivos de salida ({\tt output}) y salida de error ({\tt error}).

\subsubsection{Universos}
\label{sec::universos}

Para Condor, un ``universo'' define un conjunto de caracter√≠sticas que marcar√°n
el entorno de ejecuci√≥n de nuestro trabajo. Por ejemplo, para trabajos en Java
existe un universo ``Java''. Este, por ejemplo, permitir√° capturar las excepciones
de la m√°quina virtual de Java o solo ejecutar√° los trabajos en m√°quinas con la
m√°quina virtual disponible.

B√°sicamente podemos elegir entre tres universos:
\begin{description}
	\item[vanilla] Es el universo por defecto y, adem√°s, es el menos restrictivo con
	los trabajos que se pueden enviar (acepta cualquier programa escrito en cualquier 
	lenguaje). La parte negativa es que no permite ``checkpointing'' o llamadas al sistema
	remotas (ver universo ``standard'' a continuaci√≥n).
	\item[standard] Este universo soporta ``checkpointing'' y llamadas al sistema remotas.
	Hacer ``checkpointing'' de un programa significa guardar en disco su estado
	actual de ejecuci√≥n antes de parar el proceso. Gracias al ``checkpointing'', un
	programa se puede parar (guard√°ndose su estado en un fichero), y m√°s adelante se
	puede volver a ejecutar desde el punto exacto en que se abort√≥. Para que un
	programa pueda ser enviado a este universo ha de estar enlazado con las
	librer√≠as de Condor (compilado usando {\em condor\_compile}). Presenta algunas
	restricciones en los trabajos que se pueden enviar.
	\item[java] Este universo est√° destinado para el env√≠o de trabajos escritos en Java.
\end{description}

Para informaci√≥n m√°s detallada acerca de cada universo puede visitar la 
\htmladdnormallink{secci√≥n 2.4.1 del manual}{http://goya/inves/SINFIN/Condor/v6.6/2\_4Road\_map\_Running.html\#SECTION00341000000000000000}.

\subsubsection{Sobre el acceso a los ficheros}
	El √∫nico universo que dispone de un sistema de llamadas al sistema remotas es el ``standard'', 
debido a esto, cuando use otro universo (por ejemplo el ``vanilla'') aseg√∫rese de que los archivos de entrada
y salida de sus trabajos se escriban o lean en directorios compartidos por NFS (es decir, visibles desde
todas las m√°quinas). Un buen ejemplo es su directorio home ({\tt /home/{\em user}/\ldots}) ya que desde cualquier 
m√°quina se puede acceder a √©l. Un ejemplo de un directorio no compartido ser√≠a {\tt /tmp/}, si crea un directorio 
{\tt /tmp/my\_condor\_job/}, este solo ser√° visible desde su m√°quina, por lo que cuando su trabajo se empiece a ejecutar
en otra m√°quina y vaya a abrir un archivo en ese directorio se encontrar√° que no existe y no podr√° continuar (estos
errores aparecer√°n en el {\tt Log} del trabajo).

\subsection{Estado de los trabajos enviados. {\em condor\_q}}
\label{sec::condor_q}

Podemos obtener informaci√≥n acerca de nuestros trabajos con el comando {\em condor\_q}:

\begin{verbatim}
[adrians@trevina ~]$ condor_submit myjob.submit
Submitting job(s).
Logging submit event(s).
1 job(s) submitted to cluster 1.

[adrians@trevina ~]$ condor_q


-- Submitter: trevina.iac.es : <161.72.81.178:1085> : trevina.iac.es
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD
   1.0   adrians         7/13 12:37   0+00:00:00 I  0   0.0  myprog Example.1.0

1 jobs; 1 idle, 0 running, 0 held
\end{verbatim}

Por defecto, este comando nos mostrar√° informaci√≥n de los trabajos que hemos
enviado desde la m√°quina donde se ejecuta, en el ejemplo ser√≠a ``trevina''.
La informaci√≥n que aparece en la salida ser√≠a:
\begin{itemize}
	+ El {\tt ID} es el identificador del trabajo y est√° formado por dos n√∫meros:
	\begin{itemize}
		+ El n√∫mero antes del punto representa el ``cluster''. Un ``cluster'' es
			el conjunto de trabajos creado en un env√≠o. Podemos ver un ejemplo en la salida
			del comando ``condor\_submit''.
		+ El n√∫mero despu√©s del punto representa el trabajo dentro del cluster,
			como en el ejemplo solo creamos uno, ser√° el trabajo 0. Trabajos
			sucesivos en el mismo cluster se nombrar√≠an como 1.1, 1.2, \ldots.
	\end{itemize}
	+ El usuario que env√≠o los trabajos.
	+ La fecha del env√≠o.
	+ El tiempo de ejecuci√≥n, en el formato: D√≠as+HH:MM:SS.
	+ El estado actual del trabajo. Algunos valores posibles son:
		\begin{description}
 			\item[I:] No se est√° ejecutando porque aun no se le ha asignado ninguna
				m√°quina (IDLE).
			\item[R:] Ejecut√°ndose actualmente (RUNNING).
			\item[H:] El trabajo no se est√° ejecutando por deseo del propietario
(HOLD). Ver el comando \htmladdnormallink{condor\_hold}
{http://goya/inves/SINFIN/Condor/v6.6/condor\_hold.html}, 
\htmladdnormallink{condor\_release}
{http://goya/inves/SINFIN/Condor/v6.6/condor\_release.html} 
o la
\htmladdnormallink{secci√≥n 2.6.3}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00363000000000000000}
del manual de Condor. 
		\end{description}
	+ La prioridad del trabajo que ha especificado el usuario. Ver comando
\htmladdnormallink{condor\_prio}{http://goya/inves/SINFIN/Condor/v6.6/condor\_prio.html} o
la \htmladdnormallink{secci√≥n 2.6.4}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00364000000000000000}
del manual de Condor.
	+ El tama√±o de la imagen del trabajo en megabytes.
	+ Y por √∫ltimo, el nombre del ejecutable.
\end{itemize}

En el caso de que un trabajo no se est√© ejecutando, este comando tambi√©n nos
permite conocer el motivo gracias a la opci√≥n {\tt -analyze}. Por ejemplo:
%Este comando tambi√©n nos permite conocer las causas de que un trabajo no se est√©
%ejecutando, para esto usaremos la opci√≥n {\tt -analyze}. Por ejemplo:
\begin{verbatim}
[adrians@trevina ~]$ condor_submit myjob.submit 
Submitting job(s).
Logging submit event(s).
1 job(s) submitted to cluster 1.

[adrians@trevina ~]$ condor_q -analyze


-- Submitter: trevina.iac.es : <161.72.81.178:39869> : trevina.iac.es
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD               
---
001.000:  Run analysis summary.  Of 187 machines,
    187 are rejected by your job's requirements
      0 reject your job because of their own requirements
      0 match, but are serving users with a better priority in the pool
      0 match, but prefer another specific job despite its worse user-priority
      0 match, but will not currently preempt their existing job
      0 are available to run your job
        No successful match recorded.
        Last failed match: Thu Sep 16 12:38:09 2004
        Reason for last match failure: no match found

WARNING:  Be advised:
   No resources matched request's constraints
   Check the Requirements expression below:

Requirements = ((Memory > 2147483647)) && (Arch == "INTEL") &&
(OpSys == "LINUX") && (Disk >= DiskUsage) &&
(TARGET.FileSystemDomain == MY.FileSystemDomain)

\end{verbatim}

En el ejemplo podemos ver como el trabajo 1.0 tiene problemas para ejecutarse:
nuestros requisitos ({\tt Requirements}) han desechado 187 m√°quinas de las 187
candidatas. Adem√°s, {\em condor\_q} nos sugiere que revisemos dicha expresi√≥n y nos
la muestra en su salida (en el ejemplo vemos como el l√≠mite m√≠nimo de memoria
RAM es excesivo).

Para m√°s informaci√≥n puedes visitar la \htmladdnormallink{p√°gina del manual de {\em condor\_q}}
{http://goya/inves/SINFIN/Condor/v6.6/condor\_q.html}, la
\htmladdnormallink{secci√≥n 2.6.1}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00361000000000000000}
o la \htmladdnormallink{secci√≥n 2.6.5}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00365000000000000000}
del manual de Condor.

\subsection{Borrando trabajos. {\em condor\_rm}}
\label{sec::condor_rm}

Usaremos {\em condor\_rm} para borrar un trabajo de la cola de Condor:

\begin{verbatim}
[adrians@trevina ~]$ condor_q


-- Submitter: trevina.iac.es : <161.72.81.178:1085> : trevina.iac.es
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD
   2.0   adrians         7/13 12:46   0+00:00:01 R  0   0.0  myprog Example.2.0

1 jobs; 0 idle, 1 running, 0 held

[adrians@trevina ~]$ condor_rm 2.0
Job 2.0 marked for removal
\end{verbatim}

Podemos especificar tanto un trabajo como un cluster, en el ejemplo anterior, si hubi√©semos
ejecutado {\tt condor\_rm 2} habr√≠amos borrado todos los trabajos del cluster 2.

Notar que no podemos borrar trabajos que no nos pertenezcan.

Para m√°s informaci√≥n puede visitar la 
\htmladdnormallink{p√°gina del
manual}{http://goya/inves/SINFIN/Condor/v6.6/condor\_rm.html}
 o la \htmladdnormallink{secci√≥n 2.6.2 del manual de
Condor}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00362000000000000000}.

\subsection{Estado de Condor. {\em condor\_status}}

Este comando nos permitir√° conocer el estado de Condor:

\begin{verbatim}
[adrians@trevina ~]$ condor_status

Name          OpSys       Arch   State      Activity   LoadAv Mem   ActvtyTime

vm1@aciano.ia LINUX       INTEL  Claimed    Busy       1.030   501  0+16:56:02
vm2@aciano.ia LINUX       INTEL  Claimed    Busy       0.990   501  0+00:59:48
agracejo.iac. LINUX       INTEL  Claimed    Busy       1.030   500  0+21:00:39
vm1@agrimonia LINUX       INTEL  Claimed    Busy       1.010  1826  0+00:09:36
vm2@agrimonia LINUX       INTEL  Claimed    Busy       1.000  1826  0+00:09:32
alfalfa.iac.e LINUX       INTEL  Owner      Idle       0.000   248  0+00:32:55
...
tonina.iac.es SOLARIS29   SUN4u  Claimed    Busy       1.000   128  0+21:56:24
toro.iac.es   SOLARIS29   SUN4u  Unclaimed  Idle       0.000   128  0+00:00:04
tuno.iac.es   SOLARIS29   SUN4u  Owner      Idle       0.040   640  0+01:33:15
vibora.iac.es SOLARIS29   SUN4u  Claimed    Busy       1.010   576  3+02:59:06
viola.iac.es  SOLARIS29   SUN4u  Claimed    Busy       1.010   256  0+01:40:35
zarza.iac.es  SOLARIS29   SUN4u  Claimed    Busy       0.660   256  0+00:01:06
zorro.ll.iac. SOLARIS29   SUN4u  Claimed    Busy       1.040   384  1+03:38:25

                     Machines Owner Claimed Unclaimed Matched Preempting

         INTEL/LINUX       75    33      41         1       0          0
     SUN4u/SOLARIS29       87    21      64         2       0          0

               Total      162    54     105         3       0          0
\end{verbatim}

Este comando muestra informaci√≥n sobre cada una de las m√°quinas que forman el ``pool''
de Condor y un resumen del estado actual. En este resumen podemos comprobar, en cifras,
el uso que se le est√°n dando a las m√°quinas. As√≠, por ejemplo, podremos comprobar cuantas
m√°quinas quedan disponibles para ejecutar trabajos mirando la columna ``Unclaimed''.

Para m√°s informaci√≥n puedes visitar la \htmladdnormallink{p√°gina del manual}
{http://goya/inves/SINFIN/Condor/v6.6/condor\_status.html}
de este comando.

%%%%%%%%%%%%%%%%%%%%%%%% Section.
\section{Limitaciones}

\begin{itemize}
	+ Si su trabajo realiza muchas operaciones de entrada/salida (E/S)
		tenga en cuenta la sobrecarga que esto conlleva, probablemente no obtenga
		una mejora muy grande envi√°ndolo a Condor. Note que todas las operaciones
		de lectura/escritura sobre archivos se realizan sobre la red\footnote{Los archivos
		residen f√≠sicamente en el home de un usuario especial por lo que todas las
		peticiones se realizar√°n sobre NFS.} por lo que sus trabajos se ver√°n 
		ralentizados.
% Pero realmente su home siempre est√° compartido por NFS, en todo caso el
% problema ser√° para naranja...
	+ Si env√≠a un trabajo al universo ``vanilla'' contemple que cuando
		sea expulsado de una m√°quina perder√° todo lo procesado hasta ese momento
		(a no ser que haya tomado precauciones por su cuenta). Si env√≠a un trabajo
		que planea que vaya a tardar varios d√≠as en finalizar su ejecuci√≥n 
		probablemente no obtenga mejor√≠a usando Condor, en estos casos plant√©ese
		el uso del universo ``standard''.
% Explicar pq matamos su pobre trabajo :) quiz√°s un enlace a la secci√≥n de 
% ¬øC√≥mo funciona?.
	+ Tenga en cuenta que cada trabajo que env√≠e generar√° un proceso ``shadow''
		en la m√°quina desde donde se hace el env√≠o. Este proceso se encarga de
		resolver algunas cuestiones relacionadas con su trabajo, realmente
		no consume demasiada CPU pero si realiza muchos env√≠os puede llegar a
		ralentizar su m√°quina.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%% Section.
\section{¬øY si tengo problemas?}
Existe a su disposici√≥n un portal dedicado a Condor en el I.A.C., la direcci√≥n es:
\url{http://goya/inves/SINFIN/Condor/}. Tambi√©n puede ponerse en contacto con
los administradores de Condor en la direcci√≥n de correo condor@iac.es.



** Python bindings

