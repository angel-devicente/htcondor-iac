# Time-stamp: <2023-02-25 12:08:06 angelv> 

#+TITLE:   HTCondor IAC User's Manual
#+AUTHOR:  Ángel de Vicente
#+EMAIL:   angel.de.vicente@iac.es

#+OPTIONS:   H:6 num:6 toc:4 author:t email:t title:t

#+LATEX_CLASS_OPTIONS: [a4paper,10pt]
#+LaTeX_HEADER: \usepackage[left=2cm, right=2cm, top=1.5cm, bottom=2cm]{geometry}

# To be able to create boxes around text. From
# https://emacs.stackexchange.com/questions/22092/how-to-place-a-box-around-a-piece-of-text-in-org-mode

#+LATEX_HEADER_EXTRA:  \usepackage{mdframed}
#+LATEX_HEADER_EXTRA: \BeforeBeginEnvironment{minted}{\begin{mdframed}}
#+LATEX_HEADER_EXTRA: \AfterEndEnvironment{minted}{\end{mdframed}}

#+latex: \small

* Users' documentation for the IAC HTCondor Pool
  
** Introduction   

#+begin_mdframed
If you have no experience with HTCondor, we recommend that you contact us before
running any job so we can give you a quick introduction (bear in mind that you
will be using other users' computers and there are some basic guidelines that
you must follow to avoid disturbing them).
#+end_mdframed

#+begin_mdframed
The HTCondor infrastructure at the IAC has been recently expanded and improved,
with about 100 new Linux desktop PCs financed by the Ministry of Economy and
Competitiveness through FEDER funds, code IACA13-3E-2493. 
#+end_mdframed

*** What is HTCondor? 

At the IAC we have several [[http://research.iac.es/sieinvens/SINFIN/Main/supercomputing.php][Supercomputing]] resources that allow you to obtain
your computational results in much less time and/or work with much more complex
problems. One of them is [[http://research.cs.wisc.edu/htcondor/][HTCondor]], a High Throughput Computing ([[http://en.wikipedia.org/wiki/High-throughput_computing][HTC]]) system. The
underlying idea is quite simple (and powerful): let's use idle machines to
perform computations while their owners are away. So, in a nutshell, HTCondor is
an application that is installed in our PCs to make it possible to run a large
number of yours and others' computations at a time in different machines when
they are not being used, achieving a better utilization of our resources. A more
detailed overview of HTCondor is available at the official [[http://research.cs.wisc.edu/htcondor/overview/][documentation]].

*** How can HTCondor help us?

HTCondor is very useful when you have an application that has to run a large
number of times over different input data. For instance, suppose you have a
program that carry out some calculations taking an image file as input. Let's
say that the processing time is about one hour per image and you want to process
250 images. Then you can use your own machine and process all images one by one,
and wait more than 10 days to get all results, or you can use HTCondor to
process each image in different computers and hopefully get all results in one
hour, or maybe two or four, but for sure less than 10 days. And HTCondor will do
all the work for you: it will copy the input files to the remote machines,
execute your program there with different inputs and bring back the results to
your machine when they are complete.

HTCondor has also other powerful features. For instance, you can also use it to
[[http://research.iac.es/sieinvens/siepedia/pmwiki.php?n=HOWTOs.CondorFAQs#run_ckpt][create specific or periodic checkpoints]] of your @@C@@, @@C++@@ or @@fortran@@
programs. Then you can normally run your application (without using HTCondor)
and if something happens (your program crashes, PC is unexpectedly halted,
etc.), you will be able to restart the execution from any of the checkpoints,
saving a lot of time. Please, read this introduction and the other sections to
discover how HTCondor can help you.

*** How ''powerful'' is HTCondor?

HTCondor calls "'''''slot'''''" the unit that executes a job, typically a CPU or
core if the CPU has several of them. Right now we have around 900 slots
(Feb 2017) that might execute applications submitted via HTCondor. It means that
everyday more than 21000 hours could be available to run HTCondor jobs, more
than 2 years of computation in just 24 hours! OK, this is the theoretical limit
if no one were using their computers and all slots were idle... ;) The number of
idle slots is always changing, but based on our experience a more realistic
number of idle slots could be around 400 slots in office hours and 650 at nights
and weekends, so still we have more than one year of HTCondor computation time
per day.  

You can see the real-time HTCondor statistics here: [[http://nectarino][nectarino]] (''Pool
Resource Stats'' show the number of slots being used by their owners, by
HTCondor and the idle ones; while ''Pool User Stats'' show the number of
HTCondor jobs and consumed hours per user). If you want more detailed info about
which and when jobs have been executing on specific machines, check stats at
[[http://carlota:81/condor_stats]]. Also you can visit the
[[http://venus/SIE/forum/viewtopic.php?f=8&t=38][Hall of Fame]] of HTCondor. 

*** Which machines are running HTCondor?

HTCondor is already installed in most of the Desktop PCs running Linux that we
have at IAC Headquarters in La Laguna, with a total number of more than 230
machines.

If you are concerned about hardware specifications, you may know that those
machines are rather heterogeneous and its availability and specifications change
from time to time. At the present status (Sept, 2014), most CPUs are Intel (and
also some AMD) from 2.40 to 3.20 GHz. Each CPU has typically 2, 4 or 8 cores,
although there are also more powerful machines with up to 32 cores per CPU. As
for memory, the most common is 2GB per slot, while some of them have from 3 to
8GB per slot and a few just 1GB per slot.

On the other hand, software specifications are quite homogeneous and all
machines are running the same OS: Fedora Linux. Almost all machines run Fedora21
(as of June 2017, there are still a few machines running older versions, and a
handful with Fedora 25). Installed software should be also more or less the same
in every machine (see the [[http://research.iac.es/sieinvens/SINFIN/Main/software_sinfin.php][software supported by the SIE)]], which makes
it easy to run almost every application in any machine (although the available
software could be different in some machines that belong to the Instrumentation
area).

If your application has special requirements about memory per slot, OS version,
etc., you can rank and/or limit these parameters and also a quite large set of
other ones. ''Please, visit FAQs page for more information and
examples.''


*** Who can use HTCondor? How does it work?  Do I need to change my application?

If you have a computer account at the IAC and you can log in on a Linux PC
Desktop connected to the internal network, then you should be able to use
HTCondor with no problems (try @@condor_version@@ command to check whether
HTCondor is installed. Please contact us if it is not or you experience any
issue).

HTCondor is a batch-processing system, so you only need to submit your jobs to
the HTCondor queue and it will do all the work. The submission is done using a
HTCondor script where you specify your executable, its arguments, inputs and
outputs, etc. (visit HTCondor submit files page to see some
examples and recommendations). You do not need to prepare or compile your
programs in any special way to run them, and almost all programming languages
that are commonly used at IAC should be suitable to be run with HTCondor (shell
scripts, Python, Perl, C, Fortran, IDL, etc.). Sometimes a few minor
modifications may be needed in order to specify arguments and the locations of
inputs or outputs, so that HTCondor can find them, but that should be all.

Once the submitted jobs are in HTCondor queue, it uses its allocation algorithm
to send and execute your jobs on those idle slots that satisfy your
requirements. Idle slots are those located in machines where there has been no
keyboard/mouse activity for a long while and the computer load is low enough to
ensure that there is no interference with the owner's processes. While HTCondor
is running its jobs, it also keeps checking that the owner is not using the
machine. If HTCondor detects any activity in the computer (for instance, a key
is pressed), then it will suspend all its jobs and wait a little while to see
whether the machine gets idle again so as to resume the jobs. If the owner keeps
working, HTCondor will interrupt all jobs and send them to other available slots
in any other idle machine. HTCondor will repeat this process till all jobs are
done, sending notifications via email when they are finished or if any errors
show up.


*** I am using HTCondor, should I add an acknowledgement text in my publications?

Yes, you should mention it in the acknowledgments of your papers or any other
publications where you have used HTCondor. Although there is no standard format,
we suggest the following:

>>frame<< ''"This paper made use of the IAC Supercomputing facility HTCondor
(http://research.cs.wisc.edu/htcondor/), partly financed by the Ministry of
Economy and Competitiveness with FEDER funds, code IACA13-3E-2493."''  >><<

If you have used any other IAC Supercomputing facilities (LaPalma, TeideHPC,
etc.), please, add them in the acknowledgments too:

'''LaPalma''': ''"The author thankfully acknowledges the technical expertise and
assistance provided by the Spanish Supercomputing Network (Red Española de
Supercomputación), as well as the computer resources used: the LaPalma
Supercomputer, located at the Instituto de Astrofísica de Canarias."''

'''TeideHPC''': ''"The author(s) wish to acknowledge the contribution of Teide
High-Performance Computing facilities to the results of this research. TeideHPC
facilities are provided by the Instituto Tecnológico y de Energías Renovables
(ITER, SA). URL: http://teidehpc.iter.es/"''

*** I need more information or have some problems, who can help me...?

If you need further information, please check the other pages about HTCondor at
the SIEpedia: Useful Commands, Submit Files (description and examples), Submit
Files (HowTo), FAQs, etc. HTCondor at SIEpedia is continuously updated, but we
also have more documentation about older versions of HTCondor at the [[http://research.iac.es/sieinvens/SINFIN/Condor/index.php][the
HTCondor section at IAC]] (most of that information is still valid, but some may
be obsolete, including broken links). For detailed and complete information,
check the [[http://research.cs.wisc.edu/htcondor/manual/v8.6/][official documentation about HTCondor]].

If you need help or you are having any kind of issues related to HTCondor,
'''the SIE gives direct support''' to IAC's users who want to use HTCondor: we
will not code your whole application, but we help and advise you about how to
get the most out of HTCondor: use its commands, create submit files, modify your
application to run it with HTCondor (in case it is needed), fix common mistakes,
etc. We also organize workshops about HTCondor for IAC's users (the last one was
on February, 25th 2014 - [[https://docs.google.com/presentation/d/1PqCih4yL6D3FOFo0W336RjLCKrSICZbYuPX1F1CZqtQ/present#slide=id.p][slides]], and we can organize a new workshop on demand if
you and your colleges need it: if the group is large enough -10 or 12 people-,
just contact us!).

** Useful Commands

HTCondor has several dozens of commands, but in this section we will present
just the most common ones (if you want to check the complete list, try the
[[http://research.cs.wisc.edu/htcondor/manual/v8.6/11_Command_Reference.html][Command Reference page]]). Also remember that you can get further information
running @@man condor_<cmd>@@ in your shell or visiting the [[http://research.cs.wisc.edu/htcondor/manual/v8.6/2_Users_Manual.html][official Users'
Manual]]. The main command will be shown together with some useful options that
may help work with HTCondor:


*** Checking pool status

+ =condor_status=: list slots in HTCondor pool and their status: =Owner= (used
  by owner), =Claimed= (used by HTCondor), =Unclaimed= (available to be used
  by HTCondor), etc. Useful options:
  + =-avail=: List those slots that are not busy and could run HTCondor jobs at
    this moment
  + =-submitters=: Show information about the current general status, like
    number of running, idle and held jobs (and submitters)
  + =-run=: List slots that are currently running jobs and show related
    information (owner of each job, machine where it was submitted from, etc.)
  + =-compact=: Compact list, with one line per machine instead of per slot
  + =-state -total=: List a summary according to the state of each slot
  + =-master=: List machines, but just their names (status and slots are not
    shown)
  + =-server=: List attributes of slots, such as memory, disk, load, flops, etc.
  + =-sort Memory=: Sort slots by Memory, you can try also with other attributes
  + =-af <attr1> <attr2> <...>=: List specific attributes of slots, using
    autoformat (new version, very powerful)
  + =-format <fmt> <attr>=: List attributes using the specified format (old
    version). For instance, next command will show the name of each slot and the
    disk space: =condor_status -format "%s\t " Name -format "%d KB\n" Disk=
  + =<machine>=: Show the status of a specific machine
  + =<machine> -long=: Show the complete "ClassAd" of a machine (its
    specifications). We can use these specifications to add restrictions in the
    submit file so we can control which machines we want to use.
  + =-constraint <constraint>=: Only Show slots that satisfy the
    constraint. I.e: =condor_status -constraint 'Memory > 1536'= will only show
    slots with more than 1.5GB of RAM per slot.

*** Submitting jobs

+ =condor_submit <submit_file>=: Submit jobs to the HTCondor queue according to
  the information specified in =submit_file=. Visit the *submit file page* to
  see some examples of these files. There are also some FAQs related to the
  submit file. Useful options:

  + =-dry-run <dest_file> =: this option parses the submit file and saves all the
  related info (name and locations of input and output files after expanding all
  variables, value of requirements, etc.) to =<dest_file>=, but jobs are '''not'''
  submitted. Using this option is highly recommended when debugging or before the
  actual submission if you have made some modifications in your submit file and
  you are not sure whether they will work.

  + ='var=value'=: add or modify variable(s) at submission time, without changing
  the submit file. For instance, if you are using =queue $(N)= in your submit
  file, then =condor_submit <submit_file> 'N = 10'= will submit 10 jobs. You can
  specify several pairs of =var=value=.

  + =-append <command>=: add submit commands at submission time, without changing
  the submit file. You can add more than one command using several times
  =-append=.

When submitted, each job is identified by a pair of numbers '''X.Y''', like
345.32. The first number (X) is the '''cluster id''': every submission gets a
different cluster id, that is shared by all jobs belonging to the same
submission. The second number (Y) is the '''process id''': if you submitted N
jobs, then this id will go from 0 for the first job to N-1 for the last one. For
instance, if you submit a file specifying 4 jobs and HTCondor assign id 523 to
that cluster, then the ids of your jobs will be 523.0, 523.1, 523.2 and 523.3
(you can get these ids and more info using =condor_q= command).

#+begin_mdframed
*Caution!*: Before submitting your jobs, always do some simple tests in
order to make sure that both your submit file and program work in a proper way:
if you are going to submit hundreds of jobs and each job takes several hours to
finish, before doing that try with just a few jobs and change the input data in
order to let them finish in minutes. Then check the results to see if everything
went fine before submitting the real jobs. Bear in mind that submitting untested
files and/or jobs may cause a waste of time and resources if they fail, and also
your priority will be lower in following submissions. 
#+end_mdframed



*** Checking and managing submitted jobs                           :noexport:

>>frame<<
'''Note:''' Each machine manages its own HTCondor queue, so it has information only about those jobs that were submitted on it (and no information about any other jobs you may have submitted on other machines). Most of the commands explained in this section get information asking only the local queue, which means that you will only see those jobs that you have submitted on that specific machine. If you submit jobs from different machines, and later you want to check, hold, release, remove, etc. those jobs, you may need to connect to each one of those machines where you have submitted jobs from, or, when possible, use the commands with extra options to communicate with other machines.
>><<


*='''condor_q'''=: Show my jobs that have been submitted in this machine. By default you will see the ID of the job(=clusterID.processID=), the owner, submitting time, run time, status, priority, size and command. ['''STATUS''': '''I''':idle (waiting for a machine to execute on); '''R''': running; '''H''': on hold (there was an error, waiting for user's action); '''S''': suspended; '''C''': completed; '''X''': removed; '''<''': transferring input; and '''>''': transferring output]
->''Useful options:''
**=-global=: Show my jobs submitted in any machine, not only the current one
**=-nobatch=: Starting in version HTCondor 8.6.0 installed in January 2017, data is displayed in a compact mode (one line per cluster). With this option output will be displayed in the old format (one line per process)
**=-wide=: Do not truncate long lines. You can also use =-wide:<n>= to truncate lines to fit =n= columns
**=-analyze <job_id>=: Analyse a specific job and show the reason why it is in its current state (useful for those jobs in Idle status: Condor will show us how many slots match our restrictions and may give us suggestion)
**=-better-analyze <job_id>=: Analyse a specific job and show the reason why it is in its current state, giving extended info
**=-long <job_id>=: Show all information related to that job
**=-run=: Show your running jobs and related info, like how much time they have been running, in which machine, etc.
**=-currentrun=: Show the consumed time on the current run, the cumulative time from last executions will not be used (you can combine also with =-run= flag to see only the running processes at the moment)
**=-hold=: Show only jobs in the "on hold" state and the reason for that. Held jobs are those that got an error so they could not finish. An action from the user is expected to solve the problem, and then he should use the =condor_release= command in order to check the job again
**=-af <attr1> <attr2> <...>=: List specific attributes of jobs, using autoformat
**[-{-=''-global -submitter <user>=-}: Show all jobs from user =<user>= in all machines. '''Note''': starting in HTCondor version 8.6.0 installed at IAC in January 2017, HTCondor will NOT show other users' jobs'' by default, but you can use some flags like =-allusers= to change this behaviour -]



*='''condor_tail''' <job_id>=: Display on screen the last lines of the =stdout= (screen) of a running job on a remote machine. You can use this command to check whether your job is working fine, you can also visualize errors (=stderr=) or output files created by your program  (see also [[this FAQ -> CondorFAQs#ssh]]).
->''Useful options:''
**=-f=: Do not stop displaying the content, it will be displayed until interrupted with =Ctrl+C=
**=-no-stdout -stderr=: Show the content of =stderr= instead of =stdout=
**=-no-stdout <output_file>=: Show the content of an output file (=output_file= has to be listed in the =transfer_output_files= command in the submit file).

*='''condor_release''' <job_id>=: Release a specific held job in the queue. 
->''Useful options:''
**=<cluster_id>=: Instead of giving a =<job_id>=, you can specify just the =<cluster_id>= in order to release all held jobs of a specific submission
**=-constraint <constraint>=:  Release all my held jobs that satisfy the constraint
**=-all=: Release all my held jobs
-> [-'''Note:'''  Jobs with ''on hold'' state are those that HTCondor was not able to properly execute, usually due to problems with executable, paths, etc. If you can solve the problems changing the input files and/or the executable, then you can use =condor_release= command to run again your program since it will send again all files to the remote machines. If you need to change the submit file to solve the problems, then =condor_release= will NOT work because it will not evaluate again the submit file. In that case you can use =condor_qedit= (see [[this FAQ -> HOWTOs.CondorFAQs#ch_submit]]) or cancel all held jobs and re-submit them again-]

*='''condor_hold''' <job_id>=: Put jobs into the hold state. It could be useful when you detect that there are some problems with your input data (see [[this FAQ -> CondorFAQs#bad_inputs]] for more info), you are running out of disk space for outputs, etc. With this command you can delay the execution of your jobs holding them, and, after solving the problems, assign them the idle status using =condor_release=, so they will be executed again.
->''Useful options:''
**=<cluster_id>=: Instead of giving a =<job_id>=, you can specify just the =<cluster_id>= in order to hold all jobs of a specific submission
**=-constraint <constraint>=: Hold all jobs that satisfy the constraint
**=-all=: Hold all my jobs from the queue

*='''condor_rm''' <job_id>=: Remove a specific job from the queue (it will be removed even if it is running). Jobs are only removed from the current machine, so if you submitted jobs from different machines, you need to remove your jobs from each of them.
->''Useful options:''
**=<cluster_id>=: Instead of giving a =<job_id>=, you can specify just the =<cluster_id>= in order to remove all jobs of a specific submission
**=-constraint <constraint>=: Remove all jobs that satisfy the constraint
**=-all=: Remove all my jobs from the queue
**=-forcex <job_id>=: It could happen that after removing jobs, they don't disappear from the queue as expected, but they just change status to '''X'''. That's normal since HTCondor may need to do some extra operations. If jobs stay with 'X' status a very long time, you can force their elimination adding =-forcex= option. For instance: =condor_rm -forcex -all=.


*='''condor_prio'''=: Set the priority of my jobs. A user can only change the priority of her own jobs, to specify which ones she would like to run first (the higher the number, the bigger the priority). Priority could be absolute or relative, use =man condor_prio= for further information
*='''condor_ssh_to_job <job_id>'''=: Create an ssh session to a running job in a remote machine. You can use this command to check whether the execution is going fine, download/upload inputs or outputs, etc. More information about this command is available in [[FAQs section -> CondorFAQs#ssh]].


*** Getting info from logs                                         :noexport:

*='''condor_userlog''' <file.log>=: Show and summarize job statistics from the job log files (those created when using =log= command in the submit file)

*='''condor_history'''=: Show all completed jobs to date (it has to be run in the {+same machine+} where the submission was done).
->''Useful options:''
**=-userlog <file.log>=: list basic information registered in the log files (use =condor_logview <file.log>= to see information in graphic mode)
**=-long XXX.YYY -af LastRemoteHost=: show machine where job XXX.YYY was executed
**=-constraint <constraint>=: Only show jobs that satisfy the constraint. I.e: =condor_history -constraint 'RemoveReason=!=UNDEFINED'=: show your jobs that were removed before completion

*='''''condor_logview''''' <file.log>=: This is not an original HTCondor command, we have created this link to the script that allows you to display graphical information contained in the log of your executions.

+ There is also an online tool to analyze your log files and get more information: =HTCondor Log Analyzer= ([[ http://condorlog.cse.nd.edu/ ]]). 

*** Other commands                                                 :noexport:
*='''condor_userprio'''=: Show active HTCondor users' priority. Lower values means higher priority where 0.5 is the highest. Use =condor_userprio -allusers= to see all users' priority, you can also add flags =-priority= and/or =-usage= to get detailed information
*='''condor_qedit'''=: use this command to modify the attributes of a job placed on the queue. This may be useful when you need to change some of the parameters specified in the submit file without re-submitting jobs (see [[this FAQ -> HOWTOs.CondorFAQs#ch_submit]]).
*='''condor_compile'''=: Relink a program with HTCondor libraries so it can be used in the =standard= universe where checkpoints are enable (check [[this FAQ -> CondorFAQs#checkpoints]] for more info). Relinked programs can be also executed as an standalone checkpointing executable, what means that you can run it directly in your shell (no HTCondor submission is needed) and create specific or periodic checkpoints that allow you to recover the execution in case of problems. See [[this FAQ -> CondorFAQs#run_ckpt]] for more information and examples. 
*='''condor_submit_dag''' <dag_file>=: Submit a DAG file, used to describe jobs with dependencies. Visit the [[Submit File (HowTo) -> CondorHowTo#howto_dagman]] section for more info and examples. 
*='''condor_version'''=: Print the version of HTCondor. 
+ If you want some general information about HTCondor queue, the pool of machines, where jobs have been executed on, etc., you can try our online stats about HTCondor: [[http://carlota:81/condor_stats/]] and [[nectarino -> http://nectarino/]].




* TO SORT OUT                                                      :noexport:



*** Submit files (desc. & examples)

(:title HTCondor(3): Submit files (description and examples) :)
! HTCondor submit files (description and examples) 


!! Introduction
To execute your application with HTCondor, you have to specify some parameters like the name of your executable, its arguments, inputs and outputs, requirements, etc. This information is written in a plain text using '''submit commands''' in a file called ''HTCondor Submit Description File'' or simply '''submit file'''. Once that file is filled with all needed info, you have to submit it to HTCondor using ='''condor_submit'''= in your terminal, and then it will be processed and your jobs will be added to the queue in order to be executed.

'''Submit files have considerably changed after the release of versions 8.4.X''' (first version 8.4.0 released in Sept 2015, since Feb 2017 we are using versions 8.6.X). Some operations were not possible or highly painful in previous versions (like dealing with an undetermined number of files with arbitrary names, declaring variables and macros and performing operations with them, including submission commands from other files, adding conditional statements, etc.). To solve that, many researchers developed external scripts (perl, python, bash, etc.) to dynamically create description files and submit them, what in most cases resulted in complex submissions and less efficient executions, not to mention that usually it was needed a hard work to adapt those scripts when the application, arguments and/or IO files changed. 

With the addition of [[new, powerful and flexible commands -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00352000000000000000]], most of those problems have been solved, so there should be no need of using external scripts and '''we highly recommend you always use a HTCondor submit description file instead of developing scripts in other languages'''. If you did that in the past, please, consider migrating your old scripts, we will give you support if you find any problems.

In this section you will find templates and examples of HTCondor Submit Description Files. Use them as reference to create your own submit files and contact us if you have any doubt or issue. Topics:
+ [[Creating a submit file -> #creating_submit_files]] (description and structure of submit files: comments, variables, commands, etc.)
+ [[Templates and examples of submit files -> #templates_examples]]
+ [[OLD examples -> #old_examples]]
+ [[Some more useful commands and info -> #some_more_commands]]


>>frame<<
'''Caution!: Before submitting your real jobs, perform always some simple tests''' in order to make sure that both your submit file and program will work in a proper way: if you are going to submit hundreds of jobs and each job takes several hours to finish, before doing that try with just a few jobs and change the input data in order to let them finish in minutes. Then check the results to see if everything went fine before submitting the real jobs. Also we recommend you use =condor_submit '''-dry-run'''= to debug your jobs and make sure they will work as expected, see [[useful commands -> CondorUsefulCommands]] page). Bear in mind that submitting untested files and/or jobs may cause a waste of time and resources if they fail, and also your priority will be lower in following submissions.
>><<

[[#creating_submit_files]]
!! Creating a Submit File
As many other languages, HTCondor submit files allow the use of comments, variable, macros, commands, etc. Here we will describe the most common ones, you can check the %newwin%[[official documentation -> https://research.cs.wisc.edu/htcondor/manual/]] for a complete and detailed information about submit files and submitting process.
!!! Comments
HTCondor uses symbol ='''#'''= for comments. Everything found after that symbol will be ignored. Please, do not mix commands and comments in the same line, since it may produce errors. We recommend you always write commands and comments in different lines.
 ''# This is a valid comment''
 A = 4    ''# This may produce errors when expanding =A=, do not use comments and anything else in the same line!''

!!! Variables and macros

There are many predefined variables and macros in HTCondor that you can use, and you can define your own ones.
**  To '''define a variable''', just chose a valid name (names are case-insensitive) and assign a value to it, like =N = 4=, =Name = "example"=
**  To '''get the value''' of a variable, use next syntax: =$(varName)=, both =$= symbol and parentheses =()= are mandatory. 
**  You can do '''basic operations''' with variables, like =B = $(A) + 1=, etc. (since version 8.4.0 is not needed to use the old and complex syntax [@$$[(...)]@] for the operations). To get the expression evaluated, you may need to use function macros like =$INT(B)=, =$REAL(B)=, etc.
**  There are several special '''automatic variables''' defined by HTCondor that will help you when creating your submit file. The most useful one is ='''$(Process)'''= or =$(ProcId)=, that will contain the Process ID of each job (if you submit =N= jobs, the value of =$(Process)= will be =0= for the first job and =N-1= in the last job). This variable is like an '''iteration counter''' and you can use it to specify different inputs, outputs, arguments, ... for each job. There are some %newwin%[[other automatic variables -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00353000000000000000]], like =$(Cluster)= or =$(ClusterId)= that stores the ID of each submission, =$(Item)=, =$(ItemIndex)=, =$(Step)=, =$(Row)=, etc. (see %newwin%[[Example1 -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00353000000000000000]] for further information).
**  There are several [['''pre-defined Function Macros''' -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00356000000000000000]]. Their syntax is ='''$FunctName(varName)'''= and they can perform some operations on variable =varName= like evaluating expressions and type conversions, selecting a value from a list according an index, getting random numbers, string operations, filenames processing, setting environment variables, etc. Before creating your own macros, check if HTCondor has already %newwin%[[a pre-defined Function Macro -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00356000000000000000]] with the same purpose.

!!! Submit commands
You will need to add several HTCondor submit commands in your script file in order to specify which executable you want to run and where it is located, its arguments if any, input files, which result files will be generated, etc. There is a wide set of HTCondor with almost 200 different %newwin%[[submit description file commands -> http://research.cs.wisc.edu/htcondor/manual/v8.6/condor_submit.html#SECTION0012564000000000000000]] to cover many different scenarios. But in most situations you will only need to specify a few of them (usually about 10-15). Here we will present the most common ones (commands are case-insensitive):

# '''Mandatory commands:'''
** ='''executable'''=: specify where your executable is located (you can use an absolute path, a relative one to the directory where you do the submission or to another directory specified with =initialdir=). You should specify '''only the executable''' and not other things like arguments, etc., there are specific commands for that. HTCondor will automatically copy the executable file from your machine to any machine where your job will be executed, so you do not need to worry about that.
** ='''queue'''=: this command will send your job(s) to the queue, so it should be the last command in your submit file. In previous versions of HTCondor it was quite limited, only allowing the number of jobs as argument. But since version 8.4.0, this command is very powerful and flexible, and you can use it to specify variables, iterations over other commands, files to be processed, list of arguments, etc. (%newwin%[[see complete syntax and examples -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00352000000000000000]]).
# '''Highly recommended commands:'''
** ='''output'''=: it will copy the standard output printed on the screen (=stdout=) of the remote machines when executing your program to the local file you specify here. Since all the jobs will use the same name, the filename should include some variable parts that change depending on the job to avoid overwritten the same file, like =$(Process)= (and also =$(Cluster)= if you do not want that different submissions ruin your output files). Even if your program does not print any useful results on screen, it is very recommended you save the screen output to check if there were errors, debug them if any, etc.
** ='''error'''=: the same as previous command, but for standard error output (=stderr=).
** ='''log'''=: it will save a log of your submission that later can be analysed with HTCondor tools. This is very useful when there is any problem with your job(s) to find the problem and fix it.  The log should be the same for all jobs submitted in the same cluster, so you should '''not''' use =$(Process)= in the filename (but including =$(Cluster)= is recommended).
** =universe=: there are several %newwwin%[[runtime environments -> http://research.cs.wisc.edu/htcondor/manual/v8.6/condor_submit.html#man-condor-submit-universe]] in HTCondor called ''universes'', we will mostly use the one named =vanilla= since it is the easiest one. This is the universe by default, so if you miss this command, your jobs will also go to =vanilla= universe. 
# '''Useful commands when working with inputs and outputs (arguments, files, keyboard, etc.)''':
** ='''arguments'''=: it is used to specify options and flags for your executable file, like when using it in command line.
** ='''should_transfer_files'''=: assign =YES= to it in order to activate HTCondor file transfer system (needed when working with files).
** ='''when_to_transfer_output'''=: it will usually have a value of =ON_EXIT= to only copy output files when your job is finished, avoiding the copy of temporary or incomplete files if your job fails or it is moved to another machine.
** ='''transfer_input_files'''=: it is used to specify where the needed input files are located. We can use a comma-separated list of files (with absolute or relative paths, as mentioned in =executable= command). Local path will be ignored, and HTCondor will copy all files to the root directory of a virtual location on the remote machine (your executable will be also copy to the same place, so input files will be in the same directory). If you specify a directory in this command, you can choose if you want to copy only the content of the directory (add a slash "='''/'''=" at the end, for instance =myInputDir'''/'''=) or the directory itself and its content (do not add a slash).
** ='''transfer_output_files'''=: a comma-separated list of result files to be copied back to our machine. If this command is omitted, HTCondor will automatically copy all files that have been created or modified on the remote machine. Sometimes omitting this command is useful, but other times our program creates many temporary or useless files and we only want to get the ones we specify with this command.
-> ''More commands for input/output files:'' (:toggle hide io_commands button=1:)
>>id=io_commands padding=5px<<
** =transfer_output_remaps=: it changes the name of the output files when copying them to your machine. That is useful when your executable generates result file(s) with the same name, so changing the filename to include a variable part (like =$(Process)= and maybe also =$(Cluster)=) will avoid overwritten them.
** =initialdir=: this command is used to specify the base directory for input and output files, instead of the directory where the submission was performed from. If this command include a variable part (like =$(Process)=), you can use this command to specify a different base directory for each job.
** =input=: if your program needs some data from keyboard, you can specify a file or a comma-separated list of files containing it (each end of line in the file will have the same behaviour as pressing =Intro= key in the keyboard, like when using =stdin= redirection in command line with ='''<'''=). As other similar commands, you can use absolute or relative paths.
** =transfer_executable=: by default its value is =True=, but if it is set to =False=, HTCondor will not copy the executable file to the remote machine(s). This is useful when the executable is a system command or a program that is installed in all machines, so it is not needed to copy it.
>><<
# '''Other useful commands:'''
** =request_memory=, =request_disk=: if your program needs a certain amount of total RAM memory or free disk space, you can use these commands to force that your jobs will be only executed on machines with at least the requested memory/free disk space [[[[-HowTo -> CondorHowTo#howto_requirements-]]]]
** =requirements=: this is a very useful command if your program has any special needs. With it you can specify that your job can be only executed on some machines (or some machines cannot run your program) according to a wide set of parameters (machine name, operative system and version and a large etc.) [[[[-HowTo -> CondorHowTo#howto_requirements-]]]]
** =rank=: you can specify some values or combination of them (total memory, free disk space, MIPS, etc.) and HTCondor will choose the best machines for your jobs according to your specifications, where the higher the value, the better (this command is used to specify preferences, not requirements) [[[[-HowTo -> CondorHowTo#howto_prefs-]]]]
** =getenv=: if it is set to =True=, all your environment variables will be copied at submission time and they will be available when your program is executed on remote machines (if you do not use this command or it is set to =False=, then your jobs will have no environment variables). This is useful when running some programs that need a special environment, like python, etc. [[[[-HowTo -> CondorHowTo#howto_env-]]]]
** =nice_user=: if it is set to =True=, your jobs will be executed with a fake user with very low priority, what could be very useful when the queue is (almost) empty, so you can run your jobs without wasting your real user priority (you can activate and deactivate this feature when your jobs are being executed, so you can begin running your jobs as nice user if the queue is empty and change to normal user when the queue has many other jobs, or vice versa) [[[[-HowTo -> CondorHowTo#howto_priority-]]]]
** =concurrency_limits=: you can limit the maximum number of your jobs that could be executed at the same time. You should use this command if your program needs licences and there are a few of them (like =IDL=, see also [[this alternative -> CondorAndIDLVirtualMachine]]) or if for any reason you cannot use the HTCondor file transfer system and all your jobs access to the same shared resource (=/scratch=, =/net/nas=, etc.), in order to avoid that too many concurrent access can stress the network [[[[-HowTo -> CondorHowTo#howto_limit-]]]]
** =include=: since HTCondor v8.4.0, it is possible to %newwin%[[include externally defined submit commands -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00354000000000000000]] using syntax: ='''include :''' ''<myfile>''=. You can even include the output of external scripts that will be executed at submission time, adding a pipe symbol after the file: ='''include :''' ''<myscript.sh>'' '''|'''=
-> ''More useful commands:'' (:toggle hide more_useful_commands button=1:)
>>id=more_useful_commands padding=5px<<
** =environment=: this command will allow you to set/unset/change any environment variable(s) [[[[-HowTo -> CondorHowTo#howto_env-]]]]
** =priority=: if some of your jobs/clusters are more important than others and you want to execute them first, you can use =priority= command to assign them a priority (the higher the value, the higher priority). This command only have an effect on your own jobs, and it is not related to users priority [[[[-HowTo -> CondorHowTo#howto_priority-]]]]
** =job_machine_attrs=, =job_machine_attrs_history_length=: use these commands to reduce the effects of ''black holes'' in HTCondor, what causes that many of your jobs could fail in a short time [[[[-HowTo -> CondorHowTo#howto_failing-]]]]
** =noop_job=: you specify a condition and those jobs that evaluate it to true will not be executed. This is useful when some of your jobs failed and you want to repeat only the failing jobs, not all of them [[[[-HowTo -> CondorHowTo#howto_failing-]]]]
** =+PreCmd=, =+PreArguments=, =+PostCmd=, =+PostArguments=: These commands allow you to run some scripts before and/or after your executable. That is useful to prepare, convert, decompress, etc. your inputs and outputs if needed, or debug your executions [[[[-HowTo -> #CondorHowTo#howto_prepostcmd-]]]]
** =notify_user=, =notification=: use these commands if you want to receive a notification (an email) when your jobs begin, fail and/or finish [[[[-HowTo -> CondorHowTo#howto__notify-]]]]
** =if= ... =elif= ... =else= ...  =endif=: since HTCondor version 8.4.0, a %newwin%[[limited conditional semantic -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00355000000000000000]] is available. You can use it to specify different commands or options depending on the defined/undefined variables, HTCondor version, etc.
** =on_exit_hold=, =on_exit_remove=, =periodic_hold=, =periodic_remove=, =periodic_release=, etc.: you can modify the default behaviour of your jobs and the associated status. These commands can be used in a wide set of circumstances. For instance, you can force that jobs that are running for more than X minutes or hours will be deleted or get a ''on hold'' status (with this you can prevent that failing jobs will be running forever, since they will be stopped or deleted if they run for a much longer while than expected) or the opposite, hold those jobs that finish in an abnormal short time to check later what happened. Or you can also periodically release your held jobs, to run them on other machines if for any reason your jobs work fine on some machines, but fail on others [[[[-HowTo -> CondorHowTo#howto_failing-]]]]
** =deferrall_time=, =deferral_window=, =deferral_prep_time=: you can force your jobs begin at a given date and time. That is useful when the input data is not ready when submitting and your jobs have to wait till a certain time [[[[-HowTo -> CondorHowTo#howto_runintime-]]]]
>><<




[[#example_misc]][[#templates_examples]]
!! Templates and examples
Here you can find basic templates of submit files, you can use them as starting point and then do the customizations needed for your executions. Check the examples in following sections for details and explanations.

[[#common_template]]
!!!Common Template

 ''######################################################''
 ''# HTCondor Submit Description File. COMMON TEMPLATE''   
 ''# Next commands should be added to all your submit files''   
 ''######################################################''
 =if !defined= FNAME
   FNAME = condor_exec
 =endif=
 ID      = $(Cluster).$(Process)

 =output=  = $(FNAME).$(ID).out
 =error=   = $(FNAME).$(ID).err
 =log=     = $(FNAME).$(Cluster).log

 =universe=                = vanilla
 =should_transfer_files=   = YES
 =when_to_transfer_output= = ON_EXIT

'''Explanation:''' (:toggle hide common_tmpl button=1:)
>>id=common_tmpl border='1px solid #999' padding=5px bgcolor=#eee<<

Let's analyse the common template: 
#First block:
** Here we will define some variables that will be used later. The first of them is =FNAME= and first we ask with the =if defined= condition whether that variable is not already defined (if so, we will use the previous value). This variable will contain the base name for the files where HTCondor will save the information displayed on the screen (=stdout= and =stderr=) and the log file. It is interesting to give a common name to those files generated by HTCondor so later we can identify and manage them together. Since all jobs will use the name specified there, we have to include a variable part that has to be different in each job, in order to avoid overwriting the files. We recommend you use a combination of =$(Process)= (it contains the process ID that is different for each job) and =$(Cluster)= (it contains the cluster ID that is different for each submission), as we have done when defining =$(ID)=. In this way, different jobs and different submission will use different filenames and none of them will be overwritten.
#Second block:
** With =output= command we force HTCondor to write in the specified file all the screen output (=stdout=) generated by each job. We have used the variables =$(FNAME)= and =$(ID)= defined above. 
** With =error= command we manage =stderr= in the same way we did with =output=.
** Then we have also specified a HTCondor log file with =log= command. You should not use =$(Process)= in the filename of the log since all jobs should share the same log.
#Third block:
** =universe=: there are %newwwin%[[runtime environments -> http://research.cs.wisc.edu/htcondor/manual/v8.6/condor_submit.html#man-condor-submit-universe]] in HTCondor called ''universes'', we will mostly use the one named =vanilla= since it is the easiest one. This is the universe by default, so if you miss this command, your jobs will go also to =vanilla= universe.
** =should_transfer_files=YES= and =when_to_transfer_output=ON_EXIT= commands are used to specify that input files have to be copied to the remote machines and output files must be copied back to your machine only when our program is finished. Although these commands are only needed when working with files, we recommend you always use them unless you are totally sure you can omit them.
>><<

!!!Examples when working with input/output files and arguments
Most times you will want to run applications that deal with input and/or output files. Commonly, the input files will be located on your local machine, but since your application will be executed on other machine(s), it will be needed to copy your input files there, and then copy the result files back to your computer once your program is done. HTCondor have some commands to automatically do both operations in an easy way, so you do not need to worry about the file transfers: you just need to specify where your files are and HTCondor will copy them.

'''Note:''' All these examples will begin defining a specific variable =FNAME= that contains the base name of the files that HTCondor will generate to save the =stdout=, =stderr= and log. Next, the common template explained above with be included using command =include= (we assume that the common template filename is =condor_common.tmpl=). 


(:table border=0 cellpadding=5 cellspacing=0 width=100% :)
(:cell width=50% :) 
[+'''Example A'''+] (arbitrary filenames)
**  Process all input files with extension =.in= in a given directory with next program: \\
=./myprogram -i =inputFile= -o =outputFile
 ''# Including Common Template''
 FNAME = exampleA
 =include= : /path/to/condor_common.tmpl

 =transfer_input_files=    = $(mydata)
 =transfer_output_files=   = $=Fn=(mydata).out


 =executable=    = myprogram
 =arguments=     = "-i $=Fnx=(mydata) -o $=Fn=(mydata).out"

 =queue= '''mydata''' =matching files= /path/to/inputs/*.in
'''Explanation:''' (:toggle hide exampleA button=1:)
>>id=exampleA border='1px solid #999' padding=5px bgcolor=#eee<<
We use =transfer_input_files= to specify where the needed input files are located. We can use a comma-separated list of files, but since we do not know the name of the files, we will use the variable =mydata= to specify them. That variable is defined in the last line, with the =queue= command: there, we choose to process all files in =/path/to/inputs= with extension =.in=. When submitting, HTCondor will check that directory and it will automatically create a job for each =.in= file found there, assigning the complete filename to =mydata= (in this way, each job will work with a different file). We have used the =matching files= to specify that we only want files matching the condition, but we can also select only directories (=matching dirs=) or both of them (just =matching=). 

With =transfer_output_files= we set the name of the output files, that is the same as the input file with =.out= extension. To remove the old extension we use the =$Fn= macro, that is one of the %newwin%[[new =Fpdnxq= Function Macros -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00356000000000000000]] available since version 8.4.0, used to operate the filename and extract the path, name without extension, extension, etc.

Then we use =executable= to specify the name of the executable (it can be a system command, your own application, a script, etc). We can use a absolute path or a relative one to the directory where we will perform the submission. This executable will be copied to all remote machines automatically. Finally, =arguments= is used to specify the options for the program. We have to employ again =Fpdnxq= macros, first =Fnx= to remove the original path (file we be copied to the root of a virtual location where HTCondor will run the executable on the remote machine) and then =Fn= to remove path and change extension of the output file.
>><<
(:cell width=50% :)
[+'''Example B'''+] (based on ProcessID, old system before HTCondor v8.4.0)
**  Process 50 input files with consecutive names (from data0.in to data49.out) using the same program as previous example
 ''# Including Common Template''
 FNAME = example2
 =include= : /path/to/condor_common.tmpl

 =transfer_input_files=    = /path/to/inputs/data$(Process).in
 =transfer_output_files=   = data$(Process).out

 N             = 50
 =executable=    = myprogram
 =arguments=     = "-i data$(Process).in -o data$(Process).out"

 =queue= $(N)
'''Explanation:''' (:toggle hide exampleB button=1:)
>>id=exampleB border='1px solid #999' padding=5px bgcolor=#eee<<
=transfer_input_files= command allows a comma-separated list of files or directories that will be copied to the remote machine. Local path will be ignored, and HTCondor will copy all files to the root directory of a virtual location on the remote machine (your executable will be also copy to the same place, so input files will be in the same directory). If you specify a directory in this command, you can choose if you want to copy only the content of the directory (add a slash "='''/'''=" at the end, for instance =myInputDir'''/'''=) or the directory itself and its content (do not add a slash). In this case, each job will process a different input file, and since they have a consecutive name beginning from =0=, we will use HTCondor macro =$(Process)= to build the proper name, since the process ID will be =0= from the first job to =N-1= for the last job.

With =transfer_output_files= we specify a comma-separated list of result files to be copied back to our machine. In this case, we specify just one file, with the same name as the input file, but with =.out= extension.

Then we define the variable =N= to specify the number of jobs to be executed. Our program is set using =executable= command and with =arguments= command we specify all the needed options (here the name of the input and output file with the corresponding flags).

At the end, we send all jobs to the queue with =queue= command, specifying how many jobs we want (we have used the variable =N=).
>><<
(:tableend:)



(:table border=0 cellpadding=5 cellspacing=0 width=100% :)
(:cell width=50% :) 
[+'''Example C'''+] (lists of files and arguments written in submit file)
**  Process all arbitrary files and arguments of a given list. Executable is =myprogram= and it needs an input file with extension =.dat= and some arguments. Results will be printed on screen (=stdout=).
 ''# Including Common Template''
 FNAME = exampleC
 =include= : /path/to/condor_common.tmpl

 =executable=    = myprogram

 =queue transfer_input_files=,=arguments '''from'''= (
   xray434.dat, -d 345 -p f034
   sunf37.dat,  -d 2   -p f302
   light67.dat, -d 62  -p f473
 )= =

'''Explanation:''' (:toggle hide exampleC button=1:)
>>id=exampleC border='1px solid #999' padding=5px bgcolor=#eee<<
We will use the flexibility of =queue= command to assign values of a list to several commands. We must specify which files must be transferred and which arguments are needed by each file. We specify then =transfer_input_files= and =arguments= commands using the =from= option, and then we add a list of pairs ''file,argument''. 

At submission time, HTCondor will iterate over the list and expand the assignations. For instance, our jobs will have next values:
# [-=transfer_input_files= = xray434.dat, =arguments= = -d 345 -p f034-]
# [-=transfer_input_files= = sunf37.dat, =arguments= = -d 2   -p f302-]
# [-=transfer_input_files= = light67.dat, =arguments= = -d 62  -p f473-]

When using this format you can specify as many commands separated by commas as needed between =queue= and =from=, but check that each line in the list has the right number of elements also separated by commas. 

Writing the list of items in the submit file can be a little bit tedious, but it may be easily done in an external file using scripts. Then you can directly specify the file. For instance, suppose you have all items in a file named =data.lst=, then you can use next =queue= command:
 =queue transfer_input_files=,=arguments from= /path/to/data.lst
>><<
(:cell width=50% :) 
[+'''Example D'''+] (lists of files and arguments in external file)
**  Process arbitrary files and arguments stored in file =data.lst= (process only lines from 28 to 43, both inclusive, with step 5). Executable is =myprogram= as in previous example, but this time it saves the result in a file named =output.out=.
 ''# Including Common Template''
 FNAME = exampleD
 =include= : /path/to/condor_common.tmpl

 =transfer_output_files=  = output.out
 line                   = $(Row)+1
 =transfer_output_remaps= = "output.out=output$=INT=(line).out"

 =executable=    = myprogram

 =queue= =transfer_input_files=,=arguments '''from''' [27:43:5]= data.lst
'''Explanation:''' (:toggle hide exampleD button=1:)
>>id=exampleD border='1px solid #999' padding=5px bgcolor=#eee<<
This example is similar to the previous one, but this time the list of input files and arguments is written in a file with the following format:
 [-input_file1,args1-]
 [-input_file2,args2-]
 [-input_file3,args3-]
 ...
To illustrate the '''slice''' feature, we have been asked to process only items (lines) from 28 to 43 with step 5 (28, 33, 38 and 43), this could be useful when we want to run only certain experiments. The syntax for the slices is very easy, the same as Python: =[init:end:step]=. Since the first index is 0, but we do not use line 0 but line 1, the =init= should be 27. Then the =end= is 43 (it should be 42, but we need to add 1 because the upper limit is included according to our example). So we specify the slice using =[27:43:5]= in the =queue= command, between the =from= clause and the file.

We have to be careful with the results. Our program writes them in a file named =output.out=. We cannot get all files with the same name because they will be overwritten, so we need to use =transfer_output_remaps= to change names when copying from remote machines to our. We can add the =$(Process)= variable to the new name, so all of them will be different, but then it could be a little bit complicated to identify each result. Instead, we will use another of the %newwin%[[automatic variables -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00353000000000000000]], called =$(Row)=. It stores the number of the row in the list that is being processed, that is, almost the number of the line: since =$(Row)= begins in 0, we need to add 1 to get the line number. We do that in variable =$(line)=. Then, HTCondor will process rows 27, 32, 37 and 42, and our output files will be =output28.out=, =output33.out=, =output38.out= and =output43.out=.
>><<
(:tableend:)


(:table border=0 cellpadding=5 cellspacing=0 width=100% :)
(:cell width=50% :) 
[+'''Example E'''+] (=stdin=, =initialdir= external scripts and lists)
**  Our program =myprogram= works with =stdin= (keyboard is used to specify input data). We have written that input data in 4 files (=dataFeH.in=, =dataOFe.in=, =dataOH.in= and =dataHe.in=) and there is a set of 3 different experiments in directories (=dir000=, =dir001= and =dir002=). Output files will be generated with the same name as inputs and extension =.out= (use =-o= argument) and they must be located in the same directory where the respective input file is. Program also needs all =*.tbl= files located in =/path/to/tables=.
 ''# Including Common Template''
 FNAME = exampleE
 =include= : /path/to/condor_common.tmpl

 N            = 3
 =input=        = data$(met).in
 =initialdir=   = /path/to/dir$=INT=(Step,%03d)
 =include=      : input_tables.sh ='''|'''=
 =transfer_output_files= = data$(met).out

 =executable=   = myprogram
 =arguments=    = "-o data$(met).out"

 =queue= $(N) '''met''' ='''in'''= FeH, OFe, OH, He

'''Explanation:''' (:toggle hide exampleE button=1:)
>>id=exampleE border='1px solid #999' padding=5px bgcolor=#eee<<
The key of this example is the =queue= command in last line. We are using the clause ='''in'''= to specify a list of values. HTCondor will create a job for each element in the list and the current value will be assigned to the variable =met= that we have declared (this variable is optional, you can omit it and use the automatic variable =Item=). We have 3 set of experiments, so we need to go over the list 3 times, that is why we have defined =N = 3= and we are using =$(N)= in the =queue= command. So, at the end, HTCondor will execute 12 jobs (3 runs * 4 elements in the list): we will use automatic variable =$(Step)= to get the number of the present run (0, 1 or 2) and =$(met)= (or =$(Item)= if we omit the variable) to get the value of the current element in the list.

=input= command is used to specify a file that will be used as =stdin=, using variable =$(met)= to get the proper filename. That variable will be also used when building the name of the output files (=transfer_output_files= command) and the arguments (=arguments= command).

We use =initialdir= to specify a base directory that changes according to the current job, using the automatic variable =$(Step)=. HTCondor will use this directory as base for the relative paths, so it will affect the input and output files, including the =stdout=, =stderr= and log files created by HTCondor (see common template). We use =$INT(Step,%03d)= to get a 3-digit number (000, 001 and 002) to build the proper path for each experiment, then HTCondor will go to the right directory to get the input files and to place later the respective output files there.

Last thing we have to solve is the problem with the required input files (all =*.tbl= files located in =/path/to/tables=). HTCondor does not allow globbing in =transfer_input_files=, but instead we can use the new feature of %newwin%[[including external files -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#SECTION00354000000000000000]] with =include= command. This command not only include other files, but also invoke them if the command finish with a '''bar''' ='''|'''=. Then we can easily make a external script to get the list of needed files with linux command =ls= and options =-m= (commas are used to separate elements) and =-w= (used to specify the wide of the screen before adding a new line. Since we need all elements in the same line, we should specify a number big enough). In this case, our external script =input_tables.sh= is the following one:
 [-#!/bin/bash-]
 [-=echo= "transfer_input_files = `=ls= -w 400 -m /path/to/tables/*.tbl`"-]
>><<
(:cell width=50% :) 
[+'''Example F'''+] (loops)
**  Execute each iteration of a 3-level nested loop using: =myprogram -dim1 i -dim2 j -dim3 k = with the following ranges: =i:[0,20)=, =j:[0,15)= and =k:[0,35)=. Output will be written on screen, no input files are needed.
 ''# Including Common Template''
 FNAME = exampleF
 =include= : /path/to/condor_common.tmpl
 
 MAX_I = 20
 MAX_J = 15
 MAX_K = 35

 N = $(MAX_I) * $(MAX_J) * $(MAX_K)

 I = ( $(Process) / ($(MAX_K)  * $(MAX_J)))
 J = (($(Process) /  $(MAX_K)) % $(MAX_J))
 K = ( $(Process) %  $(MAX_K))

 =executable= = myprogram
 =arguments=  = "-dim1 $=INT=(I) -dim2 $=INT=(J) -dim3 $=INT=(K)"

 =queue= $(N) 

'''Explanation:''' (:toggle hide exampleF button=1:)
>>id=exampleF border='1px solid #999' padding=5px bgcolor=#eee<<
In this example we only need to ''simulate'' a 3 nested loops from a 1-level loop (we will use =$(Process)= as main loop counter). The 3-level loop will be the next ones, and HTCondor will create a job for each iteration:

 =for= (i = 0; i < MAX_I; i++)
   =for= (j = 0; j < MAX_J; j++)
     =for= (k = 0; k < MAX_K; k++)
       ./myprogram  -dim1 i -dim2 j -dim3 k

Then we only need to set the limits (=MAX_I=, =MAX_J=, =MAX_K=), the number of total iterations (=N = $(MAX_I) * $(MAX_J) * $(MAX_K)=) and use some maths to get the values of =I=, =J= and =K= according the value of =$(Process)=, as we have done above (just a few multiplications, integer divisions and remeinders are needed).

For a 2-level loop, you can use next code:
 I = ($(Process) / $(MAX_J))
 J = ($(Process) % $(MAX_J))
>><<
(:tableend:)

[+'''Example G:'''+] This example shows the use of several useful commands for specific conditions. It is also a summary of the [[HOWTOs -> CondorHowTo]], you can find further details and explanation about the submit commands there (:toggle hide exampleG button=1:)
>>id=exampleG<<
# Execute =myprogram= with argument "=-run =" from 0 to 99 by default. 
# ''BLOCK A'': Execute only on machines with at least 4GB RAM and 2GB of free disk space. The higher memory and the faster calculations, the better (we can use KFLOPS to choose the faster machines doing floating point operations, but since memory and kflops have different units, we need to weight them, for instance, multiplying memory by 200). 
# ''BLOCK B'': Execute only on machines with Linux Fedora21 or upper and avoid executing on =cata=, =miel= and those with hostname beginning with letter =m= or =d=.
# ''BLOCK C'': It is needed to run script =processData.sh= before (argument: =-decompress=) and after (argument: =-compress=) to prepare our data. 
# ''BLOCK D'': Our executable needs the environment variables and variable =OUT= has to be set with the argument. 
# ''BLOCK E'': Avoid ''black holes'' (when your jobs do not execute correctly on a machine, and since they finish quickly, that machine is getting most of the jobs).
# ''BLOCK F'': Get a notification via email when errors in the job. If the job finishes before 5 minutes or takes more than 2 hours to be done, there was a problem: hold it to check later what happened. 
# ''BLOCK G'': Our program needs licenses, so we cannot run more than 20 jobs at the same time. Execute jobs as ''nice user'' to save priority since there are no other jobs running at this moment.
(:table border=0 cellpadding=5 cellspacing=0 width=100% :)
(:cell width=50% :) 
 ''# Including Common Template''
 FNAME = exampleG
 =include= : /path/to/condor_common.tmpl

 =if !defined= N
   N = 100
 =endif=

 ''#BLOCK A''
 =requested_memory= = 4 GB
 =requested_disk=   = 2 GB
 =rank=             = (200 * Memory) + KFLOPS

 ''#BLOCK B''
 letter           = =substr=(=toLower=(=Target.Machine=),0,1)
 =requirements=     = (=UtsnameSysname= == "Linux") 
         && (=OpSysName= == "Fedora") && (=OpSysMajorVer= >= 21) 
         && '''!'''=stringListMember=(=UtsnameNodename=, "cata,miel")
         && '''!'''=stringListMember=($(letter), "m,d")


 ''#BLOCK C''
 =transfer_input_data= = processData.sh
 =+PreCmd=             = "processData.sh"
 =+PreArguments=       = "-decompress"
 =+PostCmd=            = "processData.sh"
 =+PostArguments=      = "-compress"

 # ...
(:cell width=50% :) 
 # ...

 ''#BLOCK D''
 =getenv=              = =True=
 =environment=         = "OUT=$(Process)"

 ''#BLOCK E''
 =job_machine_attrs= = Machine  
 =job_machine_attrs_history_length= = 5           
 =requirements= = $(=requirements=) 
       && (=target.machine= =!= =MachineAttrMachine1=)  
       && (=target.machine= =!= =MachineAttrMachine2=)

 ''#BLOCK F''
 =notify_user=       = myuser@iac.es
 =notification=      = Error

 =on_exit_hold= = ((=CurrentTime= - =JobStartDate=) < (5 * 60)
 =periodic_hold= = ((=JobStatus= == 2) 
          && (=time()= - =EnteredCurrentStatus=) >  (2  $(=HOUR=)))

 ''#BLOCK G''
 =concurrency_limits= = myuser$(=Cluster=):50
 =nice_user= = =True=

 =executable= = myprogram
 =arguments=  = "-run $(Process)"

 =queue= $(N) 

(:tableend:)
>><<

>>frame<<
[- '''IMPORTANT''': Although your program could use shared locations (=/net/XXXX/scratch=, =/net/nasX=, etc.) to read/write files from any machine so there is no need to copy files, we highly recommend '''you always use the HTCondor file transfer system''' to avoid network congestion since files will be accessed locally on the remote machines. Bear in mind that HTCondor can execute hundreds of your jobs at the same time, and if all of them concurrently access to the same shared location, network could experience a huge stress and fail. If for any reason you cannot copy files and you have to use shared locations -you are using huge files of several GB, etc.-, then contact us before submitting to adapt your jobs in order to avoid network congestion.-]
>><<

[[#example_howto]]


[[#howto_requirements]]
[[#howto_prefs]]
[[#howto_notify]]
[[#howto_env]]
[[#howto_prepostcmd]]
[[#howto_priority]]
[[#howto_failing]]
[[#howto_limit]]
[[#howto_complex_op]]
[[#howto_nestloop]]
[[#howto_runintime]]
[[#howto_dagman]]
[[#howto_attr]]

!! Submit file HowTo

>>frame bgcolor=#FAF2CC padding=6px<<
NOTE: '''Submit File HOWTOs have been moved to their own page''': [[ HTCondor(4): Submit File (HowTo) -> CondorHowTo]]
>><<
** [-[[CondorHowTo#howto_requirements | How to ... add requirements on the target machines where my jobs will be run?]]-]
** [-[[CondorHowTo#howto_prefs        | How to ... add preferences on the target machines where my jobs will be run?]]-]
** [-[[CondorHowTo#howto_env          | How to ... get/set environment variables?]]-]
** [-[[CondorHowTo#howto_notify       | How to ... control HTCondor notifications?]]-]
** [-[[CondorHowTo#howto_prepostcmd   | How to ... run some shell commands/scripts/programs before/after our application?]]-]
** [-[[CondorHowTo#howto_priority     | How to ... specify the priority of your jobs?]]-]
** [-[[CondorHowTo#howto_failing      | How to ... deal with jobs that fail?]]-]
** [-[[CondorHowTo#howto_limit        | How to ... limit the number of concurrent running jobs?]]-]
** [-[[CondorHowTo#howto_complex_op   | How to ... do some complex operations in my submit file?]]-]
** [-[[CondorHowTo#howto_nestloop     | How to ... work with nested loops?]]-]
** [-[[CondorHowTo#howto_runintime    | How to ... program my jobs to begin at a predefined time?]]-]
** [-[[CondorHowTo#howto_dagman       | How to ... run jobs that have dependencies among them?]]-]
** [-[[CondorHowTo#howto_attr         | How to ... know the attributes of the machines where our jobs are run?]]-]

[[#old_examples]]
!! OLD Examples

This section presents several examples of submit files, from very basic examples to more complex ones, step by step. These examples were created for previous versions of HTCondor and since version 8.4.0 there are easier and more flexible ways to get the same results in most cases. However, we have left these old examples here since they may help you, but bear in mind that they may be obsolete. (:toggle hide OLDexample button=1:)
>>id=OLDexample<<


**  [[#example_exec_args | Example 1]]. Our first submit file: executable and arguments
**  [[#example_simple_inputs | Example 2]]. Adding simple inputs and outputs: =stdin=, =stdout= and =stderr=
**  [[#example_simple_files  | Example 3]]. Simple examples including input and output files
**  [[#example_files | Example 4]]. A more complex example, step by step
**  [[#example_complex_macros | Example 5]]. Working with more complex loops and macros




These examples will cover the most common cases based on our experience with IAC's users. If you want a complete documentation, you can run =man condor_submit= in your shell, visit the =condor_submit= page in the %newwin%[[http://research.cs.wisc.edu/htcondor/manual/v8.6/condor_submit.html | reference manual]] and/or the %newwin%[[http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html | Submitting a Job section]]). Some more %newwin%[[examples -> http://research.cs.wisc.edu/htcondor/quick-start.html]] of submit description files are also available at HTCondor site.





[[#example_exec_args]]  
!! Example 1. Our first submit file: executable and arguments [[[--^ Top -> #top--]]]

The first thing you have to specify is the executable of the application to run and its arguments, and then launch the jobs. For that purpose we will use =executable=, =arguments= and =queue= commands, respectively (note that commands are case insensitive). If your application is located in a private directory that is not accessible for other users and/or from other machines, then you need to add =should_transfer_files= command and HTCondor will copy your application to the machines where it will be run.

In our first example we have developed an application called "=myprogram=" located in the same directory where we are going to do the submission. We want to run it with 2 different sets of arguments =-c -v 453= and =-g 212=. Then our submit file will be the following one:

 =universe= = vanilla
 =should_transfer_files=  = YES

 =executable= = myprogram

 =arguments=  = "-c -v 453"
 =queue=

 =arguments=  = "-g 212"
 =queue=

We will explain here why we use each of these commands:
**  =universe=: there are several runtime environments in HTCondor, we will mostly use the one named =vanilla= since it is the easiest one. This is the universe by default, so if you miss this command, your jobs will go also to =vanilla= universe.
**  =should_transfer_files=: use it with value =YES= to specify that your files are not accessible and should be copied to the remote machines
**  =executable=: Specify the name and path of your executable. The path can be absolute or relative (to the directory in which the =condor_submit= command is run). HTCondor will copy the executable to each machine where your job(s) will be run.
**  =arguments=: Specify the parameters of your application. There is an old syntax, but it is recommendable to use the new one enclosed by double quote marks. If you need to specify complex arguments including simple or double quote marks, check the %newwin%[[new syntax in the argument list -> http://research.cs.wisc.edu/htcondor/manual/v8.6/condor_submit.html#man-condor-submit-arguments]] in HTCondor documentation.
**  =queue=: Place one job into the HTCondor queue, or =N= if you use =queue <N>=.
\\

Save this file (for example, call it =myprogram.submit=) and do the submission in the same directory where your program is located:
 [...]$ =condor_submit= myprogram.submit

That is all, your jobs will be added into the HTCondor queue, you can check it running =condor_q=. 

[[#example_simple_inputs]]  
!! Example 2. Adding simple inputs and outputs: =stdin=, =stdout= and =stderr= [[[--^ Top -> #top--]]]
Now we will deal with inputs and outputs. Let's configure three HTCondor jobs to print "Hello World!" and the ID of each job. We will use OS command  =echo= so outputs will be printed in =stdout= (the screen), but since we cannot access to the screen of other machines when running the jobs, we should find the way to save these outputs to files. Of course, each job should write a different file and it may be 
interesting to store them in a separated directory, for instance an existing one called =output_files=. Also we may want to see any errors (from =stderr=) and save a log file. The resulting HTCondor submit file could be the next one:

 ''# First block''
 N = 3

 =universe=               = vanilla
 =should_transfer_files=  = YES
 =initialdir=             = /path/to/files 

 =input=   =
 =output=  = echo_example.$(Cluster).$(Process).out
 =error=   = echo_example.$(Cluster).$(Process).err                                                                                     
 =log=     = echo_example.$(Cluster).log                                                                       

 ''# Second block''
 =executable=          = /bin/echo
 =transfer_executable= = False
 =arguments=           = "Hello World, I am job: $(Process)!"

 =queue= $(N)

Let's analyze this example: 
#First block:
** The first line contains a macro declaration, =N = 3=, so from that point we can use that macro writing =$(N)= (you must use parenthesis, =$N= is NOT valid).
** =should_transfer_files = YES= command is used to specify that files should be copied to/from the remote machines. 
** Then with =initialdir= we specify the path to input and output files (not the executable), it can be an absolute path or relative (to the directory in which the =condor_submit= command is run). If your files are in the same directory where you are doing the submission, then you do not need to use this command.
** =input= command is empty since we do not need it in this example. But if you run your program in this way: =myprogram < data.in=, then you should add next command =input = data.in=.
** With =output= command we force HTCondor to write in the specified file all the screen output (=stdout=). Note that to avoid all jobs writing in the same file, we have used the =$(Cluster)= macro (it is an ID of each submission) and the =$(Process)= macro (it is an ID given to each job, from 0 to =N-1=). 
** With =error= command we manage =stderr= in the same way we did with =output=.
** Then we have also specified a log file with =log= command.

#Second block:
** We specify the name of your application using =executable= command (we set it to =/bin/echo=).
** Since the executable is an OS command available in each machine, it is not needed that HTCondor makes a copy to each machine, so we have used =transfer_executable = False= to avoid that. 
** =arguments= command specify the arguments of your program. We have use the predefined =$(Process)= macro so each job will print its own ID. This can be used also like a counter or loop in your arguments. 
** At the end we send =N= jobs to the queue using =queue <N>= command.

If we save the submit file with name =echo.submit= and send it to the queue using =condor_submit echo.submit= (let's suppose it gets Cluster ID 325), the result should be something like the following one, assuming we are located in the directory where we did the submission:
 ./echo.submit
 /path/to/output_files/echo_example.325.0.out   # ''(content: Hello World, I am job: 0!)''
 /path/to/output_files/echo_example.325.1.out   # ''(content: Hello World, I am job: 1!)''
 /path/to/output_files/echo_example.325.2.out   # ''(content: Hello World, I am job: 2!)''
 /path/to/output_files/echo_example.325.0.err   # ''(content: Empty if no errors)''
 /path/to/output_files/echo_example.325.1.err   # ''(content: Empty if no errors)''
 /path/to/output_files/echo_example.325.2.err   # ''(content: Empty if no errors)''
 /path/to/output_files/echo_example.325.log     # ''(content: Info about jobs execution)''    

\\
HTCondor is mainly designed to run batch programs and they usually have no interaction with users, but if your program needs any input from the =stdin= (i.e. keyboard), you can specify it writing all the inputs in a file and then using =input= command to indicate that file, with the same syntax as the =output= command.

[[#example_simple_files]]
!! Example 3. Simple examples including input and output files  [[[--^ Top -> #top--]]]
Now we know how to specify standard inputs and outputs, let's see how we can deal with input and output files. We will study two different situations to see how we can solve each one, depending on whether our executable accepts arguments for input/output files or not.

!!! Example 3A. We can specify our input/output files as arguments  [[[--^ Top -> #top--]]]
Suppose that we have developed an application called =myprogram= that needs two arguments, the first one is the name of the input file and the second one is the name of the output file that will be generated. We usually run this application in the following way:
 ./myprogram /path/to/input/data.in data.out

We have 300 different input data files named =data0.in=, =data1.in=, =data2.in=, ..., =data299.in= and we want to use HTCondor to execute them (each job will process a different input file). Then we just need to write the next submit file to execute jobs in HTCondor:

 N     = 300
 ID    = $(Cluster).$(Process)
 FNAME = example3A

 =output=  = $(FNAME).$(ID).out
 =error=   = $(FNAME).$(ID).err                                                                                     
 =log=     = $(FNAME).$(Cluster).log                                                                       

 =universe=                = vanilla
 =should_transfer_files=   = YES
 =when_to_transfer_output= = ON_EXIT

 =transfer_input_files=    = /path/to/input/data$(Process).in
 =transfer_output_files=   = data$(Process).out

 =executable=  = myprogram
 =arguments=   = "data$(Process).in data$(Process).out"

 =queue= $(N)

This submit file is similar to previous examples. We have defined some useful macros (=ID= and =FNAME=) to avoid writing the same text several times, and we have also used some new commands like =transfer_input_files= to specify input files and =transfer_output_files= for the output files (if you need to specify several input and/or output files, use a comma separated list). Remember we have to activate the HTCondor copying files mechanism using =should_transfer_files= command, and we have also used =when_to_transfer_output= to tell HTCondor that it should only copy the output files when our program is finished. If you do not use =transfer_output_files= command, then HTCondor will copy all generated or modified files located in the same directory where your application was executed (see [[this FAQ -> CondorFAQs#outputs]] for more info).

You do not need to deal with copying files, HTCondor will copy the input files from the specified location on your machine to the same directory where your program will be executed on the remote machine (that is why we have used no path for the input file in the =arguments= command, since that file will be in the same place as the executable). Once your program is finished, HTCondor will copy the output file from the remote machine to yours and it will be located in the same directory where you did the submission (remember you can change this behaviour with =initialdir= command).

In this example we have supposed that input files have a convenient name, containing a known pattern that includes a consecutive number from =0= to =N-1=. This is the easiest situation, and although it is not strictly needed to rename your input files, we recommend you change filenames to make much easier to specify them using HTCondor commands. There are several simple ways to rename your files, like using the =rename= linux command, a bash script, etc. For instance, if your input files have different names, but all of them have =.in= extension, then next simple bash script will do the work renaming all of them so the result will be =data0.in=, =data1.in=, =data2.in=, ..., =data299.in= following alphabetic order (you can modify it to use your own criteria, save the equivalence between old and new names, etc):

 ''#!/bin/bash''

 n=0
 =cd= /path/to/input/
 =for= file =in= *.in  
 =do= 
   =mv= =$file= data=$n=.in 
   n=$((n+1))  
 =done=



!!! Example 3B. We cannot specify arguments  [[[--^ Top -> #top--]]]
Sometimes our executable does not accept arguments and it needs to find some specific files. For instance, suppose that our application =myprogram= needs to find an input file called =data.in= in the same directory where it will be executed and then it will produce an output file called =data.out=, also in the same directory. Again, we will also assume that we have all our input files in =/path/to/input/=, so we have to prepare them. Since all the files must have the same name, we cannot use the same directory, so we are going to create directories with names =input0=, =input1=, =input2=, ..., =input299= and each of these directory will contain the pertinent =data.in= file. To do that, we can use a bash script like the next one:

 ''#!/bin/bash''

 n=0
 =cd= /path/to/input/
 =for= file =in= *.in  
 =do= 
   =mkdir= input=$n=
   =mv=  =$file= input=$n=/data.in 
   =echo= "$file -> input=$n=/data.in" >> file_map.txt
   n=$((n+1))  
 =done=

Last script simply creates a new directory and move into it the input file, renaming it as =data.in=. We have also added a extra line to create a file called =file_map.txt= that will include a list with the original and the new name and location for each file, that could be useful to identify later the outputs. Now we need to write the submit file:

 N     = 300
 ID    = $(Cluster).$(Process)
 fname = example3B

 =output=  = $(fname).$(ID).out
 =error=   = $(fname).$(ID).err                                                                                     
 =log=     = $(fname).$(Cluster).log                                                                       

 =universe=                = vanilla
 =should_transfer_files=   = YES
 =when_to_transfer_output= = ON_EXIT

 =transfer_input_files=    = /path/to/input/input$(Process)/data.in
 =transfer_output_files=   = data.out
 =transfer_output_remaps=  = "data.out=data$(ID).out"

 =executable=  = myprogram
 =arguments=   = ""

 =queue= $(N)

We have introduced a few changes in the submit file. Now we will use =transfer_input_files= to choose the proper =data.in= file according to the directory of each job. Output files will be copied to the same directory where the submission is done and since all of them will have the same name, we need to avoid that they will be overwritten using =transfer_output_remaps= command. With that command we will rename all output files to include the =ID=.

Sometimes we want that the output files will be located in the same directory where the related input file is placed. Then, since output files will be in different directories, there is no need to change their names. In these situations, we can remove the =transfer_output_remaps= command and use instead the =initialdir= command to specify that HTCondor should use a different directory for both input and output files in each execution (this will not affect the executable file):

 =initialdir=              =/path/to/input/input$(Process)
 =transfer_input_files=    = data.in
 =transfer_output_files=   = data.out


\\\

'''Note:''' Using known patterns and consecutive numbers as names of files makes very easy that you can specify input and output files in HTCondor, and you only need to use simple linux commands and/or bash scripts to rename these files (always keep a backup of your original files!). However, there are other ways to work with HTCondor if for any reason you do not want or you cannot change the names of your files.

Also remember that if you specify directories with =transfer_input_files= and =transfer_output_files= and they finish with a slash ("'''=/='''"), HTCondor will copy the content of the directories, but not the directory itself. That can be used to copy input or output files without knowing their names, we only need to place them in a pertinent directory structure, using a bash script like that presented in example 3B (but without changing the name of the files). Also if your application is able to use the =stdin= to get the name of the files, you can write those names in another file with a known pattern and then specify that file using a HTCondor =input= command.

Also you can add in your submit file some more commands that could be very useful when dealing with inputs and output files. For instance, =preCmd= and =postCmd= commands allow you to run scripts or shell commands before and after executing your program, respectively, so you can use them to rename or change the location of your input and output files, or any other operation that you may need. You have more information about these commands in [[ Submit File (HowTo) -> CondorHowTo#howto__prepostcmd]] section.


[[#example_files]]
!!  Example 4. A more complex example, step by step  [[[--^ Top -> #top--]]]

This example should be enough to run HTCondor jobs in most common situations. In this example, assume that we have an application called =myprogram= that accepts two arguments: the first one is the input file to be processed, where each line is a set of values that can be independently computed. The second argument is the name of the output file that will be created with the results.

In our example, we have a huge input file with several thousands of lines, called =data.in= and it takes quite a long time to be computed (several days), so we will use HTCondor to reduce this amount of time. What we are going to do is to split the huge input file in =N= smaller files with names =data0.in=, =data1.in=, ..., =data(N-1).in= and create a HTCondor job to process each one. 

The first step is to decide how many files we will create. Since each file will be a HTCondor job, this is a critical step, we have to make our decision according to next criteria:
# We should create a relatively large number of jobs, at least a few hundreds of them. If we split our input in just 2 files, that means that there will be only 2 jobs to be executed by HTCondor, so the maximum speedup we could get is 2 (our results will be ready in half time compared to a normal serial execution). But if we generate 100 hundreds jobs, then we could get a time factor reduction of 100x, or 500x if we generate 500 jobs... Of course, this is always a theoretical limit, it is almost impossible to reach it (all jobs have several overheads, probably there will be more users running jobs with HTCondor, the number of idle machines is always changing, your jobs could be evicted and restarted later, etc.), but generating a large number of jobs will increase your chances to get your results in less time. If you are wondering how much speedup you can get, on average HTCondor has around 350 idle slots at working hours, but at nights or weekends there could be peaks of about 600 idle slots. Anyway, you can generate as many jobs as you want, even several thousands of them, HTCondor will manage it and run your jobs when slots get idle. A large number of short jobs could be more efficient than a low number of long ones, but also bear in mind that transferring input and output files consumes resources and time: if your jobs need that HTCondor transfers many/long files to/from remote machines, then you may need to significantly reduce the number of jobs to avoid overloading the network and also to decrease the total time consumed by those file transfers.
# Most times the number of jobs has to be chosen according to the estimation of the time a job needs to be processed. We should not choose jobs that only last few seconds/minutes, because executing a job has an overhead (communications, creating the execution environment, transferring files, etc.), so if your job is too short, it could happen that this overhead takes more time than executing your program. On the other hand, if your jobs need several hours to be finished, it is likely they will be suspended/killed and restarted from the beginning many times, so the final consumed time could be really high. There is not a fixed rule about the duration of your jobs and sometimes you cannot choose it... But if you can choose, a job that needs from 10 to 30 minutes to be done should be fine (the bigger the files you need to transfer, the larger the jobs should be to reduce the total number of jobs and, therefore, the amount of file transfers). When possible, avoid those large jobs that need more than one hour to be processed, unless heavy file transfers are involved (if files are so big, consider using a share location like =scratch= instead of copying them to all remote machines, and then [[add a limit -> CondorHowTo#howto_limit]] to the number of concurrent jobs).


For instance, our original =data.in= file has 97564 lines and we will try to follow these recommendations when splitting it. Before choosing the number of jobs, we need to run some tests to have an estimation about how much time our program needs to process different inputs. For example, suppose we have already done those tests and, on average, our program needs about 4 second per line, so it can process 250 lines in around 17 minutes. If we split our huge file in smaller ones of 250 lines each, then we will have 391 files. That means 391 jobs will be generated, what is a good amount. Since we just need to transfer one input file and one output file and their sizes will be about just a few KB, this time it is not needed to think about the overhead of file transfers. If we are really lucky and HTCondor is able to immediately execute all our jobs at the same time, then we could get our results in about 17 minutes. It is almost sure that will not happen, we may need to wait some more minutes or hours, but we will get our results much faster than a serial execution that needs 97564 * 4 seconds to be processed, almost 5 days. 

So, we have finally chosen =N = 391=. Next step should be to split our file, that could be easily done with Linux commands like =split= or =awk=. For example, see next command:
  =awk= '{filename = "=A=" int((NR-1)/=B=) "=C="; print >> filename}' =D=
where =A=: prefix of the output file, =B=: number of lines to split, =C=: postfix of the output file and =D=: input file. When used, this command will split the input file (=D=) in files containing a number of =C= lines each and named =A=0=C=, =A=1=C=, =A=2=C=, ...

Then we will use that command in the next way: =A = data=, =B = 250=, =C = .in= and =D = data.in=
  [...]$ =awk= '{filename = "data" int((NR-1)/250) ".in"; print >> filename}' data.in

After executing the previous command, we will have 391 files of 250 lines each (except the last one), from =data0.in= to =data390.in=, what means we are going to execute 391 jobs. Then, we will also name our output files in the same way: =data0.out=, =data0.out=, ..., =data390.out=. At this point we are ready to create our submission file, we only need to specify what the executable is, the arguments, the inputs and outputs and where to find them.

If for any reason you want to include a header, you can use next command:
  [...]$ =sed -i= '=1i=Write your header here...' data*.in

To process all files we need to change the arguments in each execution. We could explicitly do that writing =N= times the proper =argument= and =queue= commands in the submit file, but this is a very awful way to solve the problem, besides other factors. A much simpler (and ''elegant'') way is to use a '''loop''', from 0 to 390 (=N - 1=), to generate all the arguments. To simulate this loop, we could try to write an script (for instance, a bash script) in order to generate =N= submit files where each one has the correct arguments, but again this is not the best solution: managing 391 HTCondor submit files is bothersome and, even worse, efficiency will be reduced: every time you do a submission, HTCondor will create a ''Cluster'' for that execution, what involves an overhead, so we should try to create only one cluster with =N= jobs rather than =N= clusters with only one job each. To solve this problem, HTCondor offers us a simple way to process this loop: we can use the =$(Process)= macro, so each job will have a different value from =0= to =N-1=. Then, the HTCondor submit file should be similar to the following one:


 ''# Set number of jobs to execute''
 N    = 391

 ID = $(Cluster).$(Process) 
 =output=  = myprogram.$(ID).out
 =error=   = myprogram.$(ID).err
 =log=     = myprogram.$(Cluster).log

 =universe=                = vanilla
 =should_transfer_files=   = YES
 =when_to_transfer_output= = ON_EXIT
 =transfer_input_files=    = data$(Process).in
 =transfer_output_files=   = data$(Process).out

 =executable=    = myprogram
 =arguments=     = "data$(Process).in  data$(Process).out"

 =queue= $(N)

The final submit file shown above is very simple and easy to understand. The first blocks were explained in the previous example, we just defined a new macro called =ID= to make some commands shorter. Then, =should_transfer_files= command is again used to force the file transfers and we have added a =when_to_transfer_output= command to tell HTCondor that the files should be transferred after completion.

The key of this example is the =transfer_input_files= and =transfer_output_files= commands. With these two commands we tell HTCondor which files have to be copied to the remote machine before executing the program and which files have to be copied back to the machine where the submission was done as results. Before queueing the jobs, we use the =arguments= command to specify the name of the input file (first argument) and the output file (second argument). 

And that is all: HTCondor will expand =$(Process)= macro in every job, so it will copy the file =data0.in= to the remote machine where job number =0= will be executed with arguments "=data0.in data0.out=" and, afterwards, will copy =data0.out= back to the submit machine, and so on with all remaining jobs till =N - 1=. 

!!! Some remarks to this example:

**  '''NOTE 1''': We are supposing that our inputs and outputs are not in a shared directory so it will not be accessible from other machines where your jobs will be run. It might be possible to solve these problems changing your application and using shared locations, like those in =/net/<your_machine>/scratch/...=, but this solution is highly not recommendable, moreover if you are using big files or many of them and your application is constantly accessing them to perform read/write operation. If you do so, a big amount of concurrently access may produce locks and a considerable slowdown in your and others' computer's performance. To avoid that, it is a much better idea to copy your input files to the target machine where your job will be run and then bring the results back to your machine. You do not need to take care of this copying process, HTCondor will do all the work for you, the only thing you need to do is use HTCondor commands =transfer_input_files=  and =transfer_output_files= to specify where files and directories to be copied are located. If you cannot avoid intensive accesses to your files located in shared resources like =scracth=, then consider the possibility of [[limiting your concurrent running jobs -> CondorHowTo#howto_limit]].

**  '''NOTE 2''': We are assuming here that all inputs and outputs are located in the same directory where the submission will be done. If that is not true, we can specify absolute or relative path (to the submission directory) in the =transfer_input_files= command, or use =initialdir= command as explained in the previous example, affecting to both input and output files. Remember that when using =transfer_input_files= or =transfer_output_files= you can also specify a directory to be copied to the remote machine. If you specify a long path, HTCondor will not create it all, just the last level (if you want to copy only the content and not the directory itself, add an slash at the end of the directory). For instance, suppose that =data_inputs= directory only contains a file called =data1.dat=:

(:table border=1 cellpadding=5 cellspacing=0 width=70% align=center:)
(:cell align=center valign=middle :) '''Command''' 
(:cell align=center valign=middle :) '''Exec Dir @ remote machine'''
(:cellnr  valign=middle :) =transfer_input_files= = =/path/to/inputs/data_inputs/data1.dat=
(:cell align=center valign=middle :) =data1.dat=
(:cellnr  valign=middle :) =transfer_input_files= = =/path/to/inputs/data_inputs=
(:cell align=center valign=middle :) =data_inputs= (and its content)
(:cellnr  valign=middle :) =transfer_input_files= = =/path/to/inputs/data_inputs/=
(:cell align=center valign=middle :) =data1.dat=
(:tableend:)

->Please, check next example for more details or %newwin%[[Condor documentation about transferring files -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_5Submitting_Job.html#sec:file-transfer]]. If you have doubts about where your input files will be located in the remote machine, it could be useful to submit a job with executable =tree= to see where files and directories will be placed when executing.


**  '''NOTE 3''': Another assumption is that we can specify arguments to our executable. That is now always true, it could happen that the executable is expecting to find files with predefined names, for example, =data.in= as input and it will generate =data.out= as output. If we cannot change this behaviour (for instance, we do not have access to the source code), we need to do some small modifications. The first step is to change our =awk= script for splitting files in order to place every resulting file in a different directory (=dataXX/=), but with the same name (=data.in=), so our inputs will be located in =data0/data.in=, =data1/data.in=, ..., =data390/data.in=. Then, we will add next commands in the submit file (following lines should be placed before the =queue= command):
   =Initialdir=  = data$(Process)
   =arguments=   = ""

-> With =Initialdir= command we are specifying that HTCondor has to search for the inputs in that directory (it will be different for each job), and output files will be also placed in that directory. For instance, job with ID =34= will transfer the input file located in =data34/data.in= and after the execution it will place the output file in =data34/data.out=. 

-> But we may want to have all our output files in the same directory to process all of them together. That could be achieved removing the =Initialdir= command and changing our submit file with next commands:  
    =transfer_input_files=    = data$(Process)/data.in
    =transfer_output_files=   = data.out
    =transfer_output_remaps=  = "data.out=data$(Process).out"
    =arguments=               = ""

->  With the new =transfer_input_files= command we specify that every =data.in= have to be copied from the proper directory. Then we use =transfer_output_files= to copy back the output file, but since all the output files will have the same name, we need to use =transfer_output_remaps= to change the name and avoiding all jobs overwriting the same file, so they will be renamed to =data0.out=, =data1.out=, ... =data390.out= (this command ONLY works with files, NOT with directories). Finally, we do not specify any arguments since the names of the files are those expected by the executable. 

-> Additionally, you can use =+PreCmd= and/or =+PostCmd= commands to run shell commands/scripts/programs before and/or after your main executable, so you can use this commands to rename or move your input and output files. See [[Submit File (HowTo) -> CondorHowTo#howto_prepostcmd]] section for more information.

**  '''NOTE 4''': If we want to change the number of lines per file, we do not need to change the submit file. For instance, now we want files with 350 lines so after running the =awk= command, we will have 279 input files and =N = 279=. Then we can use the same submit file and change the value of =N= when doing the submission using the =-append= options, that allows us to change the value of existing macros or define new ones:


   [...]$ =condor_submit= myprogram.submit =-append= 'N = 279'


[[#example_complex_macros]]
!!  Example 5. Working with more complex loops and macros  [[[--^ Top -> #top--]]]

After studying simple loops where we directly use the =$(Process)= macro from =0= to =N -1=, we will see some more complex situations where we need to do some operations with macros. Now assume that we have developed an application called =myprogram= that needs the following '''inputs''':
# We have to specify next arguments, =-init XX -end YY=:
** First job (ID: =0=):  =-init 0 -end 99=
** Second job (ID: =1=): =-init 100 -end 199=
** ...
** Last job (ID: =N-1=): =-init [N*100] -end [((N+1)*100)-1]= 
# The application expects to find the following files and directories located {+in the same directory where it will run+}, although right now they are in different locations:
## a common file (it does not depend on the arguments) called =data.in= located in =/path/to/inputs/data.in=
## all files located inside =/path/to/inputs/data_inputs= directory
## a specific directory called =specific-XXX/= (where =XXX= is the value of the =-init= argument) located in =/path/to/inputs/specific-XXX/=


With these inputs, our program will produce next '''outputs''' in the same directory where it was executed:
# A file called =data.out=
# A directory called =data_outputs-XXX= (where =XXX= is the value of the =-init= argument) with many files inside

We will present the HTCondor submit file for this situation and it will be discussed right after:

 ''# Set number of jobs to execute''
 N  = 50     
 ID = $(Cluster).$(Process) 

 =output=  = myprogram.$(ID).out
 =error=   = myprogram.$(ID).err
 =log=     = myprogram.$(Cluster).log
 =should_transfer_files=   = YES
 =when_to_transfer_output= = ON_EXIT
 =universe=                = vanilla

 ''# Step in arguments'' 
 STEP = 100   
 init = $$([$(Process) * $(STEP)])
 end  = $$([(($(Process) + 1) * $(STEP)) -1])

 BDIR                    = /path/to/inputs
 =+TransferInput=          = "$(BDIR)/data.in, $(BDIR)/data_inputs/, $(BDIR)/specific-$(init)"
 =+TransferOutput=         = "data.out, data_outputs-$(init)"
 =transfer_output_remaps=  = "data.out=data-$(init).out"

 =executable=    = myprogram
 =arguments=     = "-init $(init) -end $(end)"

 =queue= $(N)

\\
Let's skip the first and second blocks since we have explained those commands in previous examples (we have just set =N = 50= in this example, we can change this value when submitting if we use =-append= option). In the third block we have used a special syntax =\$\$(\[...\])= to define macros =init= and =end=. With this syntax we specify that we want to evaluate the macro, allowing arithmetic operators like =*=, =/=, =+=, =-=, =%=, ... If you need complex macros, there is a number of %newwin%[[operators, predefined functions, etc. -> http://research.cs.wisc.edu/htcondor/manual/v8.6/4_1HTCondor_s_ClassAd.html#SECTION00512400000000000000]] (for instance, =eval()= could be very helpful, or other functions to manipulate strings, lists, ...) and also other %newwin%[[predefined macros -> http://research.cs.wisc.edu/htcondor/manual/v8.6/3_5Configuration_Macros.html#SECTION00451800000000000000] that you can use to generate random numbers, randomly choose one value among several of them, etc. 

Most HTCondor commands will use the resulting value when expanding these macros, but unfortunately that does not work for all commands. For instance, =transfer_input_files= and =transfer_output_files= commands do a simple expansion, but do not evaluate the operations, so instead of getting the directory =specific-100=, you will get =specific-$$([$(1) * $(100)])=. To avoid that, we have to use other commands that correctly expand complex macros and have similar functionality. In this case =+TransferInput= and =+TransferOutput= respectively do the same with similar syntax (they expect strings, so you have to use quotes). We have also defined a simple macro =BDIR= to avoid writing the path several times.

According to the written commands in the third and fourth blocks, the behaviour of this submit file will be the next one:
*'''Inputs''': when our program runs in other machine(s), it will find next structure in its local directory: =data.in= (file), all the content of =data_inputs= (but NOT the directory itself) and =specific-XXX= (directory and its content).
*'''Outputs''': On the outputs side, once all jobs have finished, we should find in our machine the next structure in the same directory where we did the submission: =data.out= (file) and one directory called =data-XXX= for each job (where =XXX= is the value of each =-init= argument). Note that we have a problem because our application always name the result file with =data.out=, so all jobs will override it in destination. To avoid that, we use the =transfer_output_remaps= command to specify that  =data.out= file has to be renamed to =data-XXX.out= and then all results will be copied in different files (this command ONLY works with files, NOT with directories). 
>><<



[[#some_more_commands]]
!! Some more useful commands and info

If you have some issues when creating submit files or running your jobs, please, check the [[HOWTOs -> CondorHowTo]] and [[FAQs -> CondorFAQs]] pages, since there you could find some more examples or visit the [[useful commands -> CondorUsefulCommands]] page. Much more information is available at the %newwin%[[official documentation -> http://research.cs.wisc.edu/htcondor/]] about HTCondor and the %newwin%[[Howto recipes -> https://htcondor-wiki.cs.wisc.edu/index.cgi/wiki?p=HowToAdminRecipes]]. If you need further support, just contact us.

\\\


!! Check also:
**  [[HTCondor(1): Introduction -> Condor]]
**  [[HTCondor(2): Useful Commands -> CondorUsefulCommands]]
**  HTCondor(3): Submit files (description & examples)
**  [[HTCondor(4): Submit files (HowTo) -> CondorHowTo]]
**  [[HTCondor(5): FAQs -> CondorFAQs]]
**  [[HTCondor(6): HTCondor and IDL -> CondorAndIDLVirtualMachine]]

\\\

\\\

[[Category.HOWTOs | Section: HOWTOs ]]

*** Submit files (HowTo)
[[#top]]
>>frame<<
(:table border=0 cellpadding=5 cellspacing=0 width=100% :)
(:cell align=center valign=middle :) [[Introduction -> Condor]]
(:cell align=center valign=middle :) [[Useful Commands -> CondorUsefulCommands]]
(:cell align=center valign=middle :) [[Submit files (desc. & examples) -> CondorSubmitFile]]
(:cell align=center valign=middle :) '''Submit files (HowTo)'''
(:cell align=center valign=middle :) [[FAQs -> CondorFAQs]]
(:cell align=center valign=middle :) [[HTCondor and IDL -> CondorAndIDLVirtualMachine]]
(:tableend:)
>><<


(:title HTCondor(4): Submit files (HowTo) :)
! HTCondor submit files (HowTo) 

[[#example_howto]]
!! Submit file HowTo

HTCondor has a huge set of commands that should cover most possible scenarios. It is impossible to describe here all of them, but you can read the official documentation to get further information (there are many of these commands at the %newwin%[[=condor_submit= page -> http://research.cs.wisc.edu/htcondor/manual/v8.6/condor_submit]]. Just to complement [[some of the examples -> CondorSubmitFile#templates_examples]], we will mention here a few useful commands that can be added to the submit file when needed. You can also find more details about these and other commands at the [[FAQs page -> HOWTOs.CondorFAQs]].


** [[#howto_requirements | How to ... add requirements on the target machines where my jobs will be run?]]
** [[#howto_prefs        | How to ... add preferences on the target machines where my jobs will be run?]]
** [[#howto_env          | How to ... get/set environment variables?]]
** [[#howto_notify       | How to ... control HTCondor notifications?]]
** [[#howto_prepostcmd   | How to ... run some shell commands/scripts/programs before/after our application?]]
** [[#howto_priority     | How to ... specify the priority of your jobs?]]
** [[#howto_failing      | How to ... deal with jobs that fail?]]
** [[#howto_limit        | How to ... limit the number of concurrent running jobs?]]
** [[#howto_complex_op   | How to ... do some complex operations in my submit file?]]
** [[#howto_nestloop     | How to ... work with nested loops?]]
** [[#howto_runintime    | How to ... program my jobs to begin at a predefined time?]]
** [[#howto_dagman       | How to ... run jobs that have dependencies among them?]]
** [[#howto_attr         | How to ... know the attributes of the machines where our jobs are run?]]



[[#howto_requirements]]
!!! How to ... add requirements on the target machines where my jobs will be run?  [[[--^ Top -> #top--]]]
If your program has some limitations (memory, disk, libraries, etc.) and cannot run in all machines, you can use =requirements= command to tell HTCondor what those limitations are so it can execute your jobs only on machines that satisfy those requirements. If you try next command =condor_status -long <your_machine>= in your shell, it will list all the parameters that HTCondor has about each slot of your machine, and most of those parameters can be used to add requirements. Conditions and expressions could be as complex as needed, there is a number of %newwin%[[operators, predefined functions, etc. -> http://research.cs.wisc.edu/htcondor/manual/v8.6/4_1HTCondor_s_ClassAd.html#SECTION00512300000000000000]] that can be used. For memory, disk and CPUs you can also use =request_memory=, =request_disk= and =request_cpus=, respectively.  

For example, if your program needs at least 1.5 GB of RAM and 5 GB of free space in disk, and due to library dependencies it can only run on machines with Linux Fedora17 or above, add next commands in your submit file:
 =request_disk=   = 5 GB
 =request_memory= = 1.5 GB
 =requirements=   = (UtsnameSysname == "Linux") && (OpSysName == "Fedora") && (OpSysMajorVer >= 17)
Be careful when specifying the values since the default unit for =request_disk= is KB and MB for =request_memory=. It is much better to always specify the unit (=KB= or =K=, =MB= or =M=, =GB= or =G=, =TB= or =T=).


'''Caution!''': Be careful when choosing your restrictions, using them will reduce the amount of available slots for your jobs so it will be more difficult to execute them. Also check that you are asking for restrictions that can be satisfied by our current machines, or your jobs will stay always in idle status (you can check the reasons why a job is idle using =condor_q -analyze <job.id>=). Before adding a requirement, always check if there are enough slots that satisfy it. For instance, to see which slots satisfy the requirements of this example, use next command (you can add flag =-avail= to see only the slots that could execute your job at this moment):

 [...]$ =condor_status= -constraint '(UtsnameSysname == "Linux") && (OpSysName == "Fedora")  
                    && (OpSysMajorVer >= 17) && (Memory > 1536)  && (Disk >= 5120000)'

If you already know which machines are not able to run your application, you can force HTCondor to avoid them... or the opposite: run your application only on some machines (see [[this FAQ -> HOWTOs.#howto_failing ]] where this is explained).

\\\

[[#howto_prefs]]
!!! How to ... add preferences on the target machines where my jobs will be run?  [[[--^ Top -> #top--]]]

Preferences are similar to requirements, but they do not limit the machines (you can use both preferences and requirements in the same submit file). HTCondor will try to satisfy your preferences when possible, assigning a rank to the available machines and choosing those with higher value. For example, we would like to use slots with at least 4GB of RAM if they are available and the more available disk space, the better. Then commands to add should be the following ones:

 =Rank=  = Disk && (Memory >= 4096)

Rank is evaluated as a float point expression, and always higher values are the better ones. Then, you can do arithmetic operations to emphasize some parameters. For example, the first expression will consider the floating point speed but will give more importance to run on machines with my same Operating System, while the second expression will choose machines with higher values of RAM, and those with also more than 100GB of disk will have 200 extra ''points'':

 =Rank=  = kflops + (1000000 * (TARGET.OpSysAndVer == MY.OpSysAndVer))
 =Rank=  = Memory + (200 * (Disk >= 102400))   

\\\

[[#howto_env]]
!!! How to ... get/set environment variables?  [[[--^ Top -> #top--]]]
If you application needs them, use the  =getenv= command and HTCondor will create a copy of your environment variables {+at the submitting time+} so they will be available for your program on the target machine. Also you can create/modify environment variables if needed with the =environment= command. The environment variables can be also used in the submit file using the =ENV= command. 

For example, add next commands if you want that your executable can access your environment at the submitting time, then set variables called =working_dir= and =data_dir= pointing to some directories, and finally create a macro called =home_dir= that contains your home directory to be used in your submit file:

 =getenv=        = True
 =environment=   = "working_dir=/path/to/some/place data_dir=/path/to/data"
 home_dir      = $ENV(HOME)

If you want to run your python program using HTCondor, you might need to define some environment variables, please, [[read this FAQ -> HOWTOs.CondorFAQs#python-fedora ]].

\\\


[[#howto_notify]]
!!! How to ... control HTCondor notifications?  [[[--^ Top -> #top--]]]
If you are submitting a large set of jobs, receiving notifications from all of them can be annoying. You can set the email address and the type of the notifications that you want to receive. For example, to send notifications to =someaddress@iac.es= only in case of errors, use following commands: 

 =notify_user=   = someaddress@iac.es
 =notification=  = Error

=notify_user= changes the email address used to send notifications, if you need to add more addresses, you can use =email_attributes= command. With =notification= command we tell HTCondor when it should send those notifications, it could be set to =Never=, =Complete=, =Error= or =Always=; we recommend you use =Error=.

\\\

[[#howto_prepostcmd]]
!!! How to ... run some shell commands/scripts/programs before/after our application?  [[[--^ Top -> #top--]]]
If your application needs some pre- or post-processing, you can use =+PreCmd= and =+PostCmd= commands to run it before and after your main executable, respectively. For example, these commands may be useful if you need to rename or move input or output files before or after the execution. You can also use them for debugging purpose, for instance, use =tree= command to check where the input/output files are located: 

 =+PreCmd=        = "tree"
 =+PreArguments=  = "-o tree_before.$(Cluster).$(Process).txt"
 =+PostCmd=       = "my_postscript.sh"
 =+PostArguments= = "-g"

 =should_transfer_files=  = YES
 =transfer_input_files=   = my_postscript.sh, /usr/bin/tree
 =transfer_output_files=  = tree_before.$(Cluster).$(Process).txt

Remember that you have to add those scripts/programs to the list of files to be copied with =transfer_input_files= command, and also check that your submit file contains the following command: =should_transfer_files = YES=. When using a shell command (like =tree=), you can get its location using the command =which=. For instance, =which tree= will show =/usr/bin/tree=, this is the path you should add to  =transfer_input_files= command. 

\\\

[[#howto_priority]]
!!! How to ... specify the priority of your jobs?  [[[--^ Top -> #top--]]]
HTCondor uses two different types of priorities: '''job priority''' (which of your jobs will run first) and '''users priority''' (which users will run their jobs and how many of them).

[+'''Job priority'''+]

If some of your jobs/clusters are more important than others and you want to execute them first, you can use the =priority= command to assign them a priority (the higher the value, the higher priority). For instance, if you want to execute first the last jobs of a cluster (reverse order), you can use next command:
 =priority=      = $(Process)

Remember that after submitting your jobs, you can set or change their priority using the shell command =condor_prio=. 

[+'''Users priority'''+]

Whenever your jobs are being executed, your user priority is decreased (the more jobs are executed, the faster you lose priority). Users with best priority will run more jobs and they will begin sooner, so if your jobs are not so important or the queue is empty, you can use =nice_user= command to run them without wasting your priority. If you set this command to =True=, your jobs will be executed by a ''fake user'' with very low priority, so you will save your real priority (but it is likely your jobs will not be executed unless the queue is almost empty).
 =nice_user=     = True
Those jobs will be run with user =nice-user.<your_user>= and they will not change your user's priority (you can use shell command =condor_userprio -allusers= to see your and other users' priority).
\\\

Remember that using =condor_qedit= command you can change the attributes of your jobs after submitting them (see [[this FAQ -> HOWTOs.CondorFAQs#ch_submit]]). We can use this command to change the status of =NiceUser= attribute depending on how many slots are free (if there are many free slots, then we can set our jobs as ''nice'' to run them without affecting our priority, or the opposite, setting =NiceUser= to =false= when there are no free slots). For instance, use next commands to set all jobs belonging to Cluster ID =1234=:

  =[...]$ condor_q 1234 -af ProcId NiceUser=  ''#Check current status''
         0 false
         1 false
         ...

  =[...]$ condor_qedit 1234 NiceUser True=
         Set attribute "NiceUser".

  =[...]$ condor_q 1234 -af ProcId NiceUser=  ''#Check current status''
         0 true
         1 true
         ...

If user priority is a critical factor to you, you may want to periodically check the queue to change the =NiceUser= attribute according to the current status, setting it to =True= when you are the only active user or there is a large number of available slots, and set it to =False= when there are more active users or a few available slots. In order to simplify this process, we have developed a script that automatically performs those operations, you only need to specify your username or a particular =clusterID= (and optionally a minimum number of available slots) and it will change the =NiceUser= attribute to save your real priority as much as possible. You can copy the script from =/net/vial/scratch/adorta/htcondor_files/htcondor_niceuser.sh= and use it (or modify it) whenever you want. You can even periodically execute it using =crontab= (but please, do NOT run it too often to avoid overloading the system, every 30 or 60 minutes is fine). Run it with no arguments to get the description and syntax.

'''Notes''': 
** You can use =condor_qedit '''-constraint''' ...= to change the attributes of only some of your jobs.
** Condor can evaluate the attributes only when jobs begin to run, so new values may not affect the currently running jobs at the time of using =condor_qedit=, but they will be valid in jobs that begin to run after using the command.

\\\

[[#howto_failing]] 
!!! How to ... deal with jobs that fail?  [[[--^ Top -> #top--]]]
Sometimes jobs fail because there are problems when executing your program. It could happen that the problem is not in your program, but in the machine that executed it (a missing or misconfigured application, a library with a different version from the one you need, etc.). Then you should identify those problematic machines and use =requirements= commands in your submit file in order to block them, as is explained in [[this FAQ -> HOWTOs.CondorFAQs#blackholes]]. For example, to block machines with names =piston= and =loro= use only one of the next commands (both are equivalent): 

 =requirements= = ((UtsnameNodename =!= "piston") && (UtsnameNodename =!= "loro"))  
 =requirements= = '''!'''=stringListMember=(UtsnameNodename, "piston,loro")

You can also block all machines that satisfy a pattern. For instance, to avoid executing your jobs on those machines with names beginning with "k", "c" and "l", add next lines (you can specify more complex patterns using the %newwin%[[predefined functions and macros -> http://research.cs.wisc.edu/htcondor/manual/v8.6/4_1HTCondor_s_ClassAd.html#SECTION00512300000000000000]]):
  letter       = =substr=(toLower(Target.Machine),0,1)
  =requirements= = '''!'''=stringListMember=($(letter), "k,c,l")

Sometimes it is better to specify a list of machines where your application can run (and avoid any other that is not in that list). For that purpose, just use previous expressions after negating them with an ''exclamation mark'' "'''!'''" (or remove it if they were already negated).

After avoiding machines that are not able to run your program, you should submit again your jobs. But, please, execute {+only+} those jobs that failed (check [[this FAQ -> CondorFAQs#repeat]] to see how), do not execute again jobs that were already correctly executed to avoid wasting time and resources. For instance, add next command to only execute jobs with Process ID =0=, =13=, =25= and those from =37= to =44=:
   =noop_job= = '''!'''=( stringListMember=("$(Process)","0,13,25") || (($(Process) >= 37) && ($(Process) <= 44)) =)=
'''Note''': =noop_job= will ''not'' execute those jobs where the condition is =True=. Therefore, if you want to specify a list of jobs ''to be executed'', you need to ''negate'' your expression adding an exclamation mark at the beginning: =noop_job = '''!'''(...)=. On the other hand, if you want to specify a list of jobs that should ''not'' be executed, then use the expression without negating it.

Jobs that are not executed may stay in the queue with =Complete= status (when using =condor_q= you will see that =ST= column is =C=). To remove all =C= jobs from the queue, try next command in your shell (use the second one to remove {+only+} =Complete= jobs that belongs to cluster =XXX=):
  =condor_rm= -constraint 'JobStatus == 4'
  =condor_rm= -constraint 'JobStatus == 4 && clusterID == XXX'

\\\

Also, it could be interesting to avoid the '''black holes''': suppose that each of your jobs needs hours to finish, but they fail in an specific machine after a few minutes of execution time. That means that machine will be idle every few minutes, ready to accept another of your jobs, that will also fail, and this process may repeat again and again... sometimes a failing machine could even execute almost all your jobs... That is known as ''black hole''. To avoid it, we can force HTCondor to change machines when sending jobs. For that purpose add these lines to your submit file:

  ''#Avoid black holes: send to different machines''
  =job_machine_attrs= = Machine  
  =job_machine_attrs_history_length= = 5           
  =requirements= = $(requirements) && (target.machine =!= MachineAttrMachine1) && (target.machine =!= MachineAttrMachine2)

\\\
When there are problems with your jobs, you should receive an email with an error and some related information (if it was not disabled using =notification= command as explained above) and the job will leave the queue. You can change this behavior with =on_exit_hold= and/or =on_exit_remove= commands, forcing HTCondor to keep that job in the queue with status ''on hold'' or even as ''idle'' so it will be executed again:

(:table border=1 cellpadding=5 cellspacing=0 width=70% align=center:)
(:cell align=center valign=middle :) '''Command''' 
(:cell align=center valign=middle :) ''' True '''
(:cell align=center valign=middle :) ''' False '''
(:cellnr align=center valign=middle :) =on_exit_hold=
(:cell align=center valign=middle :) Stay in the queue with ''on hold'' status
(:cell align=center valign=middle :) Leave the queue
(:cellnr align=center valign=middle :) =on_exit_remove=
(:cell align=center valign=middle :) Leave the queue
(:cell align=center valign=middle :)  Stay in the queue with ''idle'' status (it can be executed again)
(:tableend:)
\\\

Last commands will be evaluated when jobs are ready to exit the queue, but you can force a periodic evaluation (using a configurable time) with commands like =periodic_hold=, =periodic_remove=, =periodic_release=, etc., and then decide if you want to hold/remove/release them according to your conditions. There are also some other commands to add a ''reason'' and/or a ''subcode'' when holding/removing/releasing these jobs. On the other hand, you can force your jobs to exit the queue when they satisfy a given condition using =noop_job=, or they stay in the queue even after their completion using =leave_in_queue= command (those jobs will stay in the queue with =Complete= status till you remove them using shell command =condor_rm=).


In the %newwin%[[ http://research.cs.wisc.edu/htcondor/manual/v8.6/condor_submit.html#condor-submit-on-exit-hold | official HTCondor documentation]] there are some examples about how to use these commands (all valid =JobStatus= could be displayed using shell command: =condor_q -help status=):

** With the next command, if the job exits after less than an hour (3600 seconds), it will be placed on hold and an e-mail notification sent, instead of being allowed to leave the queue:
   =on_exit_hold= = ((CurrentTime - JobStartDate) < 3600)

** Next expression lets the job leave the queue if the job was not killed by a signal or if it was killed by a signal other than 11, representing segmentation fault in this example. So, if it exited due to signal 11, it will stay in the job queue. In any other case of the job exiting, the job will leave the queue as it normally would have done. 
   =on_exit_remove= = ((ExitBySignal == False) || (ExitSignal != 11))

** With next command, if the job was killed by a signal or exited with a non-zero exit status, HTCondor would leave the job in the queue to run again:
   =on_exit_remove= = ((ExitBySignal == False) && (ExitCode == 0))

** Use the following command to hold jobs that have been executing (=JobStatus == 2=) for more than 2 hours (by default, all periodic checks are performed every 5 minutes. Please, contact us if you want a shorter period):
   =periodic_hold= = ((JobStatus == 2) && (time() - EnteredCurrentStatus) >  7200)

** The following command is used to remove all ''completed'' (=JobStatus == 4=) jobs  15 minutes after their completion:
   =periodic_remove= = ((JobStatus == 4) && (time() - EnteredCurrentStatus) >  900)

** Next command will assign again the ''idle'' status to ''on hold'' (=JobStatus == 5=) jobs  30 min. after they were held:
   =periodic_release= = ((JobStatus == 5) && (time() - EnteredCurrentStatus) >  1800)
[-'''IMPORTANT''': =periodic_release= command is useful when your program is correct, but it fails in specific machines and gets the ''on hold'' status. If that happens, this command will allow HTCondor to periodically release those jobs so they can be executed on other machines. But {+use this command with caution+}: if there are problems in your program and/or data, then your application could be indefinitely held and released, what means a big waste of resources (CPU time, network used in file transferring, etc.) and inconveniences for other users, be careful! (you can always remove your jobs using =condor_rm= command in your shell).-]

\\

When using =periodic_remove= or =periodic_hold= HTCondor submit commands, running jobs that satisfy the condition(s) will be killed and all files on remote machines will be deleted. Sometimes you want to get some of the output files that have been created on the remote machine, maybe your program is a simulation that does not converge for some sets of inputs so it never ends, but it still produces valid data and you want to get the output files. In those cases, do not use the mentioned submit commands because you will lose the output files, and use instead utilities like =timeout= in order to limit the time that your application can be running. When using this linux command, you specify the maximum time your program can run, and once it reaches that limit, it will be automatically killed. Then HTCondor will detect your program has finished and it will copy back the output files to your machine as you specified. Next example will show how to limit the execution of your program up to 30 minutes:

  ''# Some common commands above...''
  ...

  ''# Max running time (in seconds)''
  MAX_TIME = 30 * 60

  ''# Your executable and arguments''
  MY_EXEC = your_exec
  MY_ARGS = "your_arg1 your_arg2"

  ''# If your executable is not a system command, do not forget to transfer it!''
  =transfer_input_files= = your_inputs,$(MY_EXEC)
  ''# By default all new and modified files will be copied. Uncomment next line to indicate only specific output files''
  ''#=transfer_output_files= = your_outputs''

  =executable=          = /bin/timeout
  ''# Since timeout is a system command, we do not need to copy it to remote machines''
  =transfer_executable= = False
  =arguments=           = "$INT(MAX_TIME) $(MY_EXEC) $(MY_ARGS)"

  =queue= ...






\\\

[[#howto_limit]]
!!! How to ... limit the number of concurrent running jobs?  [[[--^ Top -> #top--]]]
There are some situations where it could be interesting to limit the number of jobs that can concurrently run. For instance, when your application needs licenses to run and few of them are available, or when your jobs access a shared resource (like directly reading/writing files located at =scratch=, too many concurrent access could produce locks and a considerable slowdown in your and others' computer performance). 

To deal with these situations, HTCondor is able to manage limits and apply them to running job. Different kinds of limits can be defined in the ''negotiator'' (the machine that decides which job will run on which slot), but, unfortunately, you cannot change its configuration (for obvious security reasons, only administrators can do that). If you want to use a limit, you can contact us so we will configure it, but there is an easier way to use this feature without changing the configuration: we have set a high default value (1000 units) for any undefined limit, so you only need to use a limit not defined yet and adjust the number of consumed units per job. For example, suppose that you would like to limit your concurrent running jobs to 20: then you only need to specify that every job consumes 50 units of that limit (1000 / 20 = 50). In this way no more than 20 jobs could concurrently run. 

The command used to specify limits is =concurrency_limits = XXX:YYY=, where =XXX= is the name of the limit and =YYY= is the number of units that each job uses. You can use any name for the limit, but it should be unique, so we recommend you include your username in it. 

** For instance, if your username is =jsmith= and you want to specify a limit of 12 running job (1000 / 12 ~= 83 units/job), just add next line to your submit file:
     =concurrency_limits= = jsmith:83

** Previous command will affect all your jobs that use that limit, even in different submissions. If you want to set limits that are only applied to each submission, you can use a combination of your username and the cluster ID in the name of the limit:
     =concurrency_limits= = jsmith$(Cluster):83

** If you need it, you can use several limits and specify them in the same command line, using ''commas'' to build the list of limits and consumed units per job. For instance, next line will limit to 12 the number of running jobs in this submission and to 25 (1000 / 25 = 40) the number of your total running jobs where the common limit =jsmith_total= has been used:
     =concurrency_limits= = jsmith$(Cluster):83,jsmith_total:40

** If you are executing jobs with '''IDL without the IDL Virtual Machine''', then each job will be using one license. Since the total amount of licenses is limited, you must add next line in your submit file:
     =concurrency_limits= = idl:40

\\

Limits can be changed after jobs are submitted using =condor_qedit= command. For instance, we want to change the limit that we have previously set to =jsmith:83= (12 concurrent jobs) to =jsmith:50= (20 concurrent jobs) in all jobs belonging to Cluster with ID =1234=. Then use next commands:
  =[...]$ condor_q 1234 -af ProcId ConcurrencyLimits=  ''#Check current limit''
         0 "jsmith:83"
         1 "jsmith:83"
         ...

  =[...]$ condor_qedit 1234 ConcurrencyLimits '"jsmith:50"'=
         Set attribute "ConcurrencyLimits".

  =[...]$ condor_q 1234 -af ProcId ConcurrencyLimits=  ''#Check current limit''
         0 "jsmith:50"
         1 "jsmith:50"
         ...

Values may have to be specified using quotes; be careful if your value is a string since you will be need to combine simple and double quotes, like ='"..."'= (see example above). 

'''Note''': HTCondor may evaluate the attributes only when jobs begin to run, so new values may not affect the currently running jobs at the time of using =condor_qedit=, but they will be valid in jobs that begin to run after using the command.

\\\

[[#howto_complex_op]]
!!! How to ... do some complex operations in my submit file?  [[[--^ Top -> #top--]]]
If you need to do some special operations in your submit file like evaluating expressions, manipulating strings or lists, etc. you can use
the '''predefined functions''' and some '''special macros''' that are available in HTCondor. They are specially useful when defining conditions used in commands like =requirements=, =rank=, =on_exit_hold=, =noop_job=, etc. since they will allow you to modify the attributes received from the remote machines and adapt them to your needs. We have used some of these predefined functions in our examples, but there are many others that could be used: 
** evaluate expressions: =eval()=, ... 
** flow control: = ifThenElse()=, ...
** manipulate strings : =size()=, =strcat()=, =substr()=, =strcmp()=, ... 
** manipulate lists: =stringListSize()=, =stringListSum()=, =stringListMember()=, ...
** manipulate numbers: =round()=, =floor()=, =ceiling()=, =pow()=, ...
** check and modify types: =isReal()=, =isError()=, =int()=, =real()=...
** work with times: =time()=, =formatTime()=, =interval()=, ...
** random: =random()=, =$RANDOM_CHOICE()=, =$RANDOM_INTEGER()=, ...
** etc. 

Check the documentation to see the complete list of %newwin%[[predefined functions -> http://research.cs.wisc.edu/htcondor/manual/v8.6/4_1HTCondor_s_ClassAd.html#SECTION00512400000000000000]], and also the %newwin%[[special macros -> http://research.cs.wisc.edu/htcondor/manual/v8.6/3_5Configuration_Macros.html#SECTION00451800000000000000]].

\\\

[[#howto_nestloop]]
!!! How to ... work with nested loops?  [[[--^ Top -> #top--]]]
You can use =$(Process)= macro to simulate simple loops in the submit file and use the iterator to specify your arguments, input files, etc. However, sometimes simple loops are not enough and nested loops are needed. For example, assume you need to run your program with the arguments expressed in the next pseudocode:

 MAX_I = 8
 MAX_J = 5

 =for= (i = 0; i < MAX_I; i++)
   =for= (j = 0; j < MAX_J; j++)
     ./myprogram -var1==i= -var2==j=

To simulate these 2 nested loops, you will need to use next macros in your HTCondor submit file:

 MAX_I = 8 
 MAX_J = 5
 N = MAX_I * MAX_J
 ...    
 I = ($(Process) / $(MAX_J))
 J = ($(Process) % $(MAX_J))
 ...
 =executable= = myprogram
 =arguments=  = "-var1=$=INT=(I) -var2=$=INT=(J)"
 =queue= $(N)

Last code will produce a nested loop where macro =$(I)= will work like the external iterator with values from =0= to =7=; and =$(J)= will be the internal iterator with values from =0= to =4=.

\\

If you need to simulate 3 nested loops like the next ones:
 =for= (i = 0; i < MAX_I; i++)
   =for= (j = 0; j < MAX_J; j++)
     =for= (k = 0; k < MAX_K; k++)
       ...

then you can use the following expressions:
 N = $(MAX_I) * $(MAX_J) * $(MAX_K)

 I = ( $(Process) / ($(MAX_K)  * $(MAX_J)))
 J = (($(Process) /  $(MAX_K)) % $(MAX_J))
 K = ( $(Process) %  $(MAX_K))

 =executable= = myprogram
 =arguments=  = "-var1 $=INT=(I) -var2 $=INT=(J) -var3 $=INT=(K)" ...
 =queue= $(N)

\\\

[[#howto_runintime]]   
!!! How to ... program my jobs to begin at a predefined time?  [[[--^ Top -> #top--]]]
Sometimes you may want to submit your jobs, but those jobs should not begin at that moment (maybe because they depend on some input data that is automatically generated at any other time). You can use =deferral_time= command in your submit file to specify when your jobs should be executed. Time has to be specified in ''Unix epoch time'' (the number of seconds elapsed since 00:00:00 on January 1, 1970, Coordinated Universal Time), but, do not worry, there is a linux command to get this value:

  =date= --date "MM/DD/YYYY HH:MM:SS" +%s

For instance, we want to run a job on April 23rd, 2016 at 19:25. Then, the first step is to get the epoch time:
  [...]$ =date= --date "04/23/2016 19:25:00" +%s

Our value is =1461435900=, so we only need to add next command to the submit file:
  =deferral_time= = 1461435900

Bear in mind that HTCondor will run jobs at that time according to remote machines, not yours. If there are wrong dates or times in remote machines, then your jobs could begin at other dates and/or times.

Also you can add expressions, like the next one to run your jobs one hour after the submission:
  =deferral_time= = (CurrentTime + 3600)

It may happen that your job could not begin exactly at that time (maybe it needs that some files are transferred and they are not ready yet), and in that case HTCondor may kill your job because the programmed time has expired and your job is not already running. To avoid that, you can specify a ''time window'' to begin the execution, a few minutes should be enough. For instance, add next command to tell HTCondor that your job could begin up to 3 minutes (180 seconds) after the programmed time:
  =deferral_window= = 180

'''Important:''' When you submit your programmed jobs, HTCondor will check which machines are able to run them and once the match is done, those machines will wait for the programmed time and will not accept any other jobs (actually, it will show ''Running'' status while waiting for the programmed time). That means a considerable loss of resources that should be always avoided. Using =deferral_prep_time= command we can specify that HTCondor could use those matched machines till some time before really running your jobs.

Then, add next lines to begin your jobs on April 23rd, 2016 at 19:25, specifying that they can begin up to 3 minutes after that date and that HTCondor could run other jobs on the matched machines till one minute before the programmed time:

  =deferral_time=      = 1461435900
  =deferral_window=    = 180
  =deferral_prep_time= = 60

HTCondor also allows you to use more powerful features, like specifying jobs that will be  periodically executed at given times using the ''CronTab Scheduling'' functionality. Please, read the %newwin%[[Time Scheduling for a Job Execution -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_13Time_Scheduling.html]] section in the official documentation to get more information. 

\\\

[[#howto_dagman]]
!!! How to ... run jobs that have dependencies among them?  [[[--^ Top -> #top--]]]
If your jobs have dependencies related to inputs, outputs, execution order, etc., you can specify these dependencies using a ''directed acyclic graph (DAG)''. HTCondor has a manager (called %newwin%[[http://research.cs.wisc.edu/htcondor/manual/v8.6/2_10DAGMan_Applications.html | DAGMan]]) to deal with these jobs. 

First, you have to create a DAG input file, where you specify the jobs (including the respective HTCondor submit file for each one) and the dependencies. Then, you submit this DAG input file using =condor_submit_dag <dag_file>=. Next code describes a basic example of DAG file where job A depends on B and C, that depend on D (diamond shape).

 # File name: diamond.dag
 #
 JOB  A  condor_A.submit
 JOB  B  condor_B.submit 
 JOB  C  condor_C.submit	
 JOB  D  condor_D.submit
 PARENT A CHILD B C
 PARENT B C CHILD D


 [...]$ ='''condor_submit_dag'''= diamond.dag

Examples about working with HTCondor DAGMan can be found in the %newwin%[[http://research.cs.wisc.edu/htcondor/manual/v8.6/2_10DAGMan_Applications.html#SECTION003102000000000000000 | Official documentation]] mentioned above. You can also try the easy example located at the end of [[this page -> http://research.iac.es/sieinvens/SINFIN/Condor/curso/course/node7.php]] used in a course about HTCondor imparted by SIE some years ago ([[solution here -> http://research.iac.es/sieinvens/SINFIN/Condor/curso/course/node9.php#SECTION00095000000000000000]]).

\\\

[[#howto_attr]]
!!! How to ... know the attributes of the machines where our jobs are run?  [[[--^ Top -> #top--]]]

There is a special macro to get the string attributes of target machines that we can use in our submit file. In this way, some of the parameters of each machine where HTCondor executes jobs can be accessed with =$$(parameter)=. Also there are other special macros, like the one used to print the symbol =$= since it is reserved by HTCondor: =$(DOLLAR)=.

For example, we want to know the name of each slot and machine where our jobs were executed, adding =.$.name.$.= to the results of =stdout= and =stderr=. Then we should use next commands:

 =output=        = myprogram.$(ID).$(DOLLAR).$$(Name).$(DOLLAR).out
 =error=         = myprogram.$(ID).$(DOLLAR).$$(Name).$(DOLLAR).err

Ading those commands in your submit file will create output and error files with names similar to =$.slot3@xilofon.ll.iac.es.$=.

\\\


!! Check also:


*** FAQs
[[#top]]
>>frame<<
(:table border=0 cellpadding=5 cellspacing=0 width=100% :)
(:cell align=center valign=middle :) [[Introduction -> Condor]]
(:cell align=center valign=middle :) [[Useful Commands -> CondorUsefulCommands]]
(:cell align=center valign=middle :) [[Submit files (desc. & examples) -> CondorSubmitFile]]
(:cell align=center valign=middle :) [[Submit files (HowTo) -> CondorHowTo]]
(:cell align=center valign=middle :) '''FAQs'''
(:cell align=center valign=middle :) [[HTCondor and IDL -> CondorAndIDLVirtualMachine]]
(:tableend:)
>><<


(:title HTCondor(5): FAQs :)
! FAQs about HTCondor




!!!General Information:
# [[#Q_whatscondor | What is Condor? How can Condor help me? Who can use it? Who can help me if I have any problems?]]
# [[#states | How does Condor work? My machine is in ''Owner/Unclaimed/Claimed'' state, what does it mean?]]
# [[#detection | Sometimes Condor runs jobs on my computer when I am working on it, can I avoid that?]]
# [[#Q_ack | I am using Condor, should I add an acknowledgement text in my publications?]]


!!! Preparing and submitting your jobs:
# %item value=5% [[#Q_change_program | I have developed a program, do I need to make any modification to run it with Condor?]]
# [[#Q_howexecute | How do I run my application with Condor? (submitting jobs to the queue)]]
# [[#check_queue | How do I check the Condor queue and my submitted jobs?]]
# [[#inputs | Where should I put my input files so Condor will be able to find them?]]
# [[#outputs | If Condor runs my program on different machines, how I can obtain my output files?]]
# [[#initialdir | Can I specify that Condor uses a different directory for input/output files?]]
# [[#macro_loops | I would like to use a loop to send my jobs with different arguments... can I do that?]]
# [[#rename_file | Do I need to rename my input/output files to work with Condor?]] 
# [[#delete_tmp | Should I delete temporary files?]]
# [[#requirements | What are the technical specifications of machines running Condor? Can I restrict and/or prioritize those specifications in my jobs? ]]
# [[#environment | How can I get/set environment variables when running with Condor (python and other programs may need them)?]]
# [[#ch_submit | Can I change my jobs attributes after submitting them?]]

!!! Having some troubles with your jobs:
# %item value=17% [[#Q_cannot_submit | I cannot submit jobs, what is wrong?]]
# [[#ssh | How can I check that my program is running fine? Can I access to the inputs/outputs in the remote machine?]]
# [[#idle | My submitted jobs are always in Idle status, why do they never run (and what about users' priority)?]]
# [[#input_output | Condor have problems with input and/or output files... are my paths wrong?]]
# [[#held | My jobs are in ''on hold'' status and never finish, what does it mean?]]
# [[#no_output | Condor is copying unwanted files to my machine, how can I avoid that?]] 
# [[#bad_inputs | Some of my jobs are failing due to wrong inputs, can I fix that problem and then run again only those jobs that failed?]] 
# [[#blackholes | Some of my jobs randomly fail (or I know they will fail in some specific machines)... how can I prevent that?]]
# [[#repeat | I want to repeat (resubmit) ONLY some of my jobs, is that possible?]]
# [[#moretime | I see that my jobs complete after being running for N+X minutes/hours, when they only need N to finish. Is that normal?]]
# [[#checkpoints | I have submitted jobs that need some hours to finish. They have been running for days and just few have finished... what is going on?]]
# [[#python-fedora | Some of my jobs that execute python programs work fine, but other fail...]]
# [[#matplotlib | I receive an error when running HTCondor jobs that use python and matplotlib...]]
# [[#logviewer | I would like to get more information about the execution, is there an easy way to see the logs created by Condor?]]

!!! Special needs:
# %item value=31%[[#priority | I am running many jobs, but some are more important than others, how can I prioritize them?]]
# [[#nomail | I am receiving hundreds of emails from Condor, can I stop that?]]
# [[#IDL | What happens with my IDL or Matlab jobs that require licences to run?]]
# [[#prepostscripts | I need to run some scripts before/after my executable, is that possible?]]
# [[#run_limits | Is it possible to limit the maximum number of concurrent running jobs?]]
# [[#predefined_func | I need to do some complex operations in my submit file, is that possible?]]
# [[#deferral_time | I would like to submit my jobs now, but they should run at a programmed time, can I do that?]]
# [[#lesstime | Jobs leave the queue after finishing. If something went wrong... could they be held or automatically re-executed instead?]]
# [[#run_ckpt | I want to do checkpoints of my ''normal'' programs (without using Condor) so I can restart them, is that possible?]]
# [[#fault_tolerant | I have a fault tolerant application, can I save the state and restore it when executing with Condor?]]
# [[#dependencies | My jobs have some dependencies, is it possible to specify that?]]


!!! More info:
# %item value=42%[[#morefaqs | My question is not in this list or I need further information, where can I find it?]]


\\\

!! Responses:

[[#Q_whatscondor]]
!!! Q1: What is Condor? How can Condor help me? Who can use it? Who could help me if I have any problems? [[[--^ Top -> #top--]]]
'''A''': Condor is a software that may help you to get your computational results in much less time. The underlying idea is to use idle computers to run your programs when they are not being used by their owners. When running your programs with Condor, you only need to specify the name of your program and its location, where to find the inputs and where to place your outputs, and that is almost all in most cases; everything else will be done by Condor. IAC researchers with access to a linux desktop PC should be able to use Condor; the SIE will give you support if you have any issue with it. Please, visit our [[introduction page -> Condor]] for more general information about Condor.

\\\

[[#states]] 
!!! Q2: How does Condor work? My machine is in ''Owner/Unclaimed/Claimed'' state, what does it mean? [[[--^ Top -> #top--]]]
'''A:''' Condor has to deal with complex situations, but here we will just give some outlines of its basic operation. Condor uses several daemons to essentially manage a queue of submitted jobs and a pool of ''slots'' where jobs can be executed (usually each ''slot'' is a core of the machines in the pool). Jobs have several requirements (requested memory, disk space, etc.) and slots have different specifications: what Condor does is to match jobs with suitable slots, and then execute those jobs on them.

You can try ='''condor_status'''= command to check the status of the pool of machines. The first column shows the name of the slots and machines, then some more info is shown, like the Operative System, Architecture, System load, Memory, etc. But we will focus on '''State''' and '''Activity''' columns, they can be used to understand how Condor works:

(:table border=1 cellpadding=5 cellspacing=0 width=95% align=center:)
(:cell align=center valign=middle :) '''STATE (''Activity'')''' 
(:cell align=center valign=middle width=120px:) '''Action'''
(:cell align=center valign=middle :) '''Description'''
(:cellnr align=center  valign=middle :)  =OWNER=  =(''Idle'')=
(:cell align=center valign=middle :) User is working on his/her machine
(:cell align=left valign=middle :) [-If a user is working on his/her machine, Condor will detect mouse/keyboard activity, active remote connections, etc. In this case, all slots of this machine will get the =Owner= state and Condor will not use it to run any job. The activity showed by Condor will be =Idle= since that slot is not doing any work for Condor, but it does not mean the machine is idle, most likely it will be busy working for her owner. =Owner= state can be assigned in other situations, like when the system load is high (Condor will not run any job to avoid interfering with user's programs), there are some time restrictions, etc. When user finishes working with the machine, Condor will still wait a prudential period of time (by default, 15 min.) since last activity was detected before using it.-]
(:cellnr align=center valign=middle :) =UNCLAIMED (''Idle'')=
(:cell align=center valign=middle :) Slot is idle
(:cell align=left valign=middle :) [-If the machine has not being used by his/her owner for a while, then Condor will run some benchmarks to update its info about performance and all slots will get the =Unclaimed= state and =Idle= activity. That means Condor is allowed to run jobs on the idle slots and the jobs queue will be checked to match any suitable job.-]
(:cellnr align=center valign=middle :)  =CALIMED (''Busy'')=
(:cell align=center valign=middle :) Slot is running Condor jobs
(:cell align=left valign=middle :)  [-If there is a positive match, Condor will begin to run the matched job on the slot. Condor will copy the executable and input files to the remote machine and run the program there. The slot(s) running Condor jobs will get the =Claimed= state and  =Busy= activity, and the jobs will get the =Running= state.-]
(:cellnr align=center valign=middle :)  =CLAIMED (''Suspended'')=
(:cell align=center valign=middle :) User begins to work on a machine that is running Condor jobs
(:cell align=left valign=middle :)  [-When Condor is running jobs in a machine and any user's activity is detected, Condor will immediately suspend all running jobs in all the slots. Some seconds (or few minutes) may be needed in this operation, depending on the job(s), the number of involved files, etc. The machine may get unresponsive at that time, but after a short while the machine should be ready again for the user. At this time the machine has the =Claimed= state and the =Suspended= activity, and it will keep this state for a period of time (by default, 15 minutes). This is done to prevent killing jobs when there is no real activity (for instance, the cleaning service accidentally moved the mouse, etc.). If it was an isolated activity, the machine gets idle again and then Condor will "''wake up''" the jobs and continue running them from the last point, recovering the =Claimed= state and the =Busy= activity.-]
(:cellnr align=center valign=middle :) =OWNER  (''Idle'')=
(:cell align=center valign=middle :) User is working on his/her machine
(:cell align=left valign=middle :) [-If there were suspended jobs in a machine and user is working again on it for a period of time (it is not an isolated activity), Condor will kill all suspended jobs and then the machine will get the =Owner= state. All killed jobs will go again to the queue with the =Idle= state to be executed when possible.-] 
(:tableend:)

States mentioned above are the most common and representative, but there are %newwin%[[other possible states -> http://research.cs.wisc.edu/htcondor/manual/v8.6/3_7Policy_Configuration.html#fig:machine-states]], like =Matched= (only shown for a few seconds when there is a successful match), =Preemting= (job is being killed or vacating from that slot), =Backfill= (slot is idle and queue is empty, so it can run some low priority jobs assigned by the administrators), etc. Visit the [[Useful commands page -> CondorUsefulCommands]] to get more information about commands in Condor.

\\\

[[#detection]] 
!!! Q3: Sometimes Condor runs jobs on my computer when I am working on it, can I avoid that? [[[--^ Top -> #top--]]]
'''A:''' Condor should run jobs {+only+} on idle computers that are not being used by their owners. Idle computers are those where there has not been keyboard/mouse activity for more than 15 minutes, system load is low enough (to avoid interfering with owner's programs), there are no active remote ssh connections, there are no time restrictions, it has enough free space, etc. 

If Condor is running job(s) on your computer when you begin to use it, Condor will detect your activity and it will immediately suspend all running jobs. That process is usually quite fast, most users do not even notice it, but some jobs are heavy and complex and it could take a while to suspend them (it could take from several seconds to a few minutes). If that happens, your machine could get unresponsive for a few that moments, but you just need to wait a bit and it will be ready soon (this is a normal process, sorry for the inconvenience). 

Anyway, performance problems could be caused by a wide range of different situations, like an exceeded home or disk quota, heavy load (check that your browser is not consuming a lot of CPU time if you have a large number of open tabs), configuration problems, etc. Please, use =df -h= and =quota -s= commands to get information about your available space and =htop= command to find out what processes are using your CPU and memory, that may help a lot to solve a low performance problem. 

If you want to check whether Condor has been executing jobs on your machine at any time, you can use the Stats Web we have developed: [[http://carlota:81/condor_stats/]]. There you can get some stats about which machines have been used by Condor, when and for how long, etc. Anyway, if you still think that you are experiencing any kind of problems related to Condor, just contact us and we will find a solution.

\\\

[[#Q_ack]]
!!! Q4: I am using Condor, should I add an acknowledgement text in my publications? [[[--^ Top -> #top--]]]

'''A''': Yes, you should mention it in the acknowledgments of your papers or any other publications where you have used HTCondor. Although there is no standard format, we suggest the following: 

>>frame<<
''"This paper made use of the IAC Supercomputing facility HTCondor (http://research.cs.wisc.edu/htcondor/)"''. 
>><<

If you have used any other IAC Supercomputing facilities (LaPalma, TeideHPC, etc.), please, add also them in the acknowledgments:

'''LaPalma''':  ''"The author thankfully acknowledges the technical expertise and assistance provided by the Spanish Supercomputing Network (Red Española de Supercomputación), as well as the computer resources used: the LaPalma Supercomputer, located at the Instituto de Astrofísica de Canarias."''

'''TeideHPC''': ''"The author(s) wish to acknowledge the contribution of Teide High-Performance Computing facilities to the results of this research. TeideHPC facilities are provided by the Instituto Tecnológico y de Energías Renovables (ITER, SA). URL: http://teidehpc.iter.es/"'' 

\\\

[[#Q_change_program]]
!!! Q5: I have developed a program, do I need to make any modification to run it with Condor? [[[--^ Top -> #top--]]]
'''A''': For a basic execution in Condor, you do not need to compile your program with any special library or add calls to external functions to be executed by Condor, the program runs as is. According to our experience, in most cases you will not need to change anything in your program, or only a few minor modifications may be required:

# Your program should accept arguments, since changing arguments is the way used to specify different jobs with the same executable. For instance, if your program reads a file to make the same computations with the values of each line, you can modify it to accept the number of the line as an argument, and then Condor will launch a different job for each line. Arguments can be also different data, paths to files or whatever your application use as input. 
# Paths to your input/output files may change when executing with Condor, so you should be able to change them in your application if needed.

\\\

[[#Q_howexecute]]
!!! Q6: How do I run my application with Condor? (submitting jobs to queue) [[[--^ Top -> #top--]]]
'''A:''' All the information needed by Condor to run your program should be written in a '''Condor submit file'''. You must include in that file one (and only one) =executable= command to specify what your program is (the path can be either absolute or relative to the directory where the submission is done). Additionally, if your executable is not accessible from other machines, use =should_transfer_files = YES= command and Condor will copy it to the remote machines.  With the =arguments= command you can specify your parameters (they can be either fixed values or depend on a counter) and then use =queue <N>= command to launch =N= jobs. You can repeat =arguments= and =queue= commands as many times as needed. A very basic submit file could be the following one, that assumes your application is located in the same directory where you will use the =condor_submit= command. ''Please, visit [[Condor submit file page -> CondorSubmitFile]] for more info and examples.''

  ''# Condor submit file''
  ''# Running myprogram with arguments "-v 235" and "-kf 'cgs' -v 6543"''
  =universe= = vanilla
  =should_transfer_files= = YES

  =executable= = myprogram

  =arguments=  = "-v 235"
  =queue= 

  =arguments=  = "-kf 'cgs' -v 6543"
  =queue= 

\\\

Once the submit file is ready, you can submit your jobs to the Condor queue using next command in your shell console:
  ='''condor_submit'''= submit_file

To check your jobs, use next command: 
  ='''condor_q'''=

Visit the [[Useful commands page -> CondorUsefulCommands]] to get more information about commands in Condor.

>>frame<<
'''Caution!''': Before submitting your real jobs, always sdo ome simple tests in order to make sure that both your submit file and program work in a proper way: if you are going to submit hundreds of jobs and each job takes several hours to finish, before doing that try with just a few jobs and change the input data in order to let them finish in minutes. Then check the results to see if everything went fine before submitting the actual jobs. Bear in mind that submitting untested files and/or jobs may cause a waste of time and resources if they fail, and also your priority will be worse in following submissions.
>><<

\\\

[[#check_queue]] 
!!! Q7: How do I check the Condor queue and my submitted jobs? [[[--^ Top -> #top--]]]
'''A:''' You can check the general status of the queue using ='''condor_status'''=, then you will see how many slots are used by their owners (state will be =Onwer=), how many are free to be used by Condor (=Unclaimed= state) and how many are already executing Condor jobs (=Claimed= state); these states are explained in [[this FAQ -> #states]] . If you use =condor_status -submitters=, you will get a summary of who has jobs in the queue and their status; there are many other [[useful commands and options -> CondorUsefulCommands]], please, check them. To see some graphs and stats about Condor, you can visit [[nectarino -> http://nectarino/]] (there you can also find information about Condor queue and machines states) and also [[http://carlota:81/condor_stats/]].

If you want to check only your submitted jobs, then use ='''condor_q'''=. It will show the info related to your jobs, like the cluster and process ID, owner, submission date, time they have been running, state, priority, Size, Command, etc. For instance, following lines show a possible output of this command:

  [...]$ ='''condor_q'''=

  '''ID'''      OWNER     SUBMITTED    RUN_TIME    '''ST'''  PRI SIZE   CMD             
  '''418.0'''   jsmith    3/13 17:00   0+00:37:32  '''I'''   0   317.4  myprogram -c 7
  418.'''1'''   jsmith    3/13 17:00   0+00:30:25  '''<'''   0   488.3  myprogram -c 14
  418.'''2'''   jsmith    3/13 17:00   0+01:12:10  '''R'''   0   231.4  myprogram -c 21
  418.'''3'''   jsmith    3/13 17:00   0+02:15:52  '''S'''   0   423.5  myprogram -c 62
  418.'''4'''   jsmith    3/13 17:00   0+06:31:34  '''>'''   0   623.1  myprogram -c 28
  418.'''5'''   jsmith    3/13 17:00   0+03:41:52  '''H'''   0   432.6  myprogram -c 35

The first value is the '''Job ID''', it is composed by two numbers, the first one is the ''Cluster ID'' that identifies the submission, all jobs submitted with the same submit file will share this Cluster ID (in this example Cluster ID is =418=). The second number is the ''Process ID'' and it is a consecutive number, from =0= for the first job to =N-1= for last job when =N= jobs are submitted. To understand what is happening to your jobs, check ''State'' column (=ST=), the common values are:

** ='''I'''=: ''idle'' job, waiting for a slot to be executed on (it can take a while before your jobs are executed, but if they are always in this state, check [[this FAQ -> #idle]])
** ='''<'''=: your job is about to be executed, executable and input files are being transferred to the remote machine 
** ='''R'''=: ''running'', your job is being executed at this moment
** ='''S'''=: ''suspended'', the machine that was running this job is being used, jobs are suspended while waiting for the machine gets idle again
** ='''>'''=: execution is finished, output files are being transferred
** ='''H'''=: ''on hold'', there are problems with your job that have to be solved (check [[this FAQ -> #held]])
** ='''<q'''= or ='''>q'''=: if you see those symbols, your transfers are waiting for the completion of other active transfers. This is done to avoid an excessive use of the available bandwidth.

Once your jobs are finished, they will leave the queue so they will be not listed when using =condor_q= (use =condor_history= command instead). There are other states that normally do not appear in basic executions, like =C= (completed) or =X= (removed). If you have a special need and want that your jobs stay in the queue after completion with these or other states, you can force that by using some commands in your submit files (check [[this FAQ -> #lesstime]] or [[this one -> #bad_inputs]]). 

\\\

[[#inputs]]
!!! Q8: Where should I put my input files so that Condor will be able to find them? [[[--^ Top -> #top--]]]
'''A:''' If you are using =stdin= as input (i.e. you directly specify your input data using the keyboard, or you run your program using =./myprogram < /path/to/input_file.txt=), then you should use the =input= command to specify the file that contains the input data (you can use either an absolute path or a relative one to the submitting directory):
  =input= = /path/to/input_file.txt
\\\

If your program needs to read some input files, they have to be transferred to all remotes machines on which your application will be executed, so your program will be able to find them. You do not need to deal with copying files, Condor will do all the work, the only thing you need to do is to use  =transfer_input_files= to specify the name and location of your files. For instance, suppose that your executable =myprogram= needs two input files as arguments: =data1.in= (it is now located in =/home/myuser/mydata=) and =data2.in= (it is located in the same directory where you will do the submission). Then, use next commands:

  ...
  =should_transfer_files=   = YES
  ...
  =transfer_input_files= = /home/myuser/mydata/data1.in, data2.in
  =executable= = myprogram
  =arguments= = "data1.in data2.in"
  ...

Although those input files are in different locations on your machine, Condor will copy them to the same directory where the executable will be placed on the remote machine, that is why we have used no paths when specifying files in the =arguments= command. You can also use =transfer_input_files= to copy directories (if you add a '''=/=''' at the end of the directory, then Condor will copy the content of the directory, but it will not create the directory itself). There are many possibilities when working with input and output files. Please, visit [[Condor submit file page -> CondorSubmitFile#example_simple_files]] where there is an example that explains how to work with files, step by step. 


If you have a huge amount of input files and/or they are very big (GB or so), there is another solution to avoid the copy process that could last a long while. In these situations, you can place your files in a shared location (like =/net/yourmachine/scratch=) so all machines could directly have access to the files without copying them. But that is not recommended at all since an intensive use of the shared network system could produce blocking accesses and possibly a significant slowdown in your and others' machine performance. Files should be always copied to remote machines to let them work locally. Only when you are dealing with really huge files, it might be better to use shared locations, but then you should [[limit the number of concurrent running jobs -> CondorHowTo#howto_limit]] to avoid stressing the network. Please, before submitting your jobs, contact us if you have doubts about this.

\\\

[[#outputs]]
!!! Q9: If Condor runs my program on different machines, how I can get my output files? [[[--^ Top -> #top--]]]
'''A:''' Condor will copy your output files back to your machine after the execution is finished, you only need to use some commands to specify those files and Condor will do everything else.

If your output is written in =stdout= (printed on the screen), then you have to use =output= command in your submit file to specify a file where Condor will write the output of each job. Obviously, filenames have to be different or all jobs will write in the same file and it will not be valid. To avoid that, you can use the ID of each job to write in distinct files. This ID is composed by two numbers (X.Y), where the first one is the cluster ID (it changes every time you do a submission) and the process ID (it goes from 0 to N-1 where N is the number of queued jobs). Also you should indicate a file where Condor will write the '''errors''' (those in =stderr=) and a '''log''' file. Therefore, all your submit files should include next commands (note that =ID= and =FNAME= are not commands, but some macros we have defined to make it clearer):

 =ID=     = $(Cluster).$(Process)
 =FNAME=  = filename

 =output= = $(FNAME).$(ID).out
 =error=  = $(FNAME).$(ID).err
 =log=    = $(FNAME).$(Cluster).log
\\
If your program also generates '''output files''', most times you do not need to use any command since after the execution Condor will copy to your machine all files created or modified by your job that are located in the same directory where your application was executed. You only need to check your submit file to make sure that the file transfer mechanism is active with next commands: 
 =should_transfer_files=   = YES
 =when_to_transfer_output= = ON_EXIT
\\
But sometimes we want to specify that Condor must transfer only some specific files (and avoid transferring useless files, like temporary ones), or we want to also transfer whole directories or specific files placed inside some sub-directories. In those situations you should use =transfer_output_files= command to specify which files or directories(*) you want that Condor copies back to your machine (paths should be relative to the executable):
 =transfer_output_files=   = data$(Process).out, dir$(Process)_out, dir_outputs/ 
(*):[-if your directory ends with an slash '''=/=''', Condor will copy the content of the directory, but it will not create the directory itself-]

Of course, output files should have distinct names (if you use the same name, files will be overwritten when copying them to your machine). If your application uses always the same name for output files, you can use =transfer_output_remaps= command to change their names in destination (it will only work with files, not with directories). For instance, suppose that your application creates an output file named =data.out= and you want to use distinct names to avoid overwriting those files, then you could use the =$(Process)= macro to include the process ID of the job to generate different names (=data0.out=, =data1.out=, =data2.out=, ...):
 =transfer_output_files=   = data.out
 =transfer_output_remaps=  = "data.out=data=$(Process)=.out"
\\
If you only want to get the output file from the screen (using =output= command) but '''not''' any other generated or modified file, you can use =should_transfer_files = NO= command. But this command will also affect your input files. If you want to copy input files, but NOT the output files, you should use:
 =should_transfer_files=  = YES
 =+TransferOutput=        = ""
\\
Bear in mind that =transfer_output_files= command is '''not''' used to specify where you would like that Condor places output files in your machine (you can use =initialdir= command for that, check [[this FAQ -> #initialdir]]), but where the output files will be located in the remote machine so Condor can find them (paths to your output files must be relative to the directory where your program will be run).
There are many possibilities when working with input and output files. Please, visit [[Condor submit file page -> CondorSubmitFile#example_simple_files]] where there is an example that explains how to work with files, step by step. 


'''Read this when dealing with huge input/output files''': If your program generates a huge amount of output files and/or they are very big (GB or so), there is another solution to avoid the copy process that could last a long while. In these situations, you can prepare your program to write the output files directly in a shared location (like =/net/yourmachine/scratch=). But that is not recommended at all since an intensive use of the shared network system could produce blocking accesses and possibly a significant slowdown in your and others' machine performance. Files should be always copied from remote machines to let them work locally. Only when you are dealing with really huge files, it might be better to use shared locations, but then you should [[limit the number of concurrent running jobs -> CondorHowTo#howto_limit]] to avoid stressing the network. Please, before submitting your jobs, contact us if you have doubts about this.

\\\

[[#initialdir]] 
!!! Q10: Can I tell Condor to use a different directory for input/output files? [[[--^ Top -> #top--]]]
'''A:''' Sometimes you are submitting your jobs from the directory where your executable is located, but your input/output files are placed in a different location. You could add the path to that location every time you have to specify a file, but it is much easier to use the =initialdir= command. For instance, if your input data is located in =/home/myuser/mydata= and you want that your output data will also be placed there, you can add this statement in your submit file:

 =initialdir= = /home/myuser/mydata

Bear in mind that it will affect both your input and output files, but it has no effect over the executable file.


\\\

[[#macro_loops]] 
!!! Q11: I would like to use a loop to send my jobs with different arguments... can I do that? [[[--^ Top -> #top--]]]
'''A:''' Yes, a loop is the most natural way of submitting different jobs in Condor. Many users have created shell scripts to generate different submit files, one per each set of arguments, but this is unnecessary in most cases and it is not recommended: the shell script can be quite complex; managing dozens, hundreds or even thousands of submit files is bothersome, as it will also be managing all those independent jobs; and, even worse, efficiency will be reduced (every time you submit, Condor creates a ''cluster'' for that execution, which involves an overhead. So we should try to create only one cluster with N jobs rather than N clusters with only one job each, which makes also easier managing all generated jobs).

The easiest way to work with loops is to use the predefined =$(Process)= macro in your submit file. Condor will assign the id of each job to this macro, so if you are submitting =N= jobs, =$(Process)= will be =0= in the first job, =1= in the second one, till =N-1= in the last job. This is the loop we need. For instance, next easy submit file will use perl to calculate the cube of the first =N= numbers creating one job per number (in this example we will use =N = 50=, beginning with =0=):

 N = 50

 =should_transfer_files=   = YES
 =when_to_transfer_output= = ON_EXIT 

 =output=  = cube.$(Cluster).$(Process).out
 =error=   = cube.$(Cluster).$(Process).err                                                                                     
 =log=     = cube.$(Cluster).log  

 =executable=          = /bin/perl
 =transfer_executable= = False
 =arguments=           = "-e 'print $(Process)**3'"

 =queue= $(N)

As you can see, it is very easy to simulate a loop, we only need to use the predefined macro =$(Process)= to get the iteration value. We can use it in our arguments, inputs, outputs, name of files, etc... Since we have only submitted once, just one cluster will be created. Please, visit [[Condor submit file page -> CondorSubmitFile]] to see more detailed examples. If you need a more complex loop including some arithmetic operations using the iteration value, then you can define your own macros using Condor syntax, see [[this example -> CondorSubmitFile#example_complex_macros]]. Condor also has %newwin%[[more predefined macros -> http://research.cs.wisc.edu/htcondor/manual/v8.6/3_5Configuration_Macros.html#SECTION00451800000000000000]] to generate random numbers, randomly choose one value among several of them, etc.

\\\

[[#rename_file]]
!!! Q12: Do I need to rename my input/output files to work with Condor? [[[--^ Top -> #top--]]] 
'''A:''' Using filenames with a known pattern makes it much easier to specify files to transfer in your Condor submit file. When possible, we recommend you use a common text and then an index to refer to your files, for instance: =data0.in=, =data1.in=, =data2.in=, =data3.in=, ..., =data154.in=. Then it will be very easy to specify each input file: you only need to add a command similar to next one: =transfer_input_file = data$(Process).in=. This is the easiest situation, but this approach is also valid in more complex scenarios, like when the index depends on a expression and/or has some leading zeros, like =0001=, =0002=, =0003=, ... (see [[this example -> CondorHowTo#howto_numberfmt]]). Also remember that you can run scripts (or other programs) before and after executing your main application (see [[this FAQ -> #prepostscripts]]), so you could use this feature to change the name of your files as needed (for instance, using shell commands or scripts).

But sometimes you can use a known pattern in your files, or you have a variable number of files to transfer, or maybe your program does not generate any output file under certain conditions... In those situations, it is much better to transfer directories rather than deal with individual files. Then, you only need to place your input and/or output files in directories, and then specify that Condor has to transfer these directories and their content. 

Remember that you can use =transfer_input_file= and =transfer_output_file= to specify which files and directories to transfer. Paths in the local machine can be absolute or relative to the directory where the submission is performed (or the one set using =initialdir= command). Paths in remote machines should be relative to the directory where your program is placed and executed (be careful if you use absolute paths, they have to exists in every machine). 


\\\

[[#delete_tmp]] 
!!! Q13: Should I delete temporary files? [[[--^ Top -> #top--]]] 
'''A:''' No, that is not needed if you are only using local directories (those that belongs to Condor). Condor will run your program on remote machines, and once the execution is finished and the output files are transferred, Condor will delete files and directories related to that execution, so you do not need to delete any file. If you are using another locations like those in external or shared systems (=/scratch=, =/home=, =/net/nas3=, etc.), then you need to delete all unnecessary files since Condor will not check those directories.

Condor also has periodic checks on every machine and it will analyze all directories belonging to Condor in order to remove extraneous files and directories which may be left over from Condor processes that terminated abnormally due to either internal errors or a system crash.

\\\

[[#requirements]]
!!! Q14: What are the technical specifications of machines running Condor? Can I restrict and/or prioritize those specifications in my jobs? [[[--^ Top -> #top--]]] 
'''A:''' To see an overview of the hardware and software available when running with Condor, please visit the [[introduction page -> Condor#condor_machines]]. You can also use next commands to get information about slots:
 =condor_status -server=          ''#List attributes of slots, like memory, disk, load, flops, etc.''
 =condor_status -sort Memory=     ''#Sort slots by Memory, you can try also with other attributes''

If you have an application that has hardware/software limitations, you can add restrictions or directly specify which machines you want to run your application on. Typical limitations are the OS version (due to dependencies on libraries), RAM, disk space, etc., but there are many more parameters. To apply your restrictions use the =requirements= command and the conditions (you can  use several %newwin%[[operators, predefined functions, etc. -> http://research.cs.wisc.edu/htcondor/manual/v8.6/4_1HTCondor_s_ClassAd.html#SECTION00512300000000000000]]) in your submit file. 

To see the complete list of parameters, try command =condor_status -l <your_machine>= and the values for each slot of your machine will be displayed. Most of the parameters showed in that list can be used to add requirements. Also you can use other commands in your submit file like =request_memory=, =request_disk=, etc. 

If you want to specify preferences in one or several parameters, use the =rank= command in your submit file (Condor will always give more preference to higher values of the specified parameters). For instance, add next lines to your submit file if you want to run your jobs only in slots with Fedora19 and more than 1GB of RAM, prioritizing those slots with the highest amount of RAM: 

 =rank=           = Memory
 =request_memory= = 1024
 =requirements=   = (OpSysAndVer == "Fedora19")

Rank is evaluated as float point expression, so you can weight several parameters in different ways. For instance, we want to choose slots with higher RAM, but those with at least 15GB of disk are also important for us, so will give them 100 extra ''points'':
 =rank=         = Memory + (100 * (Disk >= 15120000))

\\
'''Caution!:''' Be careful when choosing your restrictions, using them will reduce the number of available slots for your jobs so it will be more difficult to execute them. Also check that you are asking for restrictions that can be satisfied by our current machines, or your jobs will stay always in Idle status. Before adding a requirement, always check if there are enough slots that satisfy it. For instance, to see which slots have more than 1GB of RAM, try next command in your shell (you can filter and see only the available ones adding flag =-avail=):
 [...]$ =condor_status= -constraint '((Memory > 1024) && (OpSysAndVer == "Fedora19"))'

''Please, visit [[Condor submit file page -> CondorHowTo#howto_requirements]] for more info and examples.''

\\\

[[#environment]]
!!! Q15: How can I get/set environment variables when running with Condor (python and other programs may need them)?  [[[--^ Top -> #top--]]]
'''A:''' If you are running a python program it is likely it will need to access the environment variables when importing some modules. Other programs and scripts also need to get or set environment variables to properly work. If you use =getenv = True= command in your submit file, Condor will copy your current shell environment variables and they will be available when running your job (copy will be performed at the time of submitting). If you need to declare or change the value of any variable, you can use the =environment= command in the submit file, like the following example: 
 =environment= = "var1=val1 var2=""val2"" var3=val3"

If you use both commands, variables specified with =environment= command will override those copied by =getenv= if they have the same name. Using =$ENV(variable)= allow the access to environment variables in the submit file (for example, =$ENV(HOME)=). 

Please, see also [[this FAQ about python ->  http://research.iac.es/sieinvens/siepedia/pmwiki.php?n=HOWTOs.CondorFAQs#python-fedora]] for more details about how to define environment variables with python, and visit also [[Condor submit file page -> CondorHowTo#howto_env]] for more info and examples.

\\\

[[#ch_submit]] 
!!! Q16: Can I change my jobs attributes after submitting them? [[[--^ Top -> #top--]]]
'''A:''' Yes, most of the jobs attributes can be changed after the submission (but not all of them, for example, you cannot change the owner, clusterId, procId, jobStatus, etc.). Of course, you can only change your own jobs.

To change attributes, use command ='''condor_qedit'''= and specify the name of the attribute and its new value (new attributes can be defined, too). See next examples (attributes to be changed are underlined and new values are set just after them):
  [...]$ =condor_qedit 1234 {+NiceUser+} TRUE=                                ''# Enable NiceUser in all jobs belonging to cluster 1234'' 
  [...]$ =condor_qedit 1234.6 {+Requirements+} '(UtsnameNodename != "arco")'= ''# Job 1234.6 will not be executed on machine "arco"''
  [...]$ =condor_qedit -constraint 'JobStatus == 1' {+Environment+} '""'=     ''# Clean environment variables in all idle jobs''

'''Notes''':
** [-Remember to quote strings. For instance, to specify that attribute =A= has a value ="foo"= you should use: =condor_qedit ... A '"foo"'=.-]
** [-Use =condor_q= with option =-long= to get the full list of attributes of each job and their current values. Depending on which attributes you have changed/added, new values may be valid only after those attributes are re-evaluated, usually when jobs restart (so changing attributes of running jobs may not work till those jobs are stopped and executed again).-]
** [-Be careful when changing attributes like =Requirements=, =Environment=, etc., since new values will replace the old ones (they will {+not+} be appended to the previous values, so you may need to get them before and add them to your expression).-]
** [-As you can see in the examples above, you can select which jobs you want to edit specifying their clusterId, clusterId.procId and/or with a constraint (use your username to select all your jobs), with the same syntax that you use in =condor_q= (and other commands like =condor_release=, =condor_hold=, =condor_rm=, etc.). We recommend that you use =condor_q= to check the selection of jobs before editing, to avoid making unwanted changes to other jobs.-]

\\\

[[#Q_cannot_submit]]
!!! Q17: I cannot submit jobs, what is wrong? [[[--^ Top -> #top--]]]
'''A:''' If you use =condor_submit <submit_file>= and your jobs do not appear in the list when using =condor_q=, there might be errors in your submit file. If so, Condor should print those errors and some related information when doing the submission (use =-debug= flag if you do not see that info). Most problems are easy to fix since they are related to wrong paths, lack of permissions, missing required commands, etc., but if you do not have an idea about how to fix any error, please contact us.

\\\

[[#ssh]]
!!! Q18: How can I check that my program is running fine? Can I access to the input/output files in the remote machine? [[[--^ Top -> #top--]]]
'''A:''' There are several ways to check in real-time what is happening on the remote machine while it executes your jobs, so you can see how results are being generated and whether they are fine or not. All these methods only work {+when processes are running+}, remember that you can get the =job_id= using command =condor_q=, be sure that the job you choose is running with state "'''R'''" (you can select them using =condor_q -run=). 

A) You can check what your program is printing on the "screen" (=stdout= and =stderr=) and/or in output files on the remote machine while it executes your program. To display outputs, use ='''condor_tail''' <job_id>= command and it will show the latest lines of the specified output like the linux command =tail= does (you can also add =-f= option to keep showing new content). For instance, if you want to check the running job =123.45=, just use next commands:
 [...]$ =condor_tail= 123.45                       ''# Show =stdout= (normal output on screen)''
 [...]$ =condor_tail -f= 123.45                    ''# Show =stdout=, it keeps showing new content''
 [...]$ =condor_tail -no-stdout -stderr= 123.45    ''# Show =stderr= (errors on screen)''
 [...]$ =condor_tail -no-stdout= 123.45 file.out   ''# Show output file =file.out= (*)'' 
[- (*) The output file must be listed in the =transfer_output_files= command in the submit file.-]

\\\

B) You can also establish SSH connections to the remote machines where your jobs are being executed, using the command ='''condor_ssh_to_job''' <job_id>= (again, make sure that the job is running). Once the SSH connection is established, you will be placed in the directory where your program is being run, so you can check input and output files to see whether the program is running properly (you should NOT make any modifications in any file to avoid errors). To open an ssh connection you only need to specify the jobId, see example for job =123.45=:
 [...]$ =condor_ssh_to_job= 123.45
 
If you need to upload or download files, you can open an =sftp= connection using flag =-ssh sftp= or you can also use =rsync=, see following examples:
 [...]$ =condor_ssh_to_job -ssh sftp= 123.45
 [...]$ =rsync -v -e condor_ssh_to_job= 123.45:<remote filename> <local directory>

'''Important''': {+close ssh connection when you are not using it+}. Jobs with open connections cannot leave the queue, so they will appear as "running" even if they are already done, waiting till you close the connection.

\\\


C) There is a third method, but it is not recommended: the directory where Condor executes jobs is usually located in the scratch, so in most cases it will be directly accessible, you only need to know the name of the machines running your jobs. Use =condor_q -run= to get these names and then access to the working directory located in =/net/<remote_machine>/scratch/condor/execute/dir_XXXXX= (where ''XXXXX'' changes in every execution, but it should be easy to recognize due to owner's name). Note that this is the default configuration, but some machines have other configurations and/or you may have no permit to access to those directories. 

\\\

[[#idle]]
!!! Q19:  My submitted jobs are always in Idle status, why do they never run (and what about users' priority)? [[[--^ Top -> #top--]]]
'''A:''' If your jobs are always in Idle status, it may be caused by several reasons, like restrictions that you have specified in the submit file, a low user's priority, etc. With =condor_q=  command you can find out what the reason is, just choose one of your idle jobs and use next commands:

  =condor_q -analyze= <job_id>
  =condor_q -better-analyze= <job_id>

Condor will display then some detailed information about machines that rejected your job (because of your job's requirements or because they are not idle but being used by their owners), machines that could run your job but are busy executing other users' jobs, available machines to run your job if any, etc. It will also display the reason why that job is idle and some suggestions if you have non-suitable requirements.

Check that information and be sure that your requirements can be satisfied by some of the current machines (pay attention to the suggestions, they may help a lot!). For instance, if you ask for slots with more than 6GB of RAM, there are just few of them and they need to be idle to run Condor jobs, so you may need to wait for a long while before running there (also check that there are no impossible values, like asking for machines with 16GB per slot, we have none of them). Before adding a requirement, always check if there are enough slots that satisfy it (for example, to see which slots have more than 6GB of RAM, try next command in your shell: =condor_status -constraint 'Memory > 6144'=. ''Please, visit [[Condor submit file page -> CondorSubmitFile]] for more info and examples.''

You can also get messages like =Reason for last match failure: insufficient priority=. Bear in mind that Condor executes jobs according to users' priority, so that message means that Condor is right now executing jobs submitted by users with a better priority than yours, so you will still have to wait a bit. You can check yours and other users' priority running =condor_userprio -all -allusers=: all users begin with a priority value of =0.5=, the best one possible, and once you begin to run jobs with Condor, it will increase your priority value (that means worse priority) according to the number of machines you are using and the consumed time (the more you use Condor's resources, the faster your priority value will be increased). On the other hand, your priority will be gradually decreased when you are not using Condor.

If your Condor priority is important for you and you want to run some not urgent jobs, you can submit them using =nice_user = True= command in your submit file: those jobs will be run by another user called =nice_user.<your_user>= and they will not affect your real user's priority. But this new user has an extremely low priority, so its jobs can stay in the queue for a long while before being executed (but they can be run very fast if the Condor queue is almost empty). 

Besides user's priority, all jobs have also their own priority, and you can change it to specify whether some jobs are more important than others so they should be executed first (please, [[check this FAQ -> #priority]]).

\\\

[[#input_output]]
!!! Q20: Condor have problems with input and/or output files... are my paths wrong? [[[--^ Top -> #top--]]]
'''A:''' If Condor is not able to find your input files, probably your jobs will get the "''on hold''" status (see [[this FAQ -> #held]]). It is not needed to place your input files in any special location, but you need to specify the path to each file (it could be absolute or relative to the directory where you will do the submission) and make sure that the path is correct and you have access permits. Check [[this FAQ -> #inputs]] to see which commands you can use to specify the input files.

On the other hand, you also have to specify the output files that will be generated by your program so Condor can copy them from the remote machines to your computer. Check [[this FAQ -> #outputs]] to see which commands you can use for this purpose.

\\\

[[#held]]
!!! Q21: My jobs are 'on hold' status and never finish, what does it mean? [[[--^ Top -> #top--]]]
'''A:''' When there is an error, jobs change their state to "''on hold''". It means that Condor is expecting an action from the user to continue with those jobs. Most times the reason to hold jobs are related to permissions or missing files. A common problem is to specify files that cannot be accessed from other machines, like those in your home or desktop directories (use Condor commands to copy files instead), or the destination directory for output files does not exist or is not reachable, etc. You can check all your held jobs and the reason for that running next command in your shell: =condor_q -hold=. Once you have fixed the problems, run command =condor_release -all= and Condor will check all held jobs again and change their status accordingly.



\\\

[[#no_output]] 
!!! Q22: Condor is copying unwanted files to my machine, how can I avoid that?[[[--^ Top -> #top--]]] 

'''A:''' By default, Condor will copy all files generated or modified by your application that are located in the same directory where your program was executed on the remote machine, what could include some unwanted content like temporary files, etc. If you want to avoid that, then you can use the =transfer_output_files= command (see [[this FAQ -> #outputs]]) to specify which files and/or directories you want that Condor copies from the remote machine to your machine once your application has finished (then Condor will copy {+only+} those files and ignore all remaining ones).

If you only want to get the output file from the screen (using =output= command), but not any other generated of modified file, you can use =should_transfer_files = NO= command. That command will deactivate the Condor transfer mechanism, affecting both your input and output files, so it can be only used when you have none of them. If you want to copy input files, but NOT the output files, then you should use next commands:

 =should_transfer_files=  = YES
 =+TransferOutput=        = ""





\\\

[[#bad_inputs]] 
!!! Q23: Some of my jobs are failing due to wrong inputs, can I fix that problem and then run again only those jobs that failed? [[[--^ Top -> #top--]]] 
'''A:''' First of all, we strongly recommend you always perform some simple tests before submitting your actual jobs in order to make sure that both your submit file and program work in a proper way: if you are going to submit hundreds of jobs and each job takes several hours to finish, before doing that try with just a few jobs and change the input data in order to let them finish in minutes. Then check the results to see if everything went fine, and if so, then submit your real jobs. Bear in mind that submitting untested files and/or jobs may cause a waste of time and resources if they fail, and also your priority will be worse in following submissions. 

Sometimes we discover too late that there were some problems, most times related to the executable and/or the input files. If some of the jobs have run correctly while others have failed, we will try to fix the problems and execute again only those that have failed, to avoid wasting time and resources executing again jobs that worked fine. For the same reason, we should stop as soon as possible all those running (or idle jobs) that will fail. Every submission is different, and it is not possible to give general advice, but next steps should help you (and you can always contact us to study your particular situation):

# '''Identify those jobs that failed''': if your queue only contains failing jobs since all correct ones have already finished, then it will very easy to manage them. But most times you will have different jobs in your queue: correct ones that are running, incorrect ones also running, some of them that are held, others that are idle so we do not know whether they are correct or not, etc. The first thing we have to do is to find an expression to identify all failing jobs. Usually when jobs fail there is a way to recognize them, for example, they have been executing for a very long time (many hours when they only need a few minutes to finish), or very short, or the exit code is not the expected one, etc. Use =condor_q= command to list them with =-constraint= option and an expression, we will give you some tips to find those jobs:
** All held jobs (=JobStatus == 5=) from Cluster with ID 453 (=ClusterID == 453=) are not correct. To list them we simply use next command:
    =condor_q= -constraint '((JobStatus == 5) && (ClusterID == 453))'
** Our jobs need less than 10 minutes to finish, those that are running (=JobStatus == 2=) for more than 30 minutes (=(CurrentTime - JobStartDate) > 1800=) are not correct. Then we can list them using next command:
    =condor_q= -constraint '((JobStatus == 2) && ((CurrentTime - JobStartDate) > 1800))'
** All those idle jobs (=JobStatus == 1=) that have been running for more than 2 hours (=CumulativeSlotTime > 7200=) are wrong:
    =condor_q= -constraint '((JobStatus == 1) && (CumulativeSlotTime > 7200))'
->Note the difference between ''cumulative time'' (the sum of the time consumed in different executions if the job have been evicted) and the ''consumed time'' of the present execution. To see the consumed time of all running jobs you can use =condor_q -run -currentrun= (or use =-cputime= to see the real CPU time consumed without being suspended), and you can also use =condor_ssh_to_job= to connect and see what is happening (check [[this FAQ -> #ssh]]).
** Jobs have many other attributes that can be used in the constraints, just choose a incorrect job (for example job with ID =XXX.YYY=) and run =condor_q -long XXX.YYY= to get all attributes of that job. Then try to find which attributes can be used to identify all wrong jobs. All valid =JobStatus= could be displayed using shell command: =condor_q -help status=


# %item value=2% '''Stop all failing jobs and run them again with correct data''': Once you have all your failing jobs listed and the problem with input if fixed, we will try to stop those wrong jobs and re-execute them with the right data. There are two situations, depending on how you solved the problem:
** ''Situation A: to solve the problem you only need to correct the executable and/or the input files, but the submit files was NOT changed.'' This is the easiest situation, you have to be sure that the new input files are in the same location that they were previously and exactly with the same names. Then you only need to hold all those wrong jobs and release them again, so the new executable and input files will be copied. To do it, use the same expression you had before to list the jobs, but change command to =condor_hold=:
    =condor_q= -constraint '(=XXX=)'      ''List all failing jobs, =XXX= is the expression to identify them''
    =condor_hold= -constraint '(=XXX=)'   ''Hold all failing jobs''
    =condor_release= -all               ''Execute again all held jobs (we assume that all held jobs are those failing,''
                                      ''if not, just find and use a =-constraint= expression)''
->And that should be all, now all released jobs will have the correct input files, so executions should go fine.

** ''Situation B: to solve the problem you need to change the submit file''. Sometimes we cannot avoid changing the submit file because we have to modify the commands to add or remove input files, change the arguments, etc. In those situations, holding and releasing failing jobs will not work because the submit file is only processed at the submission time. Then we need to use ='''condor_qedit'''= (see [[this FAQ -> #ch_submit]]) to change the values of the attributes specified in the submit file; or you can also remove the wrong jobs and submit them again. For the last option, simply follow next steps (we are assuming here that all jobs belong to the same Cluster, if you have done several submission, then you will have to repeat these steps several times):
## Get the list of Process ID of all failing jobs (use the same expression (=XXX=) that you get in the first step):
    =condor_q= -constraint '(=XXX=)' -format "%d," ProcID
-> For example, assume that the output of the last command is =0,4,67,89,245,=
##%item value=2% Remove all those failing jobs:
    =condor_rm= -constraint '(=XXX=)'
##%item value=3% Change your submit file as needed and add next command to only execute the failing jobs
    =noop_job= = ='''!'''stringListMember=("$(Process)","0,4,67,89,245")
-> Important!! When re-submitting, output, log, and error files of ALL jobs (even those correct ones) may be overwritten, so save the old ones if they are important.
##%item value=4% Submit again.
    =condor_submit= your_submit_file
##%item value=5% Jobs that are not in the =noop_job= list will not be executed, but they may stay in the queue with =Complete= status, use next command to remove them from the queue (read [[this FAQ -> #repeat]] for more info)
    =condor_rm= -constraint 'JobStatus == 4'

As you can see, the steps to follow strongly depend on each particular problem, so it might be easier if you just come to our office.

\\\

[[#blackholes]]
!!! Q24: Some of my jobs randomly fail (or I know they will fail in some specific machines)... how can I prevent that? [[[--^ Top -> #top--]]]
'''A:''' If you see that some of your jobs fail with apparently no reasons, but they properly run when resubmitted, the problem might not be in your program, but on the machine(s) where they were executed (for example, an application or library that is used by your program is not installed on those machines, or its version is too old/new, or it is misconfigured, etc.). To detect this, simply check the machine where the failing job was executed, which is written in your condor log file, though it is easier to check it using the =condor_history= command. For instance, to check where job =XXX.YYY= was run, launch next command in the {+same machine+} where you did the submission: 

 [...]$ =condor_history= XXX.YYY =-af= LastRemoteHost

Maybe some of your jobs finished with no problems, but others finished abnormally soon. You can use =condor_history= to get a list of those jobs. For instance, suppose that you have submitted some jobs with =clusterId=XXX= and each job needs at least 30 minutes to properly finish, so you are sure that those that lasted less than 10 minutes (600 seconds) failed. Then you can use next commands to get those jobs (first command will give you a list of the jobs that failed and the second one will show two lines for each of them, the first line is where the jobs was executed on and the second line is the =procId= of the job):

 [...]$ =condor_history= -constraint '((ClusterId==XXX) && ((CompletionDate-JobStartDate) < 600))'
 [...]$ =condor_history= -constraint '((ClusterId==XXX) && ((CompletionDate-JobStartDate) < 600))' =-af= ProcId LastRemoteHost
\\
Most times these problems are simply solved by forcing these failing jobs to go again into the queue after an unsuccessful execution to be re-executed (see last paragraph). If you see that all jobs that failed were executed on the same machine(s) or you already know that your application is not able to run on some machines, then you can force Condor to avoid sending your jobs to those machines. For instance, suppose that your jobs have problems in machines with names ''agora'', ''lapiz'' and ''madera'' and you want to avoid them. Then, add either of the next lines (both are equivalent) to your Condor submit file (if you had some previous requirements, append the new ones to them):
 =requirements= = ((UtsnameNodename =!= "agora") && (UtsnameNodename =!= "lapiz") && (UtsnameNodename =!= "madera"))
 =requirements= = '''!'''=stringListMember=(UtsnameNodename, "agora,lapiz,madera")

You can also block all machines that satisfy a pattern. For instance, to avoid executing your jobs in those machines with names beginning with "a", "l" and "m", add next lines (you can specify more complex patterns using the %newwin%[[predefined functions and macros -> http://research.cs.wisc.edu/htcondor/manual/v8.6/4_1HTCondor_s_ClassAd.html#SECTION00512400000000000000]]):
 letter       = =substr=(toLower(Target.Machine),0,1)
 =requirements= = '''!'''=stringListMember=($(letter), "a,l,m")

On the opposite situation, if your application can ONLY run on those machines, then you only need to negate the previous expressions (or remove the negation):
 =requirements= = ((UtsnameNodename == "agora") || (UtsnameNodename == "lapiz") || (UtsnameNodename == "madera"))  
 =requirements= = =stringListMember=(UtsnameNodename, "agora,lapiz,madera")
 ...
 letter       = =substr=(toLower(Target.Machine),0,1)
 =requirements= = =stringListMember=($(letter), "a,l,m")

\\
Then you should execute again only {+those jobs that failed+} (check [[this FAQ -> #repeat]] to see how). Please, do not execute again all your jobs to avoid wasting time and resources. If your program could fail and never end (for example, for some sets of data it never converges), you can use utilities like linux command =timeout= to limit the time it can be running. Failing machines can cause a problem called '''black hole''' that could produce that most of your jobs fail. Please, visit [[Condor submit file section -> CondorHowTo#howto_failing]] for more info and examples to avoid that. In this section we also describe some Condor commands that you can add in your submit file to deal with failing machines, like =on_exit_hold= and =on_exit_remove=. For instance, using these commands you can specify that any job that finishes with a non valid exit code and/or before X minutes, has to be held or sent to the queue again to be re-executed, respectively. Some examples (before using these commands, make sure that the problem is on remote machines and not on your code in order to avoid re-executing failing jobs):

 [--# Held jobs if they finished in less than 10 minutes. Later we can check what was wrong with those jobs and re-execute again them--]
 [--# using =condor_release= (we can also use =periodic_release= to automatically release held jobs every X minutes)--]
 =on_exit_hold= = ((CurrentTime - JobStartDate) < (10 * 60)

 [--# Remove from the queue only those jobs that finished after 10 or more minutes. If a job finished before that period of time,--]
 [--# it will be sent again to the queue with 'Idle' status to be re-executed (most probably on a different machine)--]
 =on_exit_remove= = ((CurrentTime - JobStartDate) > (10 * 60)

\\\

[[#repeat]]
!!! Q25: I want to repeat (resubmit) ONLY some of my jobs, is that possible? [[[--^ Top -> #top--]]]
'''A:''' If you submit a large number of jobs and for any reason some of them fail and leave the queue, you should not waste time and resources running again all of them, just try with those that failed (after solving the problems they had). Unfortunately there is '''not''' a =condor_resubmit= command to easily resubmit jobs that have already left the queue. You could try to obtain the ''ClassAd'' of those jobs using =condor_history -l <job.id>=, but Condor will not accept it as input when using =condor_submit=.

If there are just a few jobs to resubmit, you could try to add pairs of =arguments= and =queue= commands to execute only those jobs, but there is an easier way to do it using =noop_job= command. For instance, suppose you want to repeat jobs with Process ID =0=, =4=, =9=, =14= and those from =24= to =32=. Then, add next line to your submit file and submit it again:

  =noop_job= = ='''!'''( stringListMember=("$(Process)","0,4,9,14") || (($(Process) >= 24) && ($(Process) <= 32)) =)=

Condor will '''not''' run jobs where that expression is =True=, so only jobs in the list will be executed. Note that we have added an exclamation mark symbol (='''!'''=) before your expression to change its value: =noop_job = '''!'''(...)=. When using =noop_job=, Condor will still create output and error files for all jobs, but they will be empty for those jobs that will not be executed (be careful to avoid that new executions overwrite output files of previous ones). 

Jobs that are not executed may stay in the queue with =Complete= status (when using =condor_q= you will see that =ST= column is =C=). To remove all =C= jobs from the queue, try next command in your shell (use the second one to only remove =Complete= jobs that belongs to cluster =XXX=):

  =condor_rm= -constraint 'JobStatus == 4'
  =condor_rm= -constraint 'JobStatus == 4 && clusterID == XXX'

\\\

[[#moretime]]
!!! Q26: I see that my jobs complete after being running for N+X minutes/hours, when they only need N to finish. Is that normal? [[[--^ Top -> #top--]]]
'''A:''' Yes, it is normal. Bear in mind that executing a Condor job in a machine is only possible when it is not used by its owner. If Condor detects any user's activity in a machine when executing jobs, they will be suspended or moved to another machines, increasing the consumed time (and that may happens several times, so the extra time could be quite long). 

Condor has several ways to show the time that jobs have been running. If you use =condor_q=, the time showed is the cumulative one by default (the result of adding the time consumed in all executions), so it could be really high if the job has been killed and restarted several times. If you use =-currentrun= option, then Condor will only display the time consumed in the current execution, which is a more realistic time (although if the job has been suspended, that time is also included). You can also use =-cputime= option to get only the CPU time (but if the job is currently running, time accumulated during the current run is not shown).

If your jobs finish in a reasonable amount of time, everything is fine. If they never finish or need an excessive amount of time to complete, please, read [[this FAQ -> #checkpoints]].

\\\

[[#checkpoints]]
!!! Q27: I have submitted jobs that need some hours to finish. They have been running for days and just few have finished... what is happening? [[[--^ Top -> #top--]]]
'''A:''' First of all, check that your program is properly running. Maybe there are some problems with the data, input files, etc. You can open a shell and check the running job using the =condor_ssh_to_job= command (see [[this FAQ -> ##ssh]]). If you discover that there are some problems with your job and it will not produce valid results, you should stop it as soon as possible to avoid wasting more time and resources, see [[this FAQ -> #bad_inputs]] for more details. If your job is working fine, maybe your job has been killed and restarted several times. Condor shows the ''cumulative running time'' by default, you can see the consumed time of the present execution using =condor_q -run -currentrun= command.

The reason why Condor kill and restart jobs is that it has several runtime environments called ''universes''. By default, all your jobs will go to the most basic (also the simplest) one called =vanilla= universe. In that universe, when Condor detects that a machine is not idle anymore, it will suspend all running jobs for a while, waiting the machine to get idle again. If that does not happen in a given (short) time interval, then Condor will kill all jobs and send them again to the queue with ''Idle'' status, so those jobs will start from the beginning. If your jobs need some hours to finish, probably some of them will be killed before their completion and restarted in other machines, that could happen even several times. 

To avoid that, you can use =standard= universe, since in that universe checkpoints are created so killed jobs can continue in other machines starting from the last checkpoint. But =standard= universe is a little bit more complex, you have to compile your application using =condor_compile= together with your normal compiler, and not all of them are supported... Please, check the %newwin%[[official documentation -> http://research.cs.wisc.edu/htcondor/manual/v8.6/condor_compile.html]] and/or contact us if you need this feature.

However, most times we can solve this problem simply changing the arguments of our jobs. For instance, suppose you have to process 10,000 inputs and each input needs about 2 minutes to be done. You can create 100 jobs to process 100 inputs each, but they will need more than 3 hours to finish and it is likely they will be killed several times. It is better to choose faster jobs that can be finished in about 15-30 minutes so they will have more possibilities to be processed on the same machine without being killed and restarted on other machines. If you choose that each job works with 10 inputs, then you will have 1000 jobs and they will need about 20 minutes to finish, that could be a good approach.

\\\


[[#python-fedora]]
!!! Q28: Some of my python programs work fine, but other fail... [[[--^ Top -> #top--]]]
'''A:''' If you are executing python programs with HTCondor and some jobs work fine and other fail, most probably you are experiencing problems related to the version of Fedora. Most of the old Linux Desktop PCs have installed Fedora21, but newer machines have a more recent version, mostly Fedora26 (although we also have a few with Fedora25). Paths to python libraries are different on the old and new machines, therefore your programs will only work properly on those machines that have the same Fedora version as the machine where you have submitted the jobs.

To fix this issue, you can force HTCondor to only execute jobs on machines with your same version of Fedora, then your environment variables and paths will work. For instance, if you are working on a machine with Fedora21, add the next requirement to force that all your jobs will be executed on machines running Fedora21:

  ='''requirements''' =  ('''OpSysMajorVer''' == '''21''')=

But adding that requirement will limit the number of available machines to execute your program: if you only run on machines with Fedora21, you will be missing all new and faster machines, and if you only run on machines with Fedora26, then you will be losing a big amount of slots since still most of the machines run Fedora21. We recommend you change a bit your submit script to be able to run your python programs on all machines, independently of their O.S (we will only avoid the few machines beginning with ='f'=, since they have a special purpose and python installation there is not the usual one):

  ... 
  =transfer_input_files= = your_program.py

  =getenv=       = =True=
  =environment=  = "PYTHONPATH=/usr/pkg/python/python2.7/lib/python2.7/site-packages"
  =requirements= = ('''!'''=stringListMember=(=substr=(=toLower=(=Target.Machine=),0,1), "f"))

  =transfer_executable= = =False=
  =executable=   = /usr/bin/env
  =arguments=    = =python= your_program.py

  =queue= ...

Example above is just a basic one, you might need to adapt it adding some other commands to transfer your input/output files, add requirements, etc., and, of course, all common commands (see [[common template -> HOWTOs.CondorSubmitFile#common_template]]).  Contact us if you have any doubts.


\\\

[[#matplotlib]] 
!!! Q29: I receive an error when running HTCondor jobs that use python and matplotlib... [[[--^ Top -> #top--]]]
'''A:''' If you are running some =python= jobs that use =matplotlib= (for example, to make some plots and save them to =png= images) and receive errors like:
** =no display name and no $DISPLAY environment variable=
** =: cannot connect to X server :0=

it might be caused because =matplotlib= (and/or some other packages) needs a =DISPLAY= environment variable, which means you have to execute it in a X server, and that is not available when running on HTCondor. In this case, simply use another background that does not need a X server, like =Agg=. For instance, you can adapt next python code when using =matplotlib=:

  =import= matplotlib =as= mpl
  mpl.use(''''Agg'''')
  =import= matplotlib.pyplot =as= plt

  ''# Now use =plt= as usual''
  ''...''
  ''fig = plt.figure()''
  ''...''
  ''fig.savefig('image.png')''
  ''...''

You can find more info about this issue %newwin%[[here -> http://stackoverflow.com/questions/4931376/generating-matplotlib-graphs-without-a-running-x-server]].  

\\\

[[#logviewer]]
!!! Q30: I would like to get more information about the execution, is there an easy way to see the logs created by Condor? [[[--^ Top -> #top--]]]
'''A:''' Yes, there are several possibilities for that. The first step is to create the ''condor log file'' adding the next command to your submit file:
  =log= = file.log      ''#(we recommend you use =your_executable_name.$(Cluster).log= as name for your log file)''

Once you have your condor log file, you can display the information using the following options:
# Directly check the content of the condor log file with any text editor (not recommended)
# Use =condor_userlog <file.log>= to get a summary of the execution.
# Run =condor_history -userlog <file.log>= command in your shell to list basic information contained in the log file. 
# Use =condor_logview <file.log>= to open the ''Condor log viewer'' and see more detailed information in graphical mode, showing the timeline of your jobs and allowing you to perform zooms, filter jobs, etc. 
# There is also an online tool to analyze your log files and get more information: ''Condor Log Analyzer'' (%newwin%[[http://condorlog.cse.nd.edu/]]).

If you just want some general information about Condor queue, the pool of machines, where jobs have been executed on, etc., you can also try our online stats about Condor: [[http://carlota:81/condor_stats/]] and [[nectarino -> http://nectarino/]].
\\\

[[#priority]]
!!! Q31: I am running many jobs, but some are more important than others, how can I prioritize them? [[[--^ Top -> #top--]]]
'''A:''' You can prioritize your jobs (and only your jobs, not other users' jobs) using =priority = <value>= command in your submit files (the higher value, the better priority). Once you have submitted your jobs, you can check or modify their priority by running =condor_prio= in a console. Please, check [[Condor submit file page -> CondorHowTo#howto_priority]] to see more examples, and also [[this FAQ -> #idle]] for more info about users' priorities.

\\\

[[#nomail]]
!!! Q32: I am receiving hundreds of emails from Condor, can I stop that? [[[--^ Top -> #top--]]]
'''A:''' Yes, by default Condor send an email notifying any event related to each job (termination, errors, etc.). If you launch 1000 jobs, that could be really annoying. To avoid that, use next command in your submit file: =notification = Never= (use =Complete= if you only want to know when they finish, =Error= when they fail or =Always= to receive all notifications; we recommend you use =Error=). Also you can change the email address using =notify_user = <email>=. 

''Please, visit [[Condor submit file page -> CondorSubmitFile]] for more info and examples.''

\\\

[[#IDL]]
!!! Q33: What happens with my IDL or Matlab jobs that require licences to run? [[[--^ Top -> #top--]]]
'''A:''' There is a limited number of IDL licences, so if you try to run a large number of IDL jobs they could fail since there may not be enough licences. But using IDL Virtual Machine does not consume any licence, so there will not be limit in the number of simultaneous IDL running jobs, just the number of available slots. See [[detailed information here -> CondorAndIDLVirtualMachine]].

There is a similar limitation with Matlab licences, that could be saved if it is possible for you to create Matlab executables using the %newwin%[[Matlab Compiler -> http://www.mathworks.es/products/compiler/]]. You have more info about this topic %newwin%[[here -> https://htcondor-wiki.cs.wisc.edu/index.cgi/wiki?p=HowToRunMatlab]].

\\\

[[#prepostscripts]]
!!! Q34: I need to run some commands or scripts before/after my executable, is that possible? [[[--^ Top -> #top--]]]
'''A:''' Yes, it is possible adding the =+PreCmd= and =+PostCmd= commands to your submit file, respectively. Running scripts before/after jobs could be useful if you need to do some operations in your input or output files, like changing their names, moving or copying them to other locations, etc. Also you can use these commands for debugging purposes, like using the shell command =tree= to check where your input/output are placed:

 =+PreCmd=        = "preScript.sh"
 =+PreArguments=  = "-iv"
 =+PostCmd=       = "tree"
 =+PostArguments= = "-o tree.out"

 =should_transfer_files= = YES
 =transfer_input_files=  = preScript.sh, /usr/bin/tree

Generally, you also have to add or update the =transfer_input_files= command to include your scripts in the list of files to be copied to the remote machines (make sure that  command =should_transfer_files = YES= is present, too). These commands are intended to be used with user's scripts. If you want to run shell commands (like =tree= in the example), you have to transfer that command (use =which <cmd>= to know its location).

\\\

[[#run_limits]]
!!! Q35: Is it possible to limit the maximum number of concurrent running jobs? [[[--^ Top -> #top--]]]
'''A:''' There are some situations where it could be interesting to limit the number of jobs that can concurrently run. For instance, when your application needs licences to run and few of them are available, or when your jobs access a shared resource (like directly reading/writing files located at =/scratch=, too many concurrent access could produce locks and a considerable slowdown in your and others' computer performance). Please, visit [[Condor submit file page -> CondorHowTo#howto_limit]] to see details and example about how you can add these limits.

\\\

[[#predefined_func]]
!!! Q36: I need to do some complex operations in my submit file, is that possible? [[[--^ Top -> #top--]]]
'''A:''' Yes, Condor has some '''predefined functions''' and some '''special macros''' that you can use in your submit file: 
** evaluate expressions: =eval()=, ... 
** flow control: = ifThenElse()=, ...
** manipulate strings : =size()=, =strcat()=, =substr()=, =strcmp()=, ... 
** manipulate lists: =stringListSize()=, =stringListSum()=, =stringListMember()=, ...
** manipulate numbers: =round()=, =floor()=, =ceiling()=, =pow()=, ...
** check and modify types: =isReal()=, =isError()=, =int()=, =real()=...
** work with times: =time()=, =formatTime()=, =interval()=, ...
** random: =random()=, =$RANDOM_CHOICE()=, =$RANDOM_INTEGER()=, ...
** etc. 

Check documentation to see the complete list of %newwin%[[predefined functions -> http://research.cs.wisc.edu/htcondor/manual/v8.6/4_1HTCondor_s_ClassAd.html#SECTION00512400000000000000]], and also the %newwin%[[function and pre-defined macros -> http://research.cs.wisc.edu/htcondor/manual/v8.6/3_5Configuration_Macros.html#SECTION00451800000000000000]].

\\\

[[#deferral_time]] 
!!! Q37: I would like to submit my jobs now, but they should run at a programmed time, can I do that? [[[--^ Top -> #top--]]]
'''A:''' Sometimes it might be interesting to run your jobs at a specific time, maybe your application depends on some data that are automatically generated at a given time and you want to run your jobs after that moment. Or you want to submit your jobs now, but for any reason they have to run in X hours from the submission time, or you want to regularly run the some jobs several times every day, or every week... Condor has several commands to deal with these situations, please, visit [[Condor submit file page -> CondorHowTo#howto_runintime]] to see details and examples about how you can specify that jobs begin at a programmed time, and also how to program periodical programmed executions.

\\\

[[#lesstime]]
!!! Q38: Jobs leave the queue after finishing. If something went wrong... could they be held or automatically re-executed instead? [[[--^ Top -> #top--]]]
'''A:''' By default all your jobs will leave the queue after completion. But it could happen that some of your jobs get ''complete'' status because they failed (for instance, they could fail due to bad inputs, or there is a missing software package in an specific machine, etc., see also [[#blackholes | this FAQ]]). If that happens and you are able to detect it, you can force that they stay in the queue with 'on hold' status or get the 'Idle' status so they will be executed again. You can control which jobs you want to change the status according to their execution time (if it is abnormally short or long), their exit code, etc. Use =on_exit_hold= command to change its state to "''on hold''"; or  =on_exit_remove= command to re-execute the job (it will get the ''Idle'' status again), adding a reason and/or subcode if you want to do that. Please, visit [[Condor submit file section -> CondorHowTo#howto_failing]] to get detailed info and examples about this feature.

\\\

[[#run_ckpt]]
!!! Q39: I want to do checkpoints of my ''normal'' programs (without using Condor) so I can restart them, is that possible? [[[--^ Top -> #top--]]]
'''A:''' Yes, if your program is written in =C=, =C++= or =fortran= (and you compile/link it using =cc=, =c89=, =CC=, =f77=, =gfortran=, =gcc=, =g++=, =g77= or =ld=) it is likely that you can do checkpointing without using Condor to run it. This is a powerful feature, it means that you can do specific or periodic checkpoints of your program when it is running and, if something happens, you can restart your program from any of those checkpoints.

We will present a full example, suppose we have a =C= program with name =myprogram.c=, then, follow next steps:

# First, you have to compile it using =condor_compile= command {+and+} your normal compiler, this is the only procedure where Condor is involved. Compile it as you normal do, just add =condor_compile= command {+before+} your compilation line.
    =condor_compile gcc= myprogram.c -o myprogram

#%item value=2% ''Optional'': Now you will have an executable called =myprogram=. These executable files created by =condor_compile= are usually quite big since some extra information is added  (like debugging info, symbol tables, etc). This extra information is not needed when running your program, so if you want a smaller executable file you can remove it using linux =strip= command, it may also increase its performance:
    =strip= myprogram

#%item value=3% Our program is ready to be executed. We will {+not+} use =condor_submit=, we will run it directly in our shell as any other program: this is called ''Standalone Checkpointing Mechanism''. Since Fedora has a feature called %newwin%[[''address space randomization'' -> http://research.cs.wisc.edu/htcondor/manual/v8.6/7_1Linux.html#SECTION00811000000000000000]] which is not compatible with the checkpointing mechanism, we have to use linux =setarch= command to disable it:
    =setarch= x86_64 -R ./myprogram   
-> The application will then run and we may receive ''Notice'' lines, that is normal. In this case, checkpoint files will be created in =./myprogram.ckpt=
    Condor: Notice: Will checkpoint to ./myprogram.ckpt
    Condor: Notice: Remote system calls disabled.

#%item value=4% To deal with checkpoints, we need to know the Proccess ID (=PID=) of your running program. We can get it using linux =ps= command (PID should appear in the second column, after the username):
    =ps aux= | =grep= myprogram    ''#Suppose that the PID is 12233''

#%item value=5% Once we have the =PID=, we can force that your application writes a checkpoint sending it a =SIGUSR2= signal at any time:
    =kill -USR2= 12233
-> After sending that signal, the checkpoint should have been created and the application may be still running, check that a file called =myprogram.ckpt= exists in the same directory. If you want to do periodic checkpoints, you can write a simple shell script or use =cron= to regularly send =SIGUSR2= signals to your program. Bear in mind that all checkpoint files are created with the same name, so if you want to keep all checkpoints, you should rename them before creating a new one.

#%item value=6% We can also force your application to write the checkpoint and stop the execution immediately afterwards. To do that, use =SIGTSTP= signal instead, or press =Ctrl+Z=:
    =kill -TSTP= 12233
-> Now you can check that the checkpoint was created and your program is not running.

#%item value=7% To restart the execution using an specific checkpoint, run your program again and add =-_condor_restart= option and the name of the checkpoint:
    =setarch= x86_64 -R ./myprogram =-_condor_restart= myprogram.ckpt
-> Your application should be now running from the same point where the checkpoint was created.

'''Notes:''' 
** If you have problems creating the checkpoints or running/restarting your application, add =-L= and/or =-B= options to =setarch=. 
** Bear in mind that programs should meet %newwin%[[some limitations -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_4Running_Job.html]].
** If your application is written in the =C= language and you want a deeper control of the checkpoint feature, you can add some functions provided by the %newwin%[[''Condor Checkpoint Library'' -> http://research.cs.wisc.edu/htcondor/manual/v8.6/4_2HTCondor_s_Checkpoint.html#SECTION00524000000000000000]] to your program.


\\\

[[#fault_tolerant]]
!!! Q40: I have a fault tolerant application, can I save the state and restore it when executing with Condor?[[[--^ Top -> #top--]]]

'''A:''' Yes, Condor allows you to use your fault tolerant programs. You only need to use next command to specify that Condor has to save files when your program fails or Condor needs to evict it:

 =when_to_transfer_output= = ON_EXIT_OR_EVICT

You have more information in the Condor manual: ''The =ON_EXIT_OR_EVICT= option is intended for fault tolerant jobs which periodically save their own state and can restart where they left off. In this case, files are spooled to the submit machine any time the job leaves a remote site, either because it exited on its own, or was evicted by the HTCondor system for any reason prior to job completion. The files spooled back are placed in a directory defined by the value of the SPOOL configuration variable. Any output files transferred back to the submit machine are automatically sent back out again as input files if the job restarts.''

\\\

[[#dependencies]]
!!! Q41: My jobs have some dependencies, is it possible to specify that? [[[--^ Top -> #top--]]]
'''A:''' Yes, if you have some dependencies in your inputs, outputs or execution order, you can specify it using a ''directed acyclic graph (DAG)''. Condor has a manager (called [[http://research.cs.wisc.edu/htcondor/manual/v8.6/2_10DAGMan_Applications.html | DAGMan]]) to deal with these jobs, but you must use special commands, like submitting your jobs with =condor_submit_dag=. Please, visit [[Condor submit file page -> CondorHowTo#howto_dagman]] for more info and examples.

\\\

[[#morefaqs]]
!!! Q42: My question is not in this list or I need further information, where can I find it? [[[--^ Top -> #top--]]]
'''A:''' There are more %newwin%[[FAQs and How-to recipes -> https://htcondor-wiki.cs.wisc.edu/index.cgi/wiki?p=HowToAdminRecipes]] available at Condor site and the %newwin%[[official Users' Manual -> http://research.cs.wisc.edu/htcondor/manual/v8.6/2_Users_Manual.html]] is useful, too. Also you can visit other sections of Condor at the SIEpedia, like [[useful commands -> CondorUsefulCommands]] or [[Submit files -> CondorSubmitFile]]. If you need further information, please, contact us (you can find [[here -> Condor#contact]] our contact data).



!! Check also:

[[Category.HOWTOs | Section: HOWTOs ]]

*** HTCondor and IDL
>>frame<<
(:table border=0 cellpadding=5 cellspacing=0 width=100% :)
(:cell align=center valign=middle :) [[Introduction -> Condor]]
(:cell align=center valign=middle :) [[Useful Commands -> CondorUsefulCommands]]
(:cell align=center valign=middle :) [[Submit files (desc. & examples) -> CondorSubmitFile]]
(:cell align=center valign=middle :) [[Submit files (HowTo) -> CondorHowTo]]
(:cell align=center valign=middle :) [[FAQs -> CondorFAQs]]
(:cell align=center valign=middle :) '''HTCondor and IDL'''
(:tableend:)
>><<


(:title HTCondor(6): HTCondor and IDL :)
!HTCondor and IDL

!! How to run IDL jobs with HTCondor unencumbered by IDL licences

A recurring question to us has been whether IDL jobs can be run with HTCondor. The '''use of IDL with HTCondor is limited by the number of available licenses''' at any given time (which meant that perhaps you could run 20-30 jobs simultaneously). However, we strongly recommend you use the '''IDL Virtual Machine (IDL VM)''' when possible  since it lets you run an IDL "executable" file (=SAVE= file) '''without the need for licenses''', so there will be no limits on the number of jobs you can concurrently run. Most of you probably know the necessary steps to create a =SAVE= file, but if in doubt see %newwin%[[ http://www.exelisvis.com/docs/Creating_SAVE_Files_of_P.html | here]] for an example on how to create such a file. 


(:if false:)
The problem is that the IDL Virtual Machine is meant to be run interactively in a server with X running and HTCondor is not particularly well suited for this. But you can manage it with a little ingenuity. Ángel de Vicente developed a little program some years ago to take care of all the details and overall it works without any problems, and now we can submit hundreds of IDL jobs simultaneously to our HTCondor pool! Read on for all the details...
(:if end:)


>>frame bgcolor=#F2DEDE padding=6px<<
'''Note:''' If for any reason you are '''not able''' to generate a =SAVE= file, please, [[contact us -> Condor#contact]] and we will help you to find other ways of executing IDL with HTCondor. Remember that running jobs in IDL with no Virtual Machine consumes licences and you must [[limit the number of concurrent jobs -> CondorSubmitFile#howto_limit]] using a command like =concurrency_limits = idl:40=
>><<

!!! Submitting a job to HTCondor using the IDL Virtual Machine (for the impatient)

All you will need to do in order to run your IDL jobs with the Virtual Machine is:

# Modify your IDL program so that it will take an argument (from 0 to the number of jobs you want to submit with HTCondor) and act according to that argument. A sample IDL program to illustrate this could be the following one (we will name it =subs.pro=):

   =PRO= SUBS

   args = '''=command_line_args()='''

   =print=, 'Original argument   ', args(0)
   =print=, 'Modified   ', args(0)*2

   =print=, 'Wasting ', args(0), ' seconds'
   =wait=, args(0)

   =print=, 'I (IDL) have finished...'
   =END=


#%item value=2%  Create a =SAVE= file from it. Usually you just need to compile your program and generate the =SAVE= file with your compiled routines. The name of the =SAVE= file has to be the same as the routine you want to execute. If you have any issue creating this file, please, check %newwin%[[ http://www.exelisvis.com/docs/Creating_SAVE_Files_of_P.html | more information and examples]]):

   [...]$ =idl=
   IDL> =.FULL_RESET_SESSION=
   IDL> =.COMPILE= subs.pro
   IDL> =RESOLVE_ALL= 
   IDL> =SAVE, /ROUTINES, FILENAME=='subs.sav'
   IDL> =exit=
   [...]$ 


#%item value=3%  Verify that this works with the IDL Virtual Machine without HTCondor (the IDL Virtual Machine will show you a Splash screen, where you will have to press the button "Click to Continue", and which then will proceed with the execution of the program).

   [...]$ =idl -vm=subs.sav -args 10=
   IDL Version 8.3 (linux x86_64 m64). (c) 2013, Exelis Visual Information Solutions, Inc.

   Original argument   10
   Modified         20
   Wasting 10 seconds
   I (IDL) have finished...
   [...]$

#%item value=4%  Write the HTCondor submit file. If you are new to HTCondor, you might need to look our [[ documentation about submit files -> http://research.iac.es/sieinvens/siepedia/pmwiki.php?n=HOWTOs.CondorSubmitFile]] (check also other sections like [[Introduction -> http://research.iac.es/sieinvens/siepedia/pmwiki.php?n=HOWTOs.Condor]], [[Useful commands -> http://research.iac.es/sieinvens/siepedia/pmwiki.php?n=HOWTOs.CondorUsefulCommands]] or [[FAQs -> http://research.iac.es/sieinvens/siepedia/pmwiki.php?n=HOWTOs.CondorFAQs]]). In the following example you will need to modify:
** The arguments line, which has 4 items: the first one is the path to the =SAVE= file; the second one is the argument to pass to it; the third one is 1 if you use a left-handed mouse, and 0 otherwise; and the fourth one is 1 if you want verbose messages for debugging, or 0 otherwise)
** NOTE: leave the line "=next_job_start_delay = 1="

    N            = 20
    ID           = $(Cluster).$(Process)
    FNAME        = idl_vm
    =Universe=     = vanilla                   
    =Notification= = error
    =should_transfer_files=   = YES 
    =when_to_transfer_output= = ON_EXIT                                               

    =output=       = $(FNAME).$(ID).out
    =error=        = $(FNAME).$(ID).err
    =Log=          = $(FNAME).$(Cluster).log    

    =transfer_input_files=   = subs.sav
    ''#Use next command when specific output files hast to be copied back to your machine:''
    ''#=transfer_output_files=  = ''
    =Executable=   = /home/condor/SIE/idlvm_with_condor.sh
    =arguments=    = subs.sav $(Process) 0 1

    =next_job_start_delay= = 1                                  
    =queue= $(N)


#%item value=5%  Submit it to HTCondor and go for a cup of coffee while the programs are executed...


>>frame<<
[-'''Note: Why some of my jobs get the ''on hold'' status?'''-]

[-When executing jobs with the IDL VM, it could happen that some jobs get the ''on hold'' status. That means some problems occurred with your jobs and HTCondor is waiting that you solve them before continuing with the execution. You can use =condor_q -hold= command to get more info about the reason why they were held. If there is no apparent cause and you are sure that your jobs are correct, the problem might be related to the initialization of the IDL Virtual Machine: sometimes this process takes longer than usual on some specific machines, and if in the meanwhile more jobs try to initialize other IDL VM on the same machine, some of them could fail and your jobs will get the ''on hold'' status. This could randomly happen and there is not an easy way to avoid that.-] 

[-If you are 100% sure that your program runs fine and the problem is caused by IDL, then you can use =condor_release -all= command and all your held jobs will get the idle status again so they will hopefully run with no problems on other machines. If some of your jobs fail again, you may need to repeat the =condor_release= command several times till all the jobs are done. If that happens too many times, you can use some commands to perform recurring releases: for instance, you can add a =periodic_release= command in your submit file (see this [[example -> CondorSubmitFile#howto_failing]]) and HTCondor will periodically release your held jobs, or you can use a combination of =condor_release= and some shell commands like =crontab=, =watch=, etc.-]

[-On the other hand, if after releasing jobs they get the ''on hold'' state again, then the problem might not be related to IDL and you should check your application to find the error (remember that you can get more information about held jobs using =condor_q -hold=).-]
>><<

(:if false:)
!!! How is it all done?

All the real work to avoid having to press the "Click to continue" button in all the virtual machines is done by the alpha-version idlvm_with_condor.sh script. This script makes use of: [[http://en.wikipedia.org/wiki/Xvfb | Xvfb]] to create a virtual X11 server where the IDL splash screen will be created (but without showing anything in the screen); and [[http://hoopajoo.net/projects/xautomation.html | xautomation]] to automatically press the button for you. The script has to take care of two important things: how to create several virtual X servers on multicore machines without conflicting with each other; and how to cleanly kill all processes when HTCondor wants to reclaim the machine for its "owner" before the IDL code has finished. The script is still work in progress (since some things could be performed probably more efficiently), but in its present form seems to work pretty well (let me know if you have any trouble with it). The script is:

 [@
#!/bin/bash                                                                                                                                                  

###### Script to run an IDL executable file (a SAVE file) in the IDL Virtual Machine 
###### with HTCondor.     
                                                                                                                                                   
###### Written by Angel de Vicente - 2009/10/26     
                                                                                                                                                  
###### Usage:    
###### /home/condor/SIE/idlvm_with_condor.sh idl_prog argument zurdo verbose       
###### Example:                                                                                  
###### /home/condor/SIE/idlvm_with_condor.sh /home/angelv/test.sav 10 0 1     
######      will press button as a right-handed person, and will print messages 
######      of its progress, and will also print debugging messages.  

XVFB_BIN="/home/condor/SIE/Xvfb"
XTE_BIN="/home/condor/SIE/xte"

## This allows for job control inside the script                                                                                                             
set -o monitor

##                                                                                                                                                           
if [ $3 -eq 1 ]; then
mousebutton=3
else
mousebutton=1
fi

if [ $4 -eq 1 ]; then
echo "Running on machine `uname -a`"
fi

## When we do a condor_rm or when the job is evicted, a SIGTERM to the executable file           
## (i.e., this script is issued, so we make sure we catch that signal, and then kill the     
## virtual X and the IDL Virtual Machine    
trap cleanup SIGINT SIGTERM SIGTSTP

function cleanup ()
{
kill %2
if [ $4 -eq 1 ]; then
echo "IDL Terminated"
fi

sleep 1

kill %1
if [ $4 -eq 1 ]; then
echo "Xvfb killed"
fi

exit
}


## Find free server number           

## A cheap way of avoiding two HTCondor processes in the same (multicore) machine to have a race condition   
## and ending up with the same server number is to sleep a random number of seconds before trying to find    
## which server number is free                                          
## NOT ROBUST ENOUGH AND A BIT WASTEFUL. SHOULD FIND A BETTER WAY OF DOING THIS  
##                                                                                                                                                           
## We comment this out, assuming the submit HTCondor file has next_job_start_delay = 1     
#RANGE=10                                                                            
#number=$RANDOM                                                                           
#let "number %= $RANGE"                                                                       
#if [ $4 -eq 1 ]; then                 
#echo "Sleeping $number seconds"                                         
#fi                                                                              
#sleep $number                                                                                

## Find the free number    
i=1
while [ -f /tmp/.X$i-lock ]; do
        i=$(($i + 1))

if [ $i -eq 10 ]; then
    i=1
 if [ $4 -eq 1 ]; then
 echo "No servers available under 10. Waiting 5 minutes..."
 sleep 300
 fi
fi
done


$XVFB_BIN :$i -screen 0 487x299x16 &
sleep 5
export DISPLAY=":$i.0"
if [ $4 -eq 1 ]; then
echo "Virtual X Server $i created"
fi

idl -vm=$1 -args $2 &
sleep 10
if [ $4 -eq 1 ]; then
echo "IDL Virtual Machine started"
fi

$XTE_BIN 'mousemove 394 235'
$XTE_BIN "mouseclick $mousebutton"
if [ $4 -eq 1 ]; then
echo "Click to continue pressed"
fi


if [ $4 -eq 1 ]; then
echo "Waiting for IDL"
fi
wait %2

if [ $4 -eq 1 ]; then
echo "IDL Finished"
fi

sleep 2

kill %1
if [ $4 -eq 1 ]; then
echo "Xvfb killed"
fi
 @]

-----
(:ifend:)

!! Check also:


** An Overview of the HTCondor System                              :noexport:

*** On High-Throughput Computing

For many scientists, the quality of their research is heavily dependent on
computing throughput. It is not uncommon to find problems that require weeks or
months of computation to solve. Scientists involved in this type of research
need a computing environment that delivers large amounts of computational power
over a long period of time. Such an environment is called a High-Throughput
Computing (HTC) environment. In contrast, High-Performance Computing (HPC)
environments deliver a tremendous amount of power over a short period of time.
HPC environments are often measured in terms of FLoating point OPerations per
Second (FLOPS). Many scientists today do not care about FLOPS; their problems
are on a much larger scale. These people are concerned with floating point
operations per month or per year. They are interested in how many jobs they can
complete over a long period of time.

A key to high throughput is the efficient use of available resources. Years
ago, the scientific community relied on large mainframe computers to do
computational work. A large number of individuals and groups would have to pool
their financial resources to afford such a computer. It was not uncommon to
find just one such machine at even the largest research institutions.
Scientists would wait their turn for mainframe time, and they would be allocated
a specific amount of time. Scientists limited the size and scope of their
problems to ensure completion. While this environment was inconvenient for the
users, it was very efficient, because the mainframe was busy nearly all the
time.

As computers became smaller, faster and less expensive, scientists moved
away from mainframes and purchased personal computers or workstations. An
individual or a small group could afford a computing resource that was available
whenever they wanted it. The resource might be slower than the mainframe, but
it provided exclusive access. Recently, instead of one large computer for an
institution, there are many workstations. Each workstation is owned by its
user. This is distributed ownership. While distributed ownership is more
convenient for the users, it is also less efficient. Machines sit idle for long
periods of time, often while their users are busy doing other things.
*Condor takes this wasted computation time and puts it to good use.* The
situation today matches that of yesterday, with the addition of clusters in the
list of resources. These machines are often dedicated to tasks. Condor manages
a cluster's effort efficiently, as well as handling other resources.

To achieve the highest throughput, Condor provides two important functions.
First, it makes available resources more efficient by putting idle machines to
work. Second, it expands the resources available to users, by functioning well
in an environment of distributed ownership.

*** Why use Condor?

Condor takes advantage of computing resources that would otherwise be wasted
and puts them to good use. Condor streamlines the scientist's tasks by allowing
the submission of many jobs at the same time. In this way, tremendous amounts
of computation can be done with very little intervention from the user.
Moreover, Condor allows users to take advantage of idle machines that they would
not otherwise have access to.

Condor provides other important features to its users. Source code does not
have to be modified in any way to take advantage of these benefits. Code that
can be re-linked with the Condor libraries gains two further abilities: the jobs
can produce checkpoints and they can perform remote system calls.

A checkpoint is the complete set of information that comprises a program's
state. Given a checkpoint, a program can use the checkpoint to resume
execution. For long-running computations, the ability to produce and use
checkpoints can save days, or even weeks of accumulated computation time. If a
machine crashes, or must be rebooted for an administrative task, a checkpoint
preserves computation already completed. Condor makes checkpoints of jobs,
doing so periodically, or when the machine on which a job is executing will
shortly become unavailable. In this way, the job can be continued on another
machine (of the same platform); this is known as process migration.

A user submits a job to Condor. The job is executed on a remote machine
within the pool of machines available to Condor. Minimal impact on and the
security of the remote machine are preserved by Condor through remote system
calls. When the job does a system call, for example to do an input or output
function, the data is maintained on the machine where the job was submitted.
The data is not on the remote machine, where it could be an imposition.

By linking in a set of Condor libraries, system calls are caught and
performed by Condor, instead of by the remote machine's operating system.
Condor sends the system call from the remote machine to the machine where the
jobs was submitted. The system call's function executes, and Condor sends the
result back to the remote machine.

This implementation has the added benefit that a user submitting jobs to
Condor does not need an account on the remote machine.

*** Small Businesses Like Condor


Condor starts with the assumption that you have relatively long running tasks
that do not require user interaction. While this is not common in small
business environments, it does occur. To take examples from businesses that we
know are using Condor, tasks involve rendering 3D scenes for a movie, performing
a nightly build and regression test on software under development, simulating
and analyzing stock market behavior, and simulating the effects of various
political decisions. Modern video codecs often take a long time to encode, and
any business generating video files could use Condor to manage the process. A
small biotechnology company might want to use Condor to manage the long running
pattern searches over the human genome. A small engineering company might have
similar needs with long running simulations of stress on a building, wind tunnel
simulations for cars, or circuit simulations for new electronics devices.

Condor helps those businesses with long running tasks. Such businesses may be
using some sort of batch system already, or operate by starting the program each
evening, hoping that it finishes before they return in the morning. This is the
sort of situation in which Condor excels. Condor also saves time and effort
when the time it takes a user to get jobs executing is longer than a few
moments, or when a large number of jobs (of any size) must be started.

Condor allows almost any application that can run without user interaction to be
managed. This is different from systems like SETI@Home and ProteinFolding@Home.
These programs are custom written. Most small companies will not have the
resources to custom build an opportunistic batch processing system.
Fortunately, Condor provides a general solution.

Condor can be useful on a range of network sizes, from small to large. On a
single machine, Condor can act as a monitoring tool that pauses the job when the
user uses the machine for other purposes, and it restarts the job if the machine
reboots. On a small dedicated cluster, Condor functions well as a cluster
submission tool. If you have long running jobs but can not afford to purchase
dedicated machines to run the jobs, you can use Condor's opportunistic behavior
to scavenge cycles from desktop machines when their users are not using the
machines (for example, in the evening or during lunch).

In a typical business these desktop machines are unused for twelve or more hours
per day. This processing time is available at no extra cost under Condor. A
long running job expected to require the exclusive use of a workstation for two
days may be able to produce results overnight.

Condor's functionality called DAGMan, manages the submission of a large number
of jobs with simple or complex dependencies on each other. A simple example is
that job A and B must complete before job C can start. A rendering example of
this would be that job A renders a 3D special effect, job B renders the
background, and job C superimposes the special effect onto the background.
Condor DAGMan can also be used to run a series of jobs (linearly).

If the small business is using Globus grid resources to gain access to more
computing power than it has available in house, Condor-G provides reliability
and job management to their jobs. Or, with Condor glidein, remote Globus grid
resources can transparently become part of a virtual Condor cluster.

*** Everyone Benefits

As more machines join a Condor pools, the quantity of computational
resources available to the users grows. While Condor can efficiently manage the
queuing of jobs where the pool consists of a single machine, Condor works
extremely well when the pool contains hundreds of machines.

A contributor to Condor's success is its ClassAd mechanism. Jobs want to
find machines upon which they can execute. A job will require a specific
platform on which to execute. Machines have specific resources available, such
as the platform and the amount of available memory. A separate ClassAd is
produced for each job and machine, listing all attributes. Condor acts as a
matchmaker between the jobs and the machines by pairing the ClassAd of a job
with the ClassAd of a machine.

This mechanism is much more flexible than the simple example of matching the
platforms of jobs with those of machines. A job may also prefer to execute on a
machine with better floating point facilities, or it may prefer to execute on a
specific set of machines. These preferences are also expressed in the ClassAd.
Further, a machine owner has great control over which jobs are executed under
what circumstances on the machine. The owner writes a configuration file that
specifies both requirements and preferences for the jobs. The owner may allow
jobs to execute when the machine is idle (identified by low load and no keyboard
activity), or allow jobs only on Tuesday evenings. There may be a requirement
that only jobs from a specific group of users may execute. Alternatively, any
of these may be expressed as a preference, for example where the machine prefers
the jobs of a select group, but will accept the jobs of others if there are no
jobs from the select group.

In this way, machine owners have extensive control over their machine. And,
with this control, more machine owners are happy to participate by joining a
Condor pool. 


** Condor Code of Conduct                                          :noexport:

Condor is a terrific tool for performing parametric studies and other type of
jobs that can run simultaneously and independently in a number of
machines. Nevertheless, under certain circumstances, if you are not careful you
can bring the network to a crawl. To avoid these situations, please stick to
this simple code of conduct:

+ Submit jobs only from your machine or from a machine whose owner you have
  contacted and is aware of the extra load that you will put on it. No
  submission from public machines, sorry! (For each Condor running job, there is
  a process running in the submitting machine, plus lots of network connections,
  so the submitting machine pays a big toll, which is not fair to pass it to
  someone else unawares).

+ If you plan to run I/O intensive code (i.e. code that reads or writes to disk
  very large files, or small ones but very often), get in touch with me
  first. Depending on how I/O intensive your code is, it might not be worth it
  to use Condor, or I might be able to offer you counsel on how to best do
  it. Hopefully your Condor submission will perform faster if we take this into
  account.

+ Test your submission. Don't go nuts and submit a 10000 jobs submission without
  first making sure the whole thing will work with a smaller subset. Start
  small, verify that things are going OK, check the logs to see that the jobs
  can access all the necessary files, etc. and only when you are satisfied that
  things are working go for the big submission.

Please stick to these basic rules so that we can avoid Condor affecting other
users' work.




** Manual del usuario de Condor (Adrián Santos Marrero)            :noexport:

*** ¿Qué es Condor?

Condor es un proyecto de la Universidad de Wisconsin-Madison (UW-Madison). Está
ideado para aprovechar al máximo la capacidad computacional de una red de
ordenadores.  Normalmente sólo disponemos de la potencia del ordenador que
estamos usando para ejecutar nuestros trabajos, y si, por ejemplo, tuviéramos
que lanzar 100 veces un mismo programa con distinta entrada, tendríamos que
hacerlo secuencialmente con la consecuente pérdida de tiempo. Condor nos permite
ejecutar nuestro trabajo en tantas máquinas como haya disponibles, por lo que,
en el mejor de los casos, nuestro trabajo finalizará en el tiempo que tarda en
ejecutarse el más lento de nuestros procesos.

Condor pone a nuestra disposición toda la capacidad de cálculo desaprovechada en
nuestra red, de esta manera, los recursos disponibles se incrementan
considerablemente.

Condor nos será útil siempre que necesitemos ejecutar un trabajo intenso, tanto
computacionalmente como en el tiempo. Al aprovechar solamente recursos ociosos
no influye en el uso cotidiano de los ordenadores (ver sección "¿Cómo
funciona?").

Además, nos permite:
+ Conocer el estado de nuestros trabajos en cada momento
+ Implementar nuestras propias políticas de orden de ejecución
+ Mantener un registro de la actividad de nuestros trabajos
+ Añadir tolerancia a fallos a nuestros trabajos

*** ¿Cómo funciona?

Básicamente, enviamos un trabajo a Condor, este lo pone en una cola, lo ejecuta y 
finalmente nos avisa del resultado.

Vamos a verlo un poco más de cerca para intentar comprender como funciona:

+ Normalmente usaremos Condor porque queremos ejecutar repetidas veces un
  programa (posiblemente con diferente entrada) o porque se requiere mucho
  tiempo para su finalización y, mientras tanto, necesitamos seguir usando
  nuestra máquina.
+ Inicialmente nuestro trabajo no necesita ninguna modificación para ser enviado
  a Condor. Sin embargo, tenemos que escribir un archivo de descripción del
  envío (ver sección \ref{sec::submit_file}). 
+ Una vez enviado a Condor, podemos seguirle la pista a nuestro trabajo con el
  comando {\tt condor\_q} (ver sección \ref{sec::condor_q}) o mediante un
  registro de actividad (fichero {\tt Log}). 
+ Condor realiza periódicamente búsqueda de trabajos nuevos e intenta casarlos
  con recursos disponibles. Si no hay disponibles, el trabajo se quedará a la
  espera del próximo ciclo. 
+ Una vez Condor ha encontrado una máquina capaz de ejecutar el trabajo
  pendiente, lo envía y empieza la ejecución. Pueden ocurrir varias cosas
  mientras se está ejecutando un trabajo:
  + Lo más deseable sería que finalizara con éxito. Si esto ocurriera se
    enviarían las salidas del trabajo a donde haya especificado el usuario y se
    mandaría un correo electrónico al mismo con un resumen de lo ocurrido. 
  + En el caso de que la máquina deje de estar utilizable (porque ha vuelto el
    usuario o alguno de los motivos explicados más abajo) el proceso deberá
    abandonarla. Si se estaba ejecutando en el universo ``standard'', se
    realizaría una imagen del estado actual del proceso ({\em checkpoint}) (ver
    sec.  \ref{sec::universos}) y se finalizaría su ejecución. En el resto de
    universos, simplemente se instará al trabajo a que finalize su ejecución
    (para ello se le envía la señal SIGTERM y si, pasado un cierto tiempo, no
    muere se le envía SIGKILL). 
  + Otra posibilidad es que el propietario del trabajo haya decidido borrarlo
    de Condor (ver sección \ref{sec::condor_rm}) con lo que finalizará su
    ejecución inmediatamente. 

A la hora de enviar nuestro trabajo hemos de tomar algunas precauciones:
+ Tenemos que elegir un ``universo'' adecuado: en la mayoría de los casos nos
  bastará con el universo ``vanilla'' (ver sec. \ref{sec::universos}). 
+ Nuestro trabajo ha de ser capaz de ejecutarse en un sistema de procesamiento
  por lotes: 
  + Ha de ser capaz de ejecutarse en ``background''. No ha de solicitar
    información interactivamente.
  + Puede usar STDIN, STDOUT y STDERR, pero estos serán archivos en vez de los
    periféricos habituales (teclado y pantalla). 
  + Ha de organizar sus archivos de datos. Por ejemplo, separados por ejecuciones.

Notar que Condor no influye en el uso cotidiano de nuestros ordenadores, ya que solo 
utilizará máquinas ociosas, o lo que es lo mismo, las que cumplan los siguientes
puntos: 
+ No se está usando el ratón o teclado
+ No se está usando la máquina remotamente
+ No se está usando para ejecutar ningún otro trabajo.

*** ¿Cómo lo uso?

Condor está compuesto de varias aplicaciones que nos permiten:
+ Enviar trabajos a Condor: {\em condor\_submit}.
+ Controlar el estado de nuestros trabajos: {\em condor\_q}.
+ Borrar un trabajo: {\em condor\_rm}.
+ Obtener información del estado de Condor: {\em condor\_status}.

**** Enviando trabajos. {\em condor\_submit}

Para realizar el envío tenemos que especificar algunas opciones para que Condor
sea capaz de manejar adecuadamente nuestro trabajo. Estas opciones incluyen qué
comando se va a ejecutar, cuantas veces y con qué entrada, donde irá la salida
de cada comando, requisitos de la máquina donde se ha de ejecutar, etc. Esta
información se especifica en un fichero de texto que llamaremos fichero de
descripción del envío. La sintaxis a seguir la veremos a continuación.

***** Fichero de descripción del envío

Este archivo será la entrada al comando {\em condor\_submit}. Un ejemplo de
fichero de envío se puede ver en el siguiente ejemplo:

#+begin_example
############################
#
# foo.submit
# 
# Ejemplo 1: Archivo simple de descripción del envío.
#
############################

Executable   = foo
Universe     = vanilla
input        = test.data
output       = foo.out
error        = foo.err
Log          = foo.log
Queue
#+end_example

Una vez guardado este fichero, le indicamos a Condor que lo ejecute de la
siguiente manera: 

#+begin_example
[adrians@trevina ~]$ condor_submit foo.submit
Submitting job(s).
Logging submit event(s).
1 job(s) submitted to cluster 3.
#+end_example

Veamos con más detalle el contenido del archivo:

+ *Executable*: Especificamos la ruta y el nombre del archivo ejecutable. En el
  ejemplo solo se ha especificado el nombre, por lo que se espera que {\tt foo} y {\tt foo.submit} estén en el mismo directorio.
+ *Universe*: Elegimos un universo, por defecto se usará el universo
  ``vanilla''. Ver sección \ref{sec::universos}.} 
+ *input*: Archivo desde donde se leerá la entrada por defecto (stdin). Si no se
  especifica, se utilizará el archivo {\tt /dev/null}. 
+ *output*: Archivo donde se escribirá la salida del comando (stdout). Si no se especifica, se utilizará el archivo {\tt /dev/null}.
+ *error*: Archivo donde se escribirá la salida de error del comando
  (stderr). Si no se especifica, se utilizará el archivo {\tt /dev/null}.
+ *Log*: Archivo donde Condor almacenará un histórico de lo que le ha ocurrido a
  nuestro trabajo e información como su código de salida, errores relacionados con Condor, etc.
+ *Queue*: Indica que Condor va a ejecutar una vez este trabajo, podemos
  especificar un número (por ejemplo {\tt Queue 10} o escribir varias veces {\tt
  Queue} con lo que se ejecutará tantas veces como hayamos escrito). Podemos
  especificar opciones para cada ejecución, por ejemplo: podemos tener un fichero de entrada ({\tt input}) para cada ejecución de nuestro trabajo.

Veamos ahora otro ejemplo, esta vez un poco más complicado:

#+begin_example
############################
#
# complex.submit
# 
# Ejemplo 2: Archivo de descripción del envío usando 
# Requirements y Rank.
#
############################

Executable   = complex
Universe     = vanilla
Requirements = Memory >= 64 && OpSys == "Linux" && Arch == "INTEL"
Rank         = Memory
input        = data.$(Process)
output       = out.$(Process)
error        = err.$(Process)
Log          = complex.log
Queue 10
#+end_example

En este ejemplo introducimos algunas opciones nuevas:
\begin{description}
	\item[Requirements:]{Especificamos los requisitos que se han de cumplir para que nuestro
trabajo se ejecute. En el ejemplo obligamos a que la máquina candidata tenga un procesador INTEL
o compatible, esté ejecutando Linux y, además, no permitimos que tenga menos de 64MB de memoria RAM.
%Notar que Condor siempre completa estas expresiones y, por ejemplo, obliga a que nuestros trabajos se
%ejecuten en la misma arquitectura y sistema operativo que desde el que se realizó el envío (siempre y 
%cuando no especifiquemos lo contrario).
En el caso de que no especifiquemos explícitamente los requisitos sobre
arquitectura y sistema operativo, Condor los creará automáticamente para que
nuestros trabajos se ejecuten en máquinas con la misma arquitectura y el mismo
sistema operativo que la máquina desde donde se envió el trabajo.
Para ver los requisitos finales de nuestro trabajo (una vez 
enviado a Condor) podemos ejecutar {\tt condor\_q -l}, este comando nos mostrará información detallada
de cada trabajo enviado.}
	\item[Rank:]{Define un valor numérico que expresa preferencia, es decir, dadas todas las máquinas
candidatas a ejecutar nuestro trabajo, Condor evalúa esta expresión en cada una
de ellas y elegirá aquellas donde su valor sea mayor. En el ejemplo, preferimos
aquellas máquinas que tengan mayor cantidad de memoria RAM.}
\end{description}
Para obtener más información acerca del uso de {\tt Requirements} y {\tt Rank} vea la \htmladdnormallink
{sección 2.5.2}{http://goya/inves/SINFIN/Condor/v6.6/2\_5Submitting\_Job.html\#SECTION00352000000000000000}
del manual de Condor.

En el ejemplo 2 también hemos usado unos nombres de archivo un tanto especiales
en las opciones {\tt input}, {\tt output} y {\tt error}. El uso de la cadena
``\$(Process)'' implica que allí donde aparezca será sustituido por el número
del trabajo que se va a ejecutar, es decir, en el ejemplo se crean 10 trabajos
({\tt Queue 10}) y cada uno de ellos tendrá como entrada el archivo data.0, data.1,
\ldots~dependiendo de que número de trabajo sea. Lo mismo ocurrirá con los
archivos de salida ({\tt output}) y salida de error ({\tt error}).

\subsubsection{Universos}
\label{sec::universos}

Para Condor, un ``universo'' define un conjunto de características que marcarán
el entorno de ejecución de nuestro trabajo. Por ejemplo, para trabajos en Java
existe un universo ``Java''. Este, por ejemplo, permitirá capturar las excepciones
de la máquina virtual de Java o solo ejecutará los trabajos en máquinas con la
máquina virtual disponible.

Básicamente podemos elegir entre tres universos:
\begin{description}
	\item[vanilla] Es el universo por defecto y, además, es el menos restrictivo con
	los trabajos que se pueden enviar (acepta cualquier programa escrito en cualquier 
	lenguaje). La parte negativa es que no permite ``checkpointing'' o llamadas al sistema
	remotas (ver universo ``standard'' a continuación).
	\item[standard] Este universo soporta ``checkpointing'' y llamadas al sistema remotas.
	Hacer ``checkpointing'' de un programa significa guardar en disco su estado
	actual de ejecución antes de parar el proceso. Gracias al ``checkpointing'', un
	programa se puede parar (guardándose su estado en un fichero), y más adelante se
	puede volver a ejecutar desde el punto exacto en que se abortó. Para que un
	programa pueda ser enviado a este universo ha de estar enlazado con las
	librerías de Condor (compilado usando {\em condor\_compile}). Presenta algunas
	restricciones en los trabajos que se pueden enviar.
	\item[java] Este universo está destinado para el envío de trabajos escritos en Java.
\end{description}

Para información más detallada acerca de cada universo puede visitar la 
\htmladdnormallink{sección 2.4.1 del manual}{http://goya/inves/SINFIN/Condor/v6.6/2\_4Road\_map\_Running.html\#SECTION00341000000000000000}.

\subsubsection{Sobre el acceso a los ficheros}
	El único universo que dispone de un sistema de llamadas al sistema remotas es el ``standard'', 
debido a esto, cuando use otro universo (por ejemplo el ``vanilla'') asegúrese de que los archivos de entrada
y salida de sus trabajos se escriban o lean en directorios compartidos por NFS (es decir, visibles desde
todas las máquinas). Un buen ejemplo es su directorio home ({\tt /home/{\em user}/\ldots}) ya que desde cualquier 
máquina se puede acceder a él. Un ejemplo de un directorio no compartido sería {\tt /tmp/}, si crea un directorio 
{\tt /tmp/my\_condor\_job/}, este solo será visible desde su máquina, por lo que cuando su trabajo se empiece a ejecutar
en otra máquina y vaya a abrir un archivo en ese directorio se encontrará que no existe y no podrá continuar (estos
errores aparecerán en el {\tt Log} del trabajo).

\subsection{Estado de los trabajos enviados. {\em condor\_q}}
\label{sec::condor_q}

Podemos obtener información acerca de nuestros trabajos con el comando {\em condor\_q}:

\begin{verbatim}
[adrians@trevina ~]$ condor_submit myjob.submit
Submitting job(s).
Logging submit event(s).
1 job(s) submitted to cluster 1.

[adrians@trevina ~]$ condor_q


-- Submitter: trevina.iac.es : <161.72.81.178:1085> : trevina.iac.es
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD
   1.0   adrians         7/13 12:37   0+00:00:00 I  0   0.0  myprog Example.1.0

1 jobs; 1 idle, 0 running, 0 held
\end{verbatim}

Por defecto, este comando nos mostrará información de los trabajos que hemos
enviado desde la máquina donde se ejecuta, en el ejemplo sería ``trevina''.
La información que aparece en la salida sería:
\begin{itemize}
	+ El {\tt ID} es el identificador del trabajo y está formado por dos números:
	\begin{itemize}
		+ El número antes del punto representa el ``cluster''. Un ``cluster'' es
			el conjunto de trabajos creado en un envío. Podemos ver un ejemplo en la salida
			del comando ``condor\_submit''.
		+ El número después del punto representa el trabajo dentro del cluster,
			como en el ejemplo solo creamos uno, será el trabajo 0. Trabajos
			sucesivos en el mismo cluster se nombrarían como 1.1, 1.2, \ldots.
	\end{itemize}
	+ El usuario que envío los trabajos.
	+ La fecha del envío.
	+ El tiempo de ejecución, en el formato: Días+HH:MM:SS.
	+ El estado actual del trabajo. Algunos valores posibles son:
		\begin{description}
 			\item[I:] No se está ejecutando porque aun no se le ha asignado ninguna
				máquina (IDLE).
			\item[R:] Ejecutándose actualmente (RUNNING).
			\item[H:] El trabajo no se está ejecutando por deseo del propietario
(HOLD). Ver el comando \htmladdnormallink{condor\_hold}
{http://goya/inves/SINFIN/Condor/v6.6/condor\_hold.html}, 
\htmladdnormallink{condor\_release}
{http://goya/inves/SINFIN/Condor/v6.6/condor\_release.html} 
o la
\htmladdnormallink{sección 2.6.3}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00363000000000000000}
del manual de Condor. 
		\end{description}
	+ La prioridad del trabajo que ha especificado el usuario. Ver comando
\htmladdnormallink{condor\_prio}{http://goya/inves/SINFIN/Condor/v6.6/condor\_prio.html} o
la \htmladdnormallink{sección 2.6.4}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00364000000000000000}
del manual de Condor.
	+ El tamaño de la imagen del trabajo en megabytes.
	+ Y por último, el nombre del ejecutable.
\end{itemize}

En el caso de que un trabajo no se esté ejecutando, este comando también nos
permite conocer el motivo gracias a la opción {\tt -analyze}. Por ejemplo:
%Este comando también nos permite conocer las causas de que un trabajo no se esté
%ejecutando, para esto usaremos la opción {\tt -analyze}. Por ejemplo:
\begin{verbatim}
[adrians@trevina ~]$ condor_submit myjob.submit 
Submitting job(s).
Logging submit event(s).
1 job(s) submitted to cluster 1.

[adrians@trevina ~]$ condor_q -analyze


-- Submitter: trevina.iac.es : <161.72.81.178:39869> : trevina.iac.es
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD               
---
001.000:  Run analysis summary.  Of 187 machines,
    187 are rejected by your job's requirements
      0 reject your job because of their own requirements
      0 match, but are serving users with a better priority in the pool
      0 match, but prefer another specific job despite its worse user-priority
      0 match, but will not currently preempt their existing job
      0 are available to run your job
        No successful match recorded.
        Last failed match: Thu Sep 16 12:38:09 2004
        Reason for last match failure: no match found

WARNING:  Be advised:
   No resources matched request's constraints
   Check the Requirements expression below:

Requirements = ((Memory > 2147483647)) && (Arch == "INTEL") &&
(OpSys == "LINUX") && (Disk >= DiskUsage) &&
(TARGET.FileSystemDomain == MY.FileSystemDomain)

\end{verbatim}

En el ejemplo podemos ver como el trabajo 1.0 tiene problemas para ejecutarse:
nuestros requisitos ({\tt Requirements}) han desechado 187 máquinas de las 187
candidatas. Además, {\em condor\_q} nos sugiere que revisemos dicha expresión y nos
la muestra en su salida (en el ejemplo vemos como el límite mínimo de memoria
RAM es excesivo).

Para más información puedes visitar la \htmladdnormallink{página del manual de {\em condor\_q}}
{http://goya/inves/SINFIN/Condor/v6.6/condor\_q.html}, la
\htmladdnormallink{sección 2.6.1}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00361000000000000000}
o la \htmladdnormallink{sección 2.6.5}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00365000000000000000}
del manual de Condor.

\subsection{Borrando trabajos. {\em condor\_rm}}
\label{sec::condor_rm}

Usaremos {\em condor\_rm} para borrar un trabajo de la cola de Condor:

\begin{verbatim}
[adrians@trevina ~]$ condor_q


-- Submitter: trevina.iac.es : <161.72.81.178:1085> : trevina.iac.es
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD
   2.0   adrians         7/13 12:46   0+00:00:01 R  0   0.0  myprog Example.2.0

1 jobs; 0 idle, 1 running, 0 held

[adrians@trevina ~]$ condor_rm 2.0
Job 2.0 marked for removal
\end{verbatim}

Podemos especificar tanto un trabajo como un cluster, en el ejemplo anterior, si hubiésemos
ejecutado {\tt condor\_rm 2} habríamos borrado todos los trabajos del cluster 2.

Notar que no podemos borrar trabajos que no nos pertenezcan.

Para más información puede visitar la 
\htmladdnormallink{página del
manual}{http://goya/inves/SINFIN/Condor/v6.6/condor\_rm.html}
 o la \htmladdnormallink{sección 2.6.2 del manual de
Condor}{http://goya/inves/SINFIN/Condor/v6.6/2\_6Managing\_Job.html\#SECTION00362000000000000000}.

\subsection{Estado de Condor. {\em condor\_status}}

Este comando nos permitirá conocer el estado de Condor:

\begin{verbatim}
[adrians@trevina ~]$ condor_status

Name          OpSys       Arch   State      Activity   LoadAv Mem   ActvtyTime

vm1@aciano.ia LINUX       INTEL  Claimed    Busy       1.030   501  0+16:56:02
vm2@aciano.ia LINUX       INTEL  Claimed    Busy       0.990   501  0+00:59:48
agracejo.iac. LINUX       INTEL  Claimed    Busy       1.030   500  0+21:00:39
vm1@agrimonia LINUX       INTEL  Claimed    Busy       1.010  1826  0+00:09:36
vm2@agrimonia LINUX       INTEL  Claimed    Busy       1.000  1826  0+00:09:32
alfalfa.iac.e LINUX       INTEL  Owner      Idle       0.000   248  0+00:32:55
...
tonina.iac.es SOLARIS29   SUN4u  Claimed    Busy       1.000   128  0+21:56:24
toro.iac.es   SOLARIS29   SUN4u  Unclaimed  Idle       0.000   128  0+00:00:04
tuno.iac.es   SOLARIS29   SUN4u  Owner      Idle       0.040   640  0+01:33:15
vibora.iac.es SOLARIS29   SUN4u  Claimed    Busy       1.010   576  3+02:59:06
viola.iac.es  SOLARIS29   SUN4u  Claimed    Busy       1.010   256  0+01:40:35
zarza.iac.es  SOLARIS29   SUN4u  Claimed    Busy       0.660   256  0+00:01:06
zorro.ll.iac. SOLARIS29   SUN4u  Claimed    Busy       1.040   384  1+03:38:25

                     Machines Owner Claimed Unclaimed Matched Preempting

         INTEL/LINUX       75    33      41         1       0          0
     SUN4u/SOLARIS29       87    21      64         2       0          0

               Total      162    54     105         3       0          0
\end{verbatim}

Este comando muestra información sobre cada una de las máquinas que forman el ``pool''
de Condor y un resumen del estado actual. En este resumen podemos comprobar, en cifras,
el uso que se le están dando a las máquinas. Así, por ejemplo, podremos comprobar cuantas
máquinas quedan disponibles para ejecutar trabajos mirando la columna ``Unclaimed''.

Para más información puedes visitar la \htmladdnormallink{página del manual}
{http://goya/inves/SINFIN/Condor/v6.6/condor\_status.html}
de este comando.

%%%%%%%%%%%%%%%%%%%%%%%% Section.
\section{Limitaciones}

\begin{itemize}
	+ Si su trabajo realiza muchas operaciones de entrada/salida (E/S)
		tenga en cuenta la sobrecarga que esto conlleva, probablemente no obtenga
		una mejora muy grande enviándolo a Condor. Note que todas las operaciones
		de lectura/escritura sobre archivos se realizan sobre la red\footnote{Los archivos
		residen físicamente en el home de un usuario especial por lo que todas las
		peticiones se realizarán sobre NFS.} por lo que sus trabajos se verán 
		ralentizados.
% Pero realmente su home siempre está compartido por NFS, en todo caso el
% problema será para naranja...
	+ Si envía un trabajo al universo ``vanilla'' contemple que cuando
		sea expulsado de una máquina perderá todo lo procesado hasta ese momento
		(a no ser que haya tomado precauciones por su cuenta). Si envía un trabajo
		que planea que vaya a tardar varios días en finalizar su ejecución 
		probablemente no obtenga mejoría usando Condor, en estos casos plantéese
		el uso del universo ``standard''.
% Explicar pq matamos su pobre trabajo :) quizás un enlace a la sección de 
% ¿Cómo funciona?.
	+ Tenga en cuenta que cada trabajo que envíe generará un proceso ``shadow''
		en la máquina desde donde se hace el envío. Este proceso se encarga de
		resolver algunas cuestiones relacionadas con su trabajo, realmente
		no consume demasiada CPU pero si realiza muchos envíos puede llegar a
		ralentizar su máquina.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%% Section.
\section{¿Y si tengo problemas?}
Existe a su disposición un portal dedicado a Condor en el I.A.C., la dirección es:
\url{http://goya/inves/SINFIN/Condor/}. También puede ponerse en contacto con
los administradores de Condor en la dirección de correo condor@iac.es.



** Python bindings                                                 :noexport:

