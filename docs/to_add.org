# Time-stamp: <2025-04-12 17:05:51 angelv> 

!!!!!!!!!!!!! DO NOT UPDATE
!!!!!!!!!!!!!  all user documentation now goes to index.rst
!!!!!!!!!!!!!  just take the info in :noexport: sections
!!!!!!!!!!!!!  and incorporate them in index.rst

* Submit files (HowTo)                                             :noexport:

** How to ... get/set environment variables?  

If you application needs them, use the =getenv= command and HTCondor will create
a copy of your environment variables {+at the submitting time+} so they will be
available for your program on the target machine. Also you can create/modify
environment variables if needed with the =environment= command. The environment
variables can be also used in the submit file using the =ENV= command.

For example, add next commands if you want that your executable can access your
environment at the submitting time, then set variables called =working_dir= and
=data_dir= pointing to some directories, and finally create a macro called
=home_dir= that contains your home directory to be used in your submit file:

 =getenv=        = True
 =environment=   = "working_dir=/path/to/some/place data_dir=/path/to/data"
 home_dir      = $ENV(HOME)

If you want to run your python program using HTCondor, you might need to define
some environment variables, please, read this FAQ
*HOWTOs.CondorFAQs#python-fedora*.


** How to ... deal with jobs that fail?  

Sometimes jobs fail because there are problems when executing your program. It
could happen that the problem is not in your program, but in the machine that
executed it (a missing or misconfigured application, a library with a different
version from the one you need, etc.). Then you should identify those problematic
machines and use =requirements= commands in your submit file in order to block
them, as is explained in this FAQ *HOWTOs.CondorFAQs#blackholes*. For example,
to block machines with names =piston= and =loro= use only one of the next
commands (both are equivalent):

 =requirements= = ((UtsnameNodename =!= "piston") && (UtsnameNodename =!= "loro"))  
 =requirements= = *!*=stringListMember=(UtsnameNodename, "piston,loro")

You can also block all machines that satisfy a pattern. For instance, to avoid
executing your jobs on those machines with names beginning with "k", "c" and
"l", add next lines (you can specify more complex patterns using the
*predefined functions and macros*:

  letter       = =substr=(toLower(Target.Machine),0,1)
  =requirements= = *!*=stringListMember=($(letter), "k,c,l")

Sometimes it is better to specify a list of machines where your application can
run (and avoid any other that is not in that list). For that purpose, just use
previous expressions after negating them with an ''exclamation mark'' "*!*" (or
remove it if they were already negated).

After avoiding machines that are not able to run your program, you should submit
again your jobs. But, please, execute {+only+} those jobs that failed (check
this FAQ *CondorFAQs#repeat* to see how), do not execute again jobs that were
already correctly executed to avoid wasting time and resources. For instance,
add next command to only execute jobs with Process ID =0=, =13=, =25= and those
from =37= to =44=:

   =noop_job= = *!*=( stringListMember=("$(Process)","0,13,25") || (($(Process) >= 37) && ($(Process) <= 44)) =)=

*Note*: =noop_job= will ''not'' execute those jobs where the condition is
=True=. Therefore, if you want to specify a list of jobs ''to be executed'', you
need to ''negate'' your expression adding an exclamation mark at the beginning:
=noop_job = *!*(...)=. On the other hand, if you want to specify a list of jobs
that should ''not'' be executed, then use the expression without negating it.

Jobs that are not executed may stay in the queue with =Complete= status (when
using =condor_q= you will see that =ST= column is =C=). To remove all =C= jobs
from the queue, try next command in your shell (use the second one to remove
{+only+} =Complete= jobs that belongs to cluster =XXX=):

  =condor_rm= -constraint 'JobStatus == 4'
  =condor_rm= -constraint 'JobStatus == 4 && clusterID == XXX'

Also, it could be interesting to avoid the *black holes*: suppose that each of
your jobs needs hours to finish, but they fail in an specific machine after a
few minutes of execution time. That means that machine will be idle every few
minutes, ready to accept another of your jobs, that will also fail, and this
process may repeat again and again... sometimes a failing machine could even
execute almost all your jobs... That is known as ''black hole''. To avoid it, we
can force HTCondor to change machines when sending jobs. For that purpose add
these lines to your submit file:

  ''#Avoid black holes: send to different machines''
  =job_machine_attrs= = Machine  
  =job_machine_attrs_history_length= = 5           
  =requirements= = $(requirements) && (target.machine =!= MachineAttrMachine1) && (target.machine =!= MachineAttrMachine2)


When there are problems with your jobs, you should receive an email with an
error and some related information (if it was not disabled using =notification=
command as explained above) and the job will leave the queue. You can change
this behavior with =on_exit_hold= and/or =on_exit_remove= commands, forcing
HTCondor to keep that job in the queue with status ''on hold'' or even as
''idle'' so it will be executed again:

(:table border=1 cellpadding=5 cellspacing=0 width=70% align=center:)
(:cell align=center valign=middle :) *Command* 
(:cell align=center valign=middle :) * True *
(:cell align=center valign=middle :) * False *
(:cellnr align=center valign=middle :) =on_exit_hold=
(:cell align=center valign=middle :) Stay in the queue with ''on hold'' status
(:cell align=center valign=middle :) Leave the queue
(:cellnr align=center valign=middle :) =on_exit_remove=
(:cell align=center valign=middle :) Leave the queue
(:cell align=center valign=middle :)  Stay in the queue with ''idle'' status (it can be executed again)
(:tableend:)
\\\

Last commands will be evaluated when jobs are ready to exit the queue, but you
can force a periodic evaluation (using a configurable time) with commands like
=periodic_hold=, =periodic_remove=, =periodic_release=, etc., and then decide if
you want to hold/remove/release them according to your conditions. There are
also some other commands to add a ''reason'' and/or a ''subcode'' when
holding/removing/releasing these jobs. On the other hand, you can force your
jobs to exit the queue when they satisfy a given condition using =noop_job=, or
they stay in the queue even after their completion using =leave_in_queue=
command (those jobs will stay in the queue with =Complete= status till you
remove them using shell command =condor_rm=).


In the
http://research.cs.wisc.edu/htcondor/manual/v8.6/condor_submit.html#condor-submit-on-exit-hold
official HTCondor documentation there are some examples about how to use these
commands (all valid =JobStatus= could be displayed using shell command:
=condor_q -help status=):

+ With the next command, if the job exits after less than an hour (3600
  seconds), it will be placed on hold and an e-mail notification sent, instead
  of being allowed to leave the queue:
   
=on_exit_hold= = ((CurrentTime - JobStartDate) < 3600)

+ Next expression lets the job leave the queue if the job was not killed by a
  signal or if it was killed by a signal other than 11, representing
  segmentation fault in this example. So, if it exited due to signal 11, it will
  stay in the job queue. In any other case of the job exiting, the job will
  leave the queue as it normally would have done.

   =on_exit_remove= = ((ExitBySignal == False) || (ExitSignal != 11))

+ With next command, if the job was killed by a signal or exited with a non-zero
  exit status, HTCondor would leave the job in the queue to run again:

   =on_exit_remove= = ((ExitBySignal == False) && (ExitCode == 0))

+ Use the following command to hold jobs that have been executing (=JobStatus ==
  2=) for more than 2 hours (by default, all periodic checks are performed every
  5 minutes. Please, contact us if you want a shorter period):

   =periodic_hold= = ((JobStatus == 2) && (time() - EnteredCurrentStatus) >  7200)

+ The following command is used to remove all ''completed'' (=JobStatus == 4=)
  jobs 15 minutes after their completion:

   =periodic_remove= = ((JobStatus == 4) && (time() - EnteredCurrentStatus) >  900)

+ Next command will assign again the ''idle'' status to ''on hold'' (=JobStatus
  == 5=) jobs 30 min. after they were held:

   =periodic_release= = ((JobStatus == 5) && (time() - EnteredCurrentStatus) >  1800)

[-*IMPORTANT*: =periodic_release= command is useful when your program is
correct, but it fails in specific machines and gets the ''on hold'' status. If
that happens, this command will allow HTCondor to periodically release those
jobs so they can be executed on other machines. But {+use this command with
caution+}: if there are problems in your program and/or data, then your
application could be indefinitely held and released, what means a big waste of
resources (CPU time, network used in file transferring, etc.) and inconveniences
for other users, be careful! (you can always remove your jobs using =condor_rm=
command in your shell).-]


When using =periodic_remove= or =periodic_hold= HTCondor submit commands,
running jobs that satisfy the condition(s) will be killed and all files on
remote machines will be deleted. Sometimes you want to get some of the output
files that have been created on the remote machine, maybe your program is a
simulation that does not converge for some sets of inputs so it never ends, but
it still produces valid data and you want to get the output files. In those
cases, do not use the mentioned submit commands because you will lose the output
files, and use instead utilities like =timeout= in order to limit the time that
your application can be running. When using this linux command, you specify the
maximum time your program can run, and once it reaches that limit, it will be
automatically killed. Then HTCondor will detect your program has finished and it
will copy back the output files to your machine as you specified. Next example
will show how to limit the execution of your program up to 30 minutes:

  ''# Some common commands above...''
  ...

  ''# Max running time (in seconds)''
  MAX_TIME = 30 * 60

  ''# Your executable and arguments''
  MY_EXEC = your_exec
  MY_ARGS = "your_arg1 your_arg2"

  ''# If your executable is not a system command, do not forget to transfer it!''
  =transfer_input_files= = your_inputs,$(MY_EXEC)
  ''# By default all new and modified files will be copied. Uncomment next line to indicate only specific output files''
  ''#=transfer_output_files= = your_outputs''

  =executable=          = /bin/timeout
  ''# Since timeout is a system command, we do not need to copy it to remote machines''
  =transfer_executable= = False
  =arguments=           = "$INT(MAX_TIME) $(MY_EXEC) $(MY_ARGS)"

  =queue= ...




** How to ... do some complex operations in my submit file?  

If you need to do some special operations in your submit file like evaluating
expressions, manipulating strings or lists, etc. you can use the *predefined
functions* and some *special macros* that are available in HTCondor. They are
specially useful when defining conditions used in commands like =requirements=,
=rank=, =on_exit_hold=, =noop_job=, etc. since they will allow you to modify the
attributes received from the remote machines and adapt them to your needs. We
have used some of these predefined functions in our examples, but there are many
others that could be used:

+ evaluate expressions: =eval()=, ... 
+ flow control: = ifThenElse()=, ...
+ manipulate strings : =size()=, =strcat()=, =substr()=, =strcmp()=, ... 
+ manipulate lists: =stringListSize()=, =stringListSum()=, =stringListMember()=, ...
+ manipulate numbers: =round()=, =floor()=, =ceiling()=, =pow()=, ...
+ check and modify types: =isReal()=, =isError()=, =int()=, =real()=...
+ work with times: =time()=, =formatTime()=, =interval()=, ...
+ random: =random()=, =$RANDOM_CHOICE()=, =$RANDOM_INTEGER()=, ...
+ etc. 

Check the documentation to see the complete list of *predefined functions*, and
also the *special macros*.

** How to ... work with nested loops?  

You can use =$(Process)= macro to simulate simple loops in the submit file and
use the iterator to specify your arguments, input files, etc. However, sometimes
simple loops are not enough and nested loops are needed. For example, assume you
need to run your program with the arguments expressed in the next pseudocode:

 MAX_I = 8
 MAX_J = 5

 =for= (i = 0; i < MAX_I; i++)
   =for= (j = 0; j < MAX_J; j++)
     ./myprogram -var1==i= -var2==j=

To simulate these 2 nested loops, you will need to use next macros in your
HTCondor submit file:

 MAX_I = 8 
 MAX_J = 5
 N = MAX_I * MAX_J
 ...    
 I = ($(Process) / $(MAX_J))
 J = ($(Process) % $(MAX_J))
 ...
 =executable= = myprogram
 =arguments=  = "-var1=$=INT=(I) -var2=$=INT=(J)"
 =queue= $(N)

Last code will produce a nested loop where macro =$(I)= will work like the
external iterator with values from =0= to =7=; and =$(J)= will be the internal
iterator with values from =0= to =4=.

\\

If you need to simulate 3 nested loops like the next ones:
 =for= (i = 0; i < MAX_I; i++)
   =for= (j = 0; j < MAX_J; j++)
     =for= (k = 0; k < MAX_K; k++)
       ...

then you can use the following expressions:
 N = $(MAX_I) * $(MAX_J) * $(MAX_K)

 I = ( $(Process) / ($(MAX_K)  * $(MAX_J)))
 J = (($(Process) /  $(MAX_K)) % $(MAX_J))
 K = ( $(Process) %  $(MAX_K))

 =executable= = myprogram
 =arguments=  = "-var1 $=INT=(I) -var2 $=INT=(J) -var3 $=INT=(K)" ...
 =queue= $(N)


** How to ... know the attributes of the machines where our jobs are run?  

There is a special macro to get the string attributes of target machines that we
can use in our submit file. In this way, some of the parameters of each machine
where HTCondor executes jobs can be accessed with =$$(parameter)=. Also there
are other special macros, like the one used to print the symbol =$= since it is
reserved by HTCondor: =$(DOLLAR)=.

For example, we want to know the name of each slot and machine where our jobs
were executed, adding =.$.name.$.= to the results of =stdout= and =stderr=. Then
we should use next commands:

 =output=        = myprogram.$(ID).$(DOLLAR).$$(Name).$(DOLLAR).out
 =error=         = myprogram.$(ID).$(DOLLAR).$$(Name).$(DOLLAR).err

Ading those commands in your submit file will create output and error files with
names similar to =$.slot3@xilofon.ll.iac.es.$=.


* FAQs                                                             :noexport:

** Having some troubles with your jobs

*** My submitted jobs are always in Idle status, why do they never run (and what about users' priority)? 

If your jobs are always in Idle status, it may be caused by several
reasons, like restrictions that you have specified in the submit file, a low
user's priority, etc. With =condor_q= command you can find out what the reason
is, just choose one of your idle jobs and use next commands:

  =condor_q -analyze= <job_id>
  =condor_q -better-analyze= <job_id>

Condor will display then some detailed information about machines that rejected
your job (because of your job's requirements or because they are not idle but
being used by their owners), machines that could run your job but are busy
executing other users' jobs, available machines to run your job if any, etc. It
will also display the reason why that job is idle and some suggestions if you
have non-suitable requirements.

Check that information and be sure that your requirements can be satisfied by
some of the current machines (pay attention to the suggestions, they may help a
lot!). For instance, if you ask for slots with more than 6GB of RAM, there are
just few of them and they need to be idle to run Condor jobs, so you may need to
wait for a long while before running there (also check that there are no
impossible values, like asking for machines with 16GB per slot, we have none of
them). Before adding a requirement, always check if there are enough slots that
satisfy it (for example, to see which slots have more than 6GB of RAM, try next
command in your shell: =condor_status -constraint 'Memory > 6144'=. ''Please,
visit *Condor submit file page -> CondorSubmitFile* for more info and
examples.''

You can also get messages like =Reason for last match failure: insufficient
priority=. Bear in mind that Condor executes jobs according to users' priority,
so that message means that Condor is right now executing jobs submitted by users
with a better priority than yours, so you will still have to wait a bit. You can
check yours and other users' priority running =condor_userprio -all -allusers=:
all users begin with a priority value of =0.5=, the best one possible, and once
you begin to run jobs with Condor, it will increase your priority value (that
means worse priority) according to the number of machines you are using and the
consumed time (the more you use Condor's resources, the faster your priority
value will be increased). On the other hand, your priority will be gradually
decreased when you are not using Condor.

If your Condor priority is important for you and you want to run some not urgent
jobs, you can submit them using =nice_user = True= command in your submit file:
those jobs will be run by another user called =nice_user.<your_user>= and they
will not affect your real user's priority. But this new user has an extremely
low priority, so its jobs can stay in the queue for a long while before being
executed (but they can be run very fast if the Condor queue is almost empty).

Besides user's priority, all jobs have also their own priority, and you can
change it to specify whether some jobs are more important than others so they
should be executed first (please, *check this FAQ -> #priority*).


*** Condor is copying unwanted files to my machine, how can I avoid that? 

By default, Condor will copy all files generated or modified by your
application that are located in the same directory where your program was
executed on the remote machine, what could include some unwanted content like
temporary files, etc. If you want to avoid that, then you can use the
=transfer_output_files= command (see *this FAQ -> #outputs*) to specify which
files and/or directories you want that Condor copies from the remote machine to
your machine once your application has finished (then Condor will copy {+only+}
those files and ignore all remaining ones).

If you only want to get the output file from the screen (using =output=
command), but not any other generated of modified file, you can use
=should_transfer_files = NO= command. That command will deactivate the Condor
transfer mechanism, affecting both your input and output files, so it can be
only used when you have none of them. If you want to copy input files, but NOT
the output files, then you should use next commands:

 =should_transfer_files=  = YES
 =+TransferOutput=        = ""



*** Some of my jobs randomly fail (or I know they will fail in some specific machines)... how can I prevent that? 

If you see that some of your jobs fail with apparently no reasons, but they
properly run when resubmitted, the problem might not be in your program, but on
the machine(s) where they were executed (for example, an application or library
that is used by your program is not installed on those machines, or its version
is too old/new, or it is misconfigured, etc.). To detect this, simply check the
machine where the failing job was executed, which is written in your condor log
file, though it is easier to check it using the =condor_history= command. For
instance, to check where job =XXX.YYY= was run, launch next command in the
{+same machine+} where you did the submission:

 [...]$ =condor_history= XXX.YYY =-af= LastRemoteHost

Maybe some of your jobs finished with no problems, but others finished
abnormally soon. You can use =condor_history= to get a list of those jobs. For
instance, suppose that you have submitted some jobs with =clusterId=XXX= and
each job needs at least 30 minutes to properly finish, so you are sure that
those that lasted less than 10 minutes (600 seconds) failed. Then you can use
next commands to get those jobs (first command will give you a list of the jobs
that failed and the second one will show two lines for each of them, the first
line is where the jobs was executed on and the second line is the =procId= of
the job):

 [...]$ =condor_history= -constraint '((ClusterId==XXX) && ((CompletionDate-JobStartDate) < 600))'
 [...]$ =condor_history= -constraint '((ClusterId==XXX) && ((CompletionDate-JobStartDate) < 600))' =-af= ProcId LastRemoteHost


Most times these problems are simply solved by forcing these failing jobs to go
again into the queue after an unsuccessful execution to be re-executed (see last
paragraph). If you see that all jobs that failed were executed on the same
machine(s) or you already know that your application is not able to run on some
machines, then you can force Condor to avoid sending your jobs to those
machines. For instance, suppose that your jobs have problems in machines with
names ''agora'', ''lapiz'' and ''madera'' and you want to avoid them. Then, add
either of the next lines (both are equivalent) to your Condor submit file (if
you had some previous requirements, append the new ones to them):

 =requirements= = ((UtsnameNodename =!= "agora") && (UtsnameNodename =!= "lapiz") && (UtsnameNodename =!= "madera"))
 =requirements= = *!*=stringListMember=(UtsnameNodename, "agora,lapiz,madera")

You can also block all machines that satisfy a pattern. For instance, to avoid
executing your jobs in those machines with names beginning with "a", "l" and
"m", add next lines (you can specify more complex patterns using the *predefined
functions and macros ->
http://research.cs.wisc.edu/htcondor/manual/v8.6/4_1HTCondor_s_ClassAd.html#SECTION00512400000000000000*):

 letter       = =substr=(toLower(Target.Machine),0,1)
 =requirements= = *!*=stringListMember=($(letter), "a,l,m")

On the opposite situation, if your application can ONLY run on those machines,
then you only need to negate the previous expressions (or remove the negation):

 =requirements= = ((UtsnameNodename == "agora") || (UtsnameNodename == "lapiz") || (UtsnameNodename == "madera"))  
 =requirements= = =stringListMember=(UtsnameNodename, "agora,lapiz,madera")
 ...
 letter       = =substr=(toLower(Target.Machine),0,1)
 =requirements= = =stringListMember=($(letter), "a,l,m")


Then you should execute again only {+those jobs that failed+} (check *this FAQ
-> #repeat* to see how). Please, do not execute again all your jobs to avoid
wasting time and resources. If your program could fail and never end (for
example, for some sets of data it never converges), you can use utilities like
linux command =timeout= to limit the time it can be running. Failing machines
can cause a problem called *black hole* that could produce that most of your
jobs fail. Please, visit *Condor submit file section ->
CondorHowTo#howto_failing* for more info and examples to avoid that. In this
section we also describe some Condor commands that you can add in your submit
file to deal with failing machines, like =on_exit_hold= and
=on_exit_remove=. For instance, using these commands you can specify that any
job that finishes with a non valid exit code and/or before X minutes, has to be
held or sent to the queue again to be re-executed, respectively. Some examples
(before using these commands, make sure that the problem is on remote machines
and not on your code in order to avoid re-executing failing jobs):

 [--# Held jobs if they finished in less than 10 minutes. Later we can check what was wrong with those jobs and re-execute again them--]
 [--# using =condor_release= (we can also use =periodic_release= to automatically release held jobs every X minutes)--]
 =on_exit_hold= = ((CurrentTime - JobStartDate) < (10 * 60)

 [--# Remove from the queue only those jobs that finished after 10 or more minutes. If a job finished before that period of time,--]
 [--# it will be sent again to the queue with 'Idle' status to be re-executed (most probably on a different machine)--]
 =on_exit_remove= = ((CurrentTime - JobStartDate) > (10 * 60)


*** I want to repeat (resubmit) ONLY some of my jobs, is that possible? 

If you submit a large number of jobs and for any reason some of them fail
and leave the queue, you should not waste time and resources running again all
of them, just try with those that failed (after solving the problems they
had). Unfortunately there is *not* a =condor_resubmit= command to easily
resubmit jobs that have already left the queue. You could try to obtain the
''ClassAd'' of those jobs using =condor_history -l <job.id>=, but Condor will
not accept it as input when using =condor_submit=.

If there are just a few jobs to resubmit, you could try to add pairs of
=arguments= and =queue= commands to execute only those jobs, but there is an
easier way to do it using =noop_job= command. For instance, suppose you want to
repeat jobs with Process ID =0=, =4=, =9=, =14= and those from =24= to
=32=. Then, add next line to your submit file and submit it again:

  =noop_job= = =*!*( stringListMember=("$(Process)","0,4,9,14") || (($(Process) >= 24) && ($(Process) <= 32)) =)=

Condor will *not* run jobs where that expression is =True=, so only jobs in the
list will be executed. Note that we have added an exclamation mark symbol
(=*!*=) before your expression to change its value: =noop_job = *!*(...)=. When
using =noop_job=, Condor will still create output and error files for all jobs,
but they will be empty for those jobs that will not be executed (be careful to
avoid that new executions overwrite output files of previous ones).

Jobs that are not executed may stay in the queue with =Complete= status (when
using =condor_q= you will see that =ST= column is =C=). To remove all =C= jobs
from the queue, try next command in your shell (use the second one to only
remove =Complete= jobs that belongs to cluster =XXX=):

  =condor_rm= -constraint 'JobStatus == 4'
  =condor_rm= -constraint 'JobStatus == 4 && clusterID == XXX'

*** I see that my jobs complete after being running for N+X minutes/hours, when they only need N to finish. Is that normal? 

Yes, it is normal. Bear in mind that executing a Condor job in a machine is
only possible when it is not used by its owner. If Condor detects any user's
activity in a machine when executing jobs, they will be suspended or moved to
another machines, increasing the consumed time (and that may happens several
times, so the extra time could be quite long).

Condor has several ways to show the time that jobs have been running. If you use
=condor_q=, the time showed is the cumulative one by default (the result of
adding the time consumed in all executions), so it could be really high if the
job has been killed and restarted several times. If you use =-currentrun=
option, then Condor will only display the time consumed in the current
execution, which is a more realistic time (although if the job has been
suspended, that time is also included). You can also use =-cputime= option to
get only the CPU time (but if the job is currently running, time accumulated
during the current run is not shown).

If your jobs finish in a reasonable amount of time, everything is fine. If they
never finish or need an excessive amount of time to complete, you will have to
modify the application to create checkpoints.

*** I have submitted jobs that need some hours to finish. They have been running for days and just few have finished... what is happening? 

First of all, check that your program is properly running. Maybe there are
some problems with the data, input files, etc. You can open a shell and check
the running job using the =condor_ssh_to_job= command (see *this FAQ ->
##ssh*). If you discover that there are some problems with your job and it will
not produce valid results, you should stop it as soon as possible to avoid
wasting more time and resources, see *this FAQ -> #bad_inputs* for more
details. If your job is working fine, maybe your job has been killed and
restarted several times. Condor shows the ''cumulative running time'' by
default, you can see the consumed time of the present execution using =condor_q
-run -currentrun= command.

The reason why Condor kill and restart jobs is that it has several runtime
environments called ''universes''. By default, all your jobs will go to the most
basic (also the simplest) one called =vanilla= universe. In that universe, when
Condor detects that a machine is not idle anymore, it will suspend all running
jobs for a while, waiting the machine to get idle again. If that does not happen
in a given (short) time interval, then Condor will kill all jobs and send them
again to the queue with ''Idle'' status, so those jobs will start from the
beginning. If your jobs need some hours to finish, probably some of them will be
killed before their completion and restarted in other machines, that could
happen even several times.

However, most times we can solve this problem simply changing the arguments of
our jobs. For instance, suppose you have to process 10,000 inputs and each input
needs about 2 minutes to be done. You can create 100 jobs to process 100 inputs
each, but they will need more than 3 hours to finish and it is likely they will
be killed several times. It is better to choose faster jobs that can be finished
in about 15-30 minutes so they will have more possibilities to be processed on
the same machine without being killed and restarted on other machines. If you
choose that each job works with 10 inputs, then you will have 1000 jobs and they
will need about 20 minutes to finish, that could be a good approach.

*** Some of my python programs work fine, but other fail... 

If you are executing python programs with HTCondor and some jobs work fine
and other fail, most probably you are experiencing problems related to the
version of Fedora. Most of the old Linux Desktop PCs have installed Fedora21,
but newer machines have a more recent version, mostly Fedora26 (although we also
have a few with Fedora25). Paths to python libraries are different on the old
and new machines, therefore your programs will only work properly on those
machines that have the same Fedora version as the machine where you have
submitted the jobs.

To fix this issue, you can force HTCondor to only execute jobs on machines with
your same version of Fedora, then your environment variables and paths will
work. For instance, if you are working on a machine with Fedora21, add the next
requirement to force that all your jobs will be executed on machines running
Fedora21:

  =*requirements* =  (*OpSysMajorVer* == *21*)=

But adding that requirement will limit the number of available machines to
execute your program: if you only run on machines with Fedora21, you will be
missing all new and faster machines, and if you only run on machines with
Fedora26, then you will be losing a big amount of slots since still most of the
machines run Fedora21. We recommend you change a bit your submit script to be
able to run your python programs on all machines, independently of their O.S (we
will only avoid the few machines beginning with ='f'=, since they have a special
purpose and python installation there is not the usual one):

  ... 
  =transfer_input_files= = your_program.py

  =getenv=       = =True=
  =environment=  = "PYTHONPATH=/usr/pkg/python/python2.7/lib/python2.7/site-packages"
  =requirements= = (*!*=stringListMember=(=substr=(=toLower=(=Target.Machine=),0,1), "f"))

  =transfer_executable= = =False=
  =executable=   = /usr/bin/env
  =arguments=    = =python= your_program.py

  =queue= ...

Example above is just a basic one, you might need to adapt it adding some other
commands to transfer your input/output files, add requirements, etc., and, of
course, all common commands (see *common template ->
HOWTOs.CondorSubmitFile#common_template*).  Contact us if you have any doubts.


*** I receive an error when running HTCondor jobs that use python and matplotlib... 

If you are running some =python= jobs that use =matplotlib= (for example,
 to make some plots and save them to =png= images) and receive errors like:

+ =no display name and no $DISPLAY environment variable=
+ =: cannot connect to X server :0=

it might be caused because =matplotlib= (and/or some other packages) needs a
=DISPLAY= environment variable, which means you have to execute it in a X
server, and that is not available when running on HTCondor. In this case, simply
use another background that does not need a X server, like =Agg=. For instance,
you can adapt next python code when using =matplotlib=:

  =import= matplotlib =as= mpl
  mpl.use(*'Agg*')
  =import= matplotlib.pyplot =as= plt

  ''# Now use =plt= as usual''
  ''...''
  ''fig = plt.figure()''
  ''...''
  ''fig.savefig('image.png')''
  ''...''

You can find more info about this issue *here ->
http://stackoverflow.com/questions/4931376/generating-matplotlib-graphs-without-a-running-x-server*.

*** I would like to get more information about the execution, is there an easy way to see the logs created by Condor? 

Yes, there are several possibilities for that. The first step is to create
the ''condor log file'' adding the next command to your submit file:

  =log= = file.log      ''#(we recommend you use =your_executable_name.$(Cluster).log= as name for your log file)''

Once you have your condor log file, you can display the information using the
following options:

+ Directly check the content of the condor log file with any text editor (not
  recommended)
+ Use =condor_userlog <file.log>= to get a summary of the execution.
+ Run =condor_history -userlog <file.log>= command in your shell to list basic
  information contained in the log file.
+ Use =condor_logview <file.log>= to open the ''Condor log viewer'' and see more
  detailed information in graphical mode, showing the timeline of your jobs and
  allowing you to perform zooms, filter jobs, etc.
+ There is also an online tool to analyze your log files and get more
  information: ''Condor Log Analyzer'' (*http://condorlog.cse.nd.edu/*).

If you just want some general information about Condor queue, the pool of
machines, where jobs have been executed on, etc., you can also try our online
stats about Condor: *http://carlota:81/condor_stats/* and *nectarino ->
http://nectarino/*.



** Special needs
*** I am running many jobs, but some are more important than others, how can I prioritize them? 

You can prioritize your jobs (and only your jobs, not other users' jobs)
using =priority = <value>= command in your submit files (the higher value, the
better priority). Once you have submitted your jobs, you can check or modify
their priority by running =condor_prio= in a console. Please, check *Condor
submit file page -> CondorHowTo#howto_priority* to see more examples, and also
*this FAQ -> #idle* for more info about users' priorities.

*** I am receiving hundreds of emails from Condor, can I stop that? 

Yes, by default Condor send an email notifying any event related to each
job (termination, errors, etc.). If you launch 1000 jobs, that could be really
annoying. To avoid that, use next command in your submit file: =notification =
Never= (use =Complete= if you only want to know when they finish, =Error= when
they fail or =Always= to receive all notifications; we recommend you use
=Error=). Also you can change the email address using =notify_user = <email>=.

''Please, visit *Condor submit file page -> CondorSubmitFile* for more info and
examples.''

*** What happens with my IDL or Matlab jobs that require licences to run? 

There is a limited number of IDL licences, so if you try to run a large
number of IDL jobs they could fail since there may not be enough licences. But
using IDL Virtual Machine does not consume any licence, so there will not be
limit in the number of simultaneous IDL running jobs, just the number of
available slots. See *detailed information here -> CondorAndIDLVirtualMachine*.

There is a similar limitation with Matlab licences, that could be saved if it is
possible for you to create Matlab executables using the *Matlab Compiler ->
http://www.mathworks.es/products/compiler/*. You have more info about this topic
*here -> https://htcondor-wiki.cs.wisc.edu/index.cgi/wiki?p=HowToRunMatlab*.




















