% Created 2023-02-26 Sun 19:17
% Intended LaTeX compiler: pdflatex
\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{color}
\usepackage{listings}
\usepackage[left=2cm, right=2cm, top=1.5cm, bottom=2cm]{geometry}
\usepackage{mdframed}
\BeforeBeginEnvironment{minted}{\begin{mdframed}}
\AfterEndEnvironment{minted}{\end{mdframed}}
\setcounter{secnumdepth}{6}
\author{Ángel de Vicente\thanks{angel.de.vicente@iac.es}}
\date{\today}
\title{HTCondor@IAC User's Manual}
\hypersetup{
 pdfauthor={Ángel de Vicente},
 pdftitle={HTCondor@IAC User's Manual},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.2 (Org mode 9.1.3)}, 
 pdflang={English}}
\begin{document}

\maketitle
\setcounter{tocdepth}{4}
\tableofcontents

\small


\begin{mdframed}
\begin{warning}
If you have no experience with HTCondor, we recommend that you contact us before
running any job so we can give you a quick introduction (bear in mind that you
will be using other users' computers and there are some basic guidelines that
you must follow to avoid disturbing them).
\end{warning}
\end{mdframed}

\begin{mdframed}
\begin{note}
The HTCondor infrastructure at the IAC has been recently expanded and improved,
with about 100 new Linux desktop PCs financed by the Ministry of Economy and
Competitiveness through FEDER funds, code IACA13-3E-2493. 
\end{note}
\end{mdframed}

\section{Introduction}
\label{sec:org500d1d9}

\subsection{What is HTCondor?}
\label{sec:org58a8184}

At the IAC we have several \href{http://research.iac.es/sieinvens/SINFIN/Main/supercomputing.php}{Supercomputing} resources that allow you to obtain
your computational results in much less time and/or work with much more complex
problems. One of them is \href{http://research.cs.wisc.edu/htcondor/}{HTCondor}, a High Throughput Computing (\href{http://en.wikipedia.org/wiki/High-throughput\_computing}{HTC}) system. The
underlying idea is quite simple (and powerful): let's use idle machines to
perform computations while their owners are away. So, in a nutshell, HTCondor is
an application that is installed in our PCs to make it possible to run a large
number of yours and others' computations at a time in different machines when
they are not being used, achieving a better utilization of our resources. A more
detailed overview of HTCondor is available at the \href{https://htcondor.readthedocs.io/en/v10\_0/overview/index.html}{official documentation}.

\subsection{How can HTCondor help you?}
\label{sec:org6bf5527}

HTCondor is very useful when you have an application that has to run a large
number of times over different input data. For instance, suppose you have a
program that carry out some calculations taking an image file as input. Let's
say that the processing time is about one hour per image and you want to process
250 images. Then you can use your own machine and process all images one by one,
and wait more than 10 days to get all results, or you can use HTCondor to
process each image in different computers and hopefully get all results in one
hour, or maybe two or four, but for sure less than 10 days. And HTCondor will do
all the work for you: it will copy the input files to the remote machines,
execute your program there with different inputs and bring back the results to
your machine when they are complete.

\subsection{How \textbf{powerful} is HTCondor?}
\label{sec:orga0e6605}

HTCondor calls a \emph{slot} the unit that executes a job, typically a CPU or a core
if the CPU has several of them. Right now we have over 1000 slots that might
execute applications submitted via HTCondor. It means that everyday more than
24000 hours could be available to run HTCondor jobs, close to 3 years of
computation in a single day! Obviously, this is the theoretical maximum if no
one were using their computers and all slots were idle, but the number of actual
available slots could be around 400 during office hours and around 700 at nights
and weekends.

ccan see \ref{fig:org89f1541}

You can see the real-time HTCondor statistics here: \href{http://nectarino}{nectarino} (''Pool
Resource Stats'' show the number of slots being used by their owners, by
HTCondor and the idle ones; while ''Pool User Stats'' show the number of
HTCondor jobs and consumed hours per user). If you want more detailed info about
which and when jobs have been executing on specific machines, check stats at
\url{http://carlota:81/condor\_stats}. Also you can visit the
\href{http://venus/SIE/forum/viewtopic.php?f=8\&t=38}{Hall of Fame} of HTCondor. 

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{images/introduction/weekly_usage.png}
\caption{\label{fig:org89f1541}
Weekly usage HTCondor statistics}
\end{figure}


\subsection{Which machines are running HTCondor?}
\label{sec:org6b4ac16}

HTCondor is already installed in most of the Desktop PCs running Linux that we
have at IAC Headquarters in La Laguna, with a total number of more than 230
machines.

If you are concerned about hardware specifications, you may know that those
machines are rather heterogeneous and its availability and specifications change
from time to time. At the present status (Sept, 2014), most CPUs are Intel (and
also some AMD) from 2.40 to 3.20 GHz. Each CPU has typically 2, 4 or 8 cores,
although there are also more powerful machines with up to 32 cores per CPU. As
for memory, the most common is 2GB per slot, while some of them have from 3 to
8GB per slot and a few just 1GB per slot.

On the other hand, software specifications are quite homogeneous and all
machines are running the same OS: Fedora Linux. Almost all machines run Fedora21
(as of June 2017, there are still a few machines running older versions, and a
handful with Fedora 25). Installed software should be also more or less the same
in every machine (see the \href{http://research.iac.es/sieinvens/SINFIN/Main/software\_sinfin.php}{software supported by the SIE)}, which makes
it easy to run almost every application in any machine (although the available
software could be different in some machines that belong to the Instrumentation
area).

If your application has special requirements about memory per slot, OS version,
etc., you can rank and/or limit these parameters and also a quite large set of
other ones. ''Please, visit FAQs page for more information and
examples.''


\subsection{Who can use HTCondor? How does it work?  Do I need to change my application?}
\label{sec:orgad47c72}

If you have a computer account at the IAC and you can log in on a Linux PC
Desktop connected to the internal network, then you should be able to use
HTCondor with no problems (try @@condor\(_{\text{version}}\)@@ command to check whether
HTCondor is installed. Please contact us if it is not or you experience any
issue).

HTCondor is a batch-processing system, so you only need to submit your jobs to
the HTCondor queue and it will do all the work. The submission is done using a
HTCondor script where you specify your executable, its arguments, inputs and
outputs, etc. (visit HTCondor submit files page to see some
examples and recommendations). You do not need to prepare or compile your
programs in any special way to run them, and almost all programming languages
that are commonly used at IAC should be suitable to be run with HTCondor (shell
scripts, Python, Perl, C, Fortran, IDL, etc.). Sometimes a few minor
modifications may be needed in order to specify arguments and the locations of
inputs or outputs, so that HTCondor can find them, but that should be all.

Once the submitted jobs are in HTCondor queue, it uses its allocation algorithm
to send and execute your jobs on those idle slots that satisfy your
requirements. Idle slots are those located in machines where there has been no
keyboard/mouse activity for a long while and the computer load is low enough to
ensure that there is no interference with the owner's processes. While HTCondor
is running its jobs, it also keeps checking that the owner is not using the
machine. If HTCondor detects any activity in the computer (for instance, a key
is pressed), then it will suspend all its jobs and wait a little while to see
whether the machine gets idle again so as to resume the jobs. If the owner keeps
working, HTCondor will interrupt all jobs and send them to other available slots
in any other idle machine. HTCondor will repeat this process till all jobs are
done, sending notifications via email when they are finished or if any errors
show up.


\subsection{I am using HTCondor, should I add an acknowledgement text in my publications?}
\label{sec:orgee71596}

Yes, you should mention it in the acknowledgments of your papers or any other
publications where you have used HTCondor. Although there is no standard format,
we suggest the following:

>>frame<< ''"This paper made use of the IAC Supercomputing facility HTCondor
(\url{http://research.cs.wisc.edu/htcondor/}), partly financed by the Ministry of
Economy and Competitiveness with FEDER funds, code IACA13-3E-2493."''  >><<

If you have used any other IAC Supercomputing facilities (LaPalma, TeideHPC,
etc.), please, add them in the acknowledgments too:

'''LaPalma''': ''"The author thankfully acknowledges the technical expertise and
assistance provided by the Spanish Supercomputing Network (Red Española de
Supercomputación), as well as the computer resources used: the LaPalma
Supercomputer, located at the Instituto de Astrofísica de Canarias."''

'''TeideHPC''': ''"The author(s) wish to acknowledge the contribution of Teide
High-Performance Computing facilities to the results of this research. TeideHPC
facilities are provided by the Instituto Tecnológico y de Energías Renovables
(ITER, SA). URL: \url{http://teidehpc.iter.es/}"''

\subsection{I need more information or have some problems, who can help me\ldots{}?}
\label{sec:org91ca645}

If you need further information, please check the other pages about HTCondor at
the SIEpedia: Useful Commands, Submit Files (description and examples), Submit
Files (HowTo), FAQs, etc. HTCondor at SIEpedia is continuously updated, but we
also have more documentation about older versions of HTCondor at the \href{http://research.iac.es/sieinvens/SINFIN/Condor/index.php}{the
HTCondor section at IAC} (most of that information is still valid, but some may
be obsolete, including broken links). For detailed and complete information,
check the \href{http://research.cs.wisc.edu/htcondor/manual/v8.6/}{official documentation about HTCondor}.

If you need help or you are having any kind of issues related to HTCondor,
'''the SIE gives direct support''' to IAC's users who want to use HTCondor: we
will not code your whole application, but we help and advise you about how to
get the most out of HTCondor: use its commands, create submit files, modify your
application to run it with HTCondor (in case it is needed), fix common mistakes,
etc. We also organize workshops about HTCondor for IAC's users (the last one was
on February, 25th 2014 - \href{https://docs.google.com/presentation/d/1PqCih4yL6D3FOFo0W336RjLCKrSICZbYuPX1F1CZqtQ/present\#slide=id.p}{slides}, and we can organize a new workshop on demand if
you and your colleges need it: if the group is large enough -10 or 12 people-,
just contact us!).

\section{Useful Commands}
\label{sec:orgf9ca571}

HTCondor has several dozens of commands, but in this section we will present
just the most common ones (if you want to check the complete list, try the
\href{http://research.cs.wisc.edu/htcondor/manual/v8.6/11\_Command\_Reference.html}{Command Reference page}). Also remember that you can get further information
running @@man condor\_<cmd>@@ in your shell or visiting the \href{http://research.cs.wisc.edu/htcondor/manual/v8.6/2\_Users\_Manual.html}{official Users'
Manual}. The main command will be shown together with some useful options that
may help work with HTCondor:


\subsection{Checking pool status}
\label{sec:org05fa071}

\begin{itemize}
\item \texttt{condor\_status}: list slots in HTCondor pool and their status: \texttt{Owner} (used
by owner), \texttt{Claimed} (used by HTCondor), \texttt{Unclaimed} (available to be used
by HTCondor), etc. Useful options:
\begin{itemize}
\item \texttt{-avail}: List those slots that are not busy and could run HTCondor jobs at
this moment
\item \texttt{-submitters}: Show information about the current general status, like
number of running, idle and held jobs (and submitters)
\item \texttt{-run}: List slots that are currently running jobs and show related
information (owner of each job, machine where it was submitted from, etc.)
\item \texttt{-compact}: Compact list, with one line per machine instead of per slot
\item \texttt{-state -total}: List a summary according to the state of each slot
\item \texttt{-master}: List machines, but just their names (status and slots are not
shown)
\item \texttt{-server}: List attributes of slots, such as memory, disk, load, flops, etc.
\item \texttt{-sort Memory}: Sort slots by Memory, you can try also with other attributes
\item \texttt{-af <attr1> <attr2> <...>}: List specific attributes of slots, using
autoformat (new version, very powerful)
\item \texttt{-format <fmt> <attr>}: List attributes using the specified format (old
version). For instance, next command will show the name of each slot and the
disk space: \texttt{condor\_status -format "\%s\textbackslash{}t " Name -format "\%d KB\textbackslash{}n" Disk}
\item \texttt{<machine>}: Show the status of a specific machine
\item \texttt{<machine> -long}: Show the complete "ClassAd" of a machine (its
specifications). We can use these specifications to add restrictions in the
submit file so we can control which machines we want to use.
\item \texttt{-constraint <constraint>}: Only Show slots that satisfy the
constraint. I.e: \texttt{condor\_status -constraint 'Memory > 1536'} will only show
slots with more than 1.5GB of RAM per slot.
\end{itemize}
\end{itemize}

\subsection{Submitting jobs}
\label{sec:org5faa532}

\begin{itemize}
\item \texttt{condor\_submit <submit\_file>}: Submit jobs to the HTCondor queue according to
the information specified in \texttt{submit\_file}. Visit the \textbf{submit file page} to
see some examples of these files. There are also some FAQs related to the
submit file. Useful options:

\begin{itemize}
\item =-dry-run <dest\(_{\text{file}}\)> =: this option parses the submit file and saves all the
\end{itemize}
related info (name and locations of input and output files after expanding all
variables, value of requirements, etc.) to \texttt{<dest\_file>}, but jobs are '''not'''
submitted. Using this option is highly recommended when debugging or before the
actual submission if you have made some modifications in your submit file and
you are not sure whether they will work.

\begin{itemize}
\item \texttt{'var=value'}: add or modify variable(s) at submission time, without changing
\end{itemize}
the submit file. For instance, if you are using \texttt{queue \$(N)} in your submit
file, then \texttt{condor\_submit <submit\_file> 'N = 10'} will submit 10 jobs. You can
specify several pairs of \texttt{var=value}.

\begin{itemize}
\item \texttt{-append <command>}: add submit commands at submission time, without changing
\end{itemize}
the submit file. You can add more than one command using several times
\texttt{-append}.
\end{itemize}

When submitted, each job is identified by a pair of numbers '''X.Y''', like
345.32. The first number (X) is the '''cluster id''': every submission gets a
different cluster id, that is shared by all jobs belonging to the same
submission. The second number (Y) is the '''process id''': if you submitted N
jobs, then this id will go from 0 for the first job to N-1 for the last one. For
instance, if you submit a file specifying 4 jobs and HTCondor assign id 523 to
that cluster, then the ids of your jobs will be 523.0, 523.1, 523.2 and 523.3
(you can get these ids and more info using \texttt{condor\_q} command).

\begin{mdframed}
\textbf{Caution!}: Before submitting your jobs, always do some simple tests in
order to make sure that both your submit file and program work in a proper way:
if you are going to submit hundreds of jobs and each job takes several hours to
finish, before doing that try with just a few jobs and change the input data in
order to let them finish in minutes. Then check the results to see if everything
went fine before submitting the real jobs. Bear in mind that submitting untested
files and/or jobs may cause a waste of time and resources if they fail, and also
your priority will be lower in following submissions. 
\end{mdframed}



\subsection{Checking and managing submitted jobs}
\label{sec:orga6521f3}

\begin{mdframed}
\textbf{Note:} Each machine manages its own HTCondor queue, so it has information only
about those jobs that were submitted on it (and no information about any other
jobs you may have submitted on other machines). Most of the commands explained
in this section get information asking only the local queue, which means that
you will only see those jobs that you have submitted on that specific
machine. If you submit jobs from different machines, and later you want to
check, hold, release, remove, etc. those jobs, you may need to connect to each
one of those machines where you have submitted jobs from, or, when possible, use
the commands with extra options to communicate with other machines.
\end{mdframed}


\begin{itemize}
\item \texttt{condor\_q}: Show my jobs that have been submitted in this machine. By default
\end{itemize}
you will see the ID of the job(\texttt{clusterID.processID}), the owner, submitting
time, run time, status, priority, size and command. [*STATUS*: \textbf{I}:idle (waiting
for a machine to execute on); \textbf{R}: running; \textbf{H}: on hold (there was an error,
waiting for user's action); \textbf{S}: suspended; \textbf{C}: completed; \textbf{X}: removed; \textbf{<}:
transferring input; and \textbf{>}: transferring output]. Useful options:
\begin{itemize}
\item \texttt{-global}: Show my jobs submitted in any machine, not only the current one
\item \texttt{-nobatch}: Starting in version HTCondor 8.6.0 installed in January 2017,
data is displayed in a compact mode (one line per cluster). With this option
output will be displayed in the old format (one line per process)
\item \texttt{-wide}: Do not truncate long lines. You can also use \texttt{-wide:<n>} to
truncate lines to fit \texttt{n} columns
\item \texttt{-analyze <job\_id>}: Analyse a specific job and show the reason why it is in
its current state (useful for those jobs in Idle status: Condor will show us
how many slots match our restrictions and may give us suggestion)
\item \texttt{-better-analyze <job\_id>}: Analyse a specific job and show the reason why
it is in its current state, giving extended info
\item \texttt{-long <job\_id>}: Show all information related to that job
\item \texttt{-run}: Show your running jobs and related info, like how much time they
have been running, in which machine, etc.
\item \texttt{-currentrun}: Show the consumed time on the current run, the cumulative
time from last executions will not be used (you can combine also with \texttt{-run}
flag to see only the running processes at the moment)
\item \texttt{-hold}: Show only jobs in the "on hold" state and the reason for that. Held
jobs are those that got an error so they could not finish. An action from
the user is expected to solve the problem, and then he should use the
\texttt{condor\_release} command in order to check the job again
\item \texttt{-af <attr1> <attr2> <...>}: List specific attributes of jobs, using
autoformat
\item\relax [-\{-\texttt{''-global -submitter <user>}-\}: Show all jobs from user \texttt{<user>} in all
machines. \textbf{Note}: starting in HTCondor version 8.6.0 installed at IAC in
January 2017, HTCondor will NOT show other users' jobs'' by default, but you
can use some flags like \texttt{-allusers} to change this behaviour -]
\end{itemize}


\begin{itemize}
\item \texttt{*condor\_tail* <job\_id>}: Display on screen the last lines of the \texttt{stdout}
(screen) of a running job on a remote machine. You can use this command to
check whether your job is working fine, you can also visualize errors
(\texttt{stderr}) or output files created by your program (see also
CondorFAQs\#ssh). Useful options:
\begin{itemize}
\item \texttt{-f}: Do not stop displaying the content, it will be displayed until
interrupted with \texttt{Ctrl+C}
\item \texttt{-no-stdout -stderr}: Show the content of \texttt{stderr} instead of \texttt{stdout}
\item \texttt{-no-stdout <output\_file>}: Show the content of an output file (\texttt{output\_file}
has to be listed in the \texttt{transfer\_output\_files} command in the submit file).
\end{itemize}

\item \texttt{*condor\_release* <job\_id>}: Release a specific held job in the queue. Useful options:
\begin{itemize}
\item \texttt{<cluster\_id>}: Instead of giving a \texttt{<job\_id>}, you can specify just the
\texttt{<cluster\_id>} in order to release all held jobs of a specific submission
\item \texttt{-constraint <constraint>}: Release all my held jobs that satisfy the
constraint
\item \texttt{-all}: Release all my held jobs
\item \textbf{Note:} Jobs with ''on hold'' state are those that HTCondor was not able
\end{itemize}
to properly execute, usually due to problems with executable, paths, etc. If
you can solve the problems changing the input files and/or the executable,
then you can use \texttt{condor\_release} command to run again your program since it
will send again all files to the remote machines. If you need to change the
submit file to solve the problems, then \texttt{condor\_release} will NOT work because
it will not evaluate again the submit file. In that case you can use
\texttt{condor\_qedit} (see the HOWTOs.CondorFAQs\#ch\(_{\text{submit}}\)) or cancel all
held jobs and re-submit them again-]

\item \texttt{*condor\_hold* <job\_id>}: Put jobs into the hold state. It could be useful
when you detect that there are some problems with your input data (see
CondorFAQs\#bad\(_{\text{inputs}}\) for more info), you are running out of disk space for
outputs, etc. With this command you can delay the execution of your jobs
holding them, and, after solving the problems, assign them the idle status
using \texttt{condor\_release}, so they will be executed again. Useful options:
\begin{itemize}
\item \texttt{<cluster\_id>}: Instead of giving a \texttt{<job\_id>}, you can specify just the
\texttt{<cluster\_id>} in order to hold all jobs of a specific submission
\item \texttt{-constraint <constraint>}: Hold all jobs that satisfy the constraint
\item \texttt{-all}: Hold all my jobs from the queue
\end{itemize}

\item \texttt{*condor\_rm* <job\_id>}: Remove a specific job from the queue (it will be
removed even if it is running). Jobs are only removed from the current
machine, so if you submitted jobs from different machines, you need to remove
your jobs from each of them. Useful options:
\begin{itemize}
\item \texttt{<cluster\_id>}: Instead of giving a \texttt{<job\_id>}, you can specify just the
\texttt{<cluster\_id>} in order to remove all jobs of a specific submission
\item \texttt{-constraint <constraint>}: Remove all jobs that satisfy the constraint
\item \texttt{-all}: Remove all my jobs from the queue
\item \texttt{-forcex <job\_id>}: It could happen that after removing jobs, they don't
disappear from the queue as expected, but they just change status to
\textbf{X}. That's normal since HTCondor may need to do some extra operations. If
jobs stay with 'X' status a very long time, you can force their elimination
adding \texttt{-forcex} option. For instance: \texttt{condor\_rm -forcex -all}.
\end{itemize}

\item \texttt{*condor\_prio*}: Set the priority of my jobs. A user can only change the
priority of her own jobs, to specify which ones she would like to run first
(the higher the number, the bigger the priority). Priority could be absolute
or relative, use \texttt{man condor\_prio} for further information

\item \texttt{*condor\_ssh\_to\_job <job\_id>*}: Create an ssh session to a running job in a
remote machine. You can use this command to check whether the execution is
going fine, download/upload inputs or outputs, etc. More information about
this command is available in CondorFAQs\#ssh.
\end{itemize}


\subsection{Getting info from logs}
\label{sec:org1730d21}

\begin{itemize}
\item \texttt{*condor\_userlog* <file.log>}: Show and summarize job statistics from the job
log files (those created when using \texttt{log} command in the submit file)

\item \texttt{*condor\_history*}: Show all completed jobs to date (it has to be run in the
\{\sout{same machine}\} where the submission was done). Useful options:
\begin{itemize}
\item \texttt{-userlog <file.log>}: list basic information registered in the log files (use
\texttt{condor\_logview <file.log>} to see information in graphic mode)
\item \texttt{-long XXX.YYY -af LastRemoteHost}: show machine where job XXX.YYY was
executed
\item \texttt{-constraint <constraint>}: Only show jobs that satisfy the constraint. I.e:
\texttt{condor\_history -constraint 'RemoveReason}!=UNDEFINED'=: show your jobs that
were removed before completion
\end{itemize}

\item \texttt{condor\_logview <file.log>}: This is not an original HTCondor command, we have
created this link to the script that allows you to display graphical
information contained in the log of your executions.

\item There is also an online tool to analyze your log files and get more
information: \texttt{HTCondor Log Analyzer} (\url{http://condorlog.cse.nd.edu/}).
\end{itemize}

\subsection{Other commands}
\label{sec:org48a150c}

\begin{itemize}
\item \texttt{condor\_userprio}: Show active HTCondor users' priority. Lower values means
higher priority where 0.5 is the highest. Use \texttt{condor\_userprio -allusers} to
see all users' priority, you can also add flags \texttt{-priority} and/or \texttt{-usage} to
get detailed information
\item \texttt{condor\_qedit}: use this command to modify the attributes of a job placed on
the queue. This may be useful when you need to change some of the parameters
specified in the submit file without re-submitting jobs (see
HOWTOs.CondorFAQs\#ch\(_{\text{submit}}\)).
\item \texttt{condor\_submit\_dag <dag\_file>}: Submit a DAG file, used to describe jobs
with dependencies. Visit the CondorHowTo\#howto\(_{\text{dagman}}\) section for more info
and examples.
\item \texttt{condor\_version}: Print the version of HTCondor.
\item If you want some general information about HTCondor queue, the pool of
machines, where jobs have been executed on, etc., you can try our online stats
about HTCondor: \url{http://carlota:81/condor\_stats/} and \url{http://nectarino/}.
\end{itemize}


\section{Submit files (desc. \& examples)}
\label{sec:org6f85953}

\subsection{Introduction}
\label{sec:org344c8c6}

To execute your application with HTCondor, you have to specify some parameters
like the name of your executable, its arguments, inputs and outputs,
requirements, etc. This information is written in a plain text using \textbf{submit
commands} in a file called ''HTCondor Submit Description File'' or simply
\textbf{submit file}. Once that file is filled with all needed info, you have to submit
it to HTCondor using \texttt{*condor\_submit*} in your terminal, and then it will be
processed and your jobs will be added to the queue in order to be executed.

\textbf{Submit files have considerably changed after the release of versions 8.4.X}
(first version 8.4.0 released in Sept 2015, since Feb 2017 we are using versions
8.6.X). Some operations were not possible or highly painful in previous versions
(like dealing with an undetermined number of files with arbitrary names,
declaring variables and macros and performing operations with them, including
submission commands from other files, adding conditional statements, etc.). To
solve that, many researchers developed external scripts (perl, python, bash,
etc.) to dynamically create description files and submit them, what in most
cases resulted in complex submissions and less efficient executions, not to
mention that usually it was needed a hard work to adapt those scripts when the
application, arguments and/or IO files changed.

With the addition of \href{http://research.cs.wisc.edu/htcondor/manual/v8.6/2\_5Submitting\_Job.html\#SECTION00352000000000000000}{new, powerful and flexible commands} most of those problems
have been solved, so there should be no need of using external scripts and *we
highly recommend you always use a HTCondor submit description file instead of
developing scripts in other languages*. If you did that in the past, please,
consider migrating your old scripts, we will give you support if you find any
problems.

In this section you will find templates and examples of HTCondor Submit
Description Files. Use them as reference to create your own submit files and
contact us if you have any doubt or issue. Topics:

\begin{itemize}
\item Creating a submit file (description and structure of
submit files: comments, variables, commands, etc.)
\item Templates and examples of submit files
\item OLD examples
\item Some more useful commands and info
\end{itemize}


\begin{mdframed}
\textbf{Caution!: Before submitting your real jobs, perform always some simple tests}
 in order to make sure that both your submit file and program will work in a
 proper way: if you are going to submit hundreds of jobs and each job takes
 several hours to finish, before doing that try with just a few jobs and change
 the input data in order to let them finish in minutes. Then check the results
 to see if everything went fine before submitting the real jobs. Also we
 recommend you use \texttt{condor\_submit *-dry-run*} to debug your jobs and make sure
 they will work as expected, see \textbf{useful commands} page). Bear in mind that
 submitting untested files and/or jobs may cause a waste of time and resources
 if they fail, and also your priority will be lower in following submissions.
\end{mdframed}


\subsection{Creating a Submit File}
\label{sec:orge1a0f30}

As many other languages, HTCondor submit files allow the use of comments,
variable, macros, commands, etc. Here we will describe the most common ones, you
can check the \href{https://research.cs.wisc.edu/htcondor/manual}{official documentation} for a complete and detailed
information about submit files and submitting process.

\subsubsection{Comments}
\label{sec:org02b553d}

HTCondor uses symbol \texttt{*\#*} for comments. Everything found after that symbol will
be ignored. Please, do not mix commands and comments in the same line, since it
may produce errors. We recommend you always write commands and comments in
different lines.

\begin{verbatim}
# This is a valid comment
A = 4  # This may produce errors when expanding =A=, do not use comments and 
       #  anything else in the same line!
\end{verbatim}

\subsubsection{Variables and macros}
\label{sec:org2bacc60}

There are many predefined variables and macros in HTCondor that you can use, and
you can define your own ones.

\begin{itemize}
\item To \textbf{define a variable}, just chose a valid name (names are case-insensitive)
and assign a value to it, like \texttt{N = 4}, \texttt{Name = "example"}
\item To \textbf{get the value} of a variable, use next syntax: \texttt{\$(varName)}, both \texttt{\$}
symbol and parentheses \texttt{()} are mandatory.
\item You can do \textbf{basic operations} with variables, like \texttt{B = \$(A) + 1}, etc. (since
version 8.4.0 is not needed to use the old and complex syntax [@\$\$[(\ldots{})]@]
for the operations). To get the expression evaluated, you may need to use
function macros like \texttt{\$INT(B)}, \texttt{\$REAL(B)}, etc.
\item There are several special \textbf{automatic variables} defined by HTCondor that will
help you when creating your submit file. The most useful one is \texttt{*\$(Process)*}
or \texttt{\$(ProcId)}, that will contain the Process ID of each job (if you submit
\texttt{N} jobs, the value of \texttt{\$(Process)} will be \texttt{0} for the first job and \texttt{N-1} in
the last job). This variable is like an \textbf{iteration counter} and you can use it
to specify different inputs, outputs, arguments, \ldots{} for each job. There are
some \textbf{automatic variables}, 
like \texttt{\$(Cluster)} or \texttt{\$(ClusterId)} that stores the ID of each submission,
\texttt{\$(Item)}, \texttt{\$(ItemIndex)}, \texttt{\$(Step)}, \texttt{\$(Row)}, etc. (see \textbf{Example1} for
further information).
\item There are several \textbf{pre-defined Function Macros}. Their syntax is
\texttt{*\$FunctName(varName)*} and they can perform some operations on variable
\texttt{varName} like evaluating expressions and type conversions, selecting a value
from a list according an index, getting random numbers, string operations,
filenames processing, setting environment variables, etc. Before creating your
own macros, check if HTCondor has already a \textbf{pre-defined Function Macro} with
the same purpose.
\end{itemize}

\subsubsection{Submit commands}
\label{sec:orgf0c60a5}

You will need to add several HTCondor submit commands in your script file in
order to specify which executable you want to run and where it is located, its
arguments if any, input files, which result files will be generated, etc. There
is a wide set of HTCondor with almost 200 different \textbf{submit description file
commands} to cover many different scenarios. But in most situations you will
only need to specify a few of them (usually about 10-15). Here we will present
the most common ones (commands are case-insensitive):

\begin{itemize}
\item \textbf{Mandatory commands:}
\begin{itemize}
\item \texttt{*executable*}: specify where your executable is located (you can use an
absolute path, a relative one to the directory where you do the submission
or to another directory specified with \texttt{initialdir}). You should specify
\textbf{only the executable} and not other things like arguments, etc., there are
specific commands for that. HTCondor will automatically copy the executable
file from your machine to any machine where your job will be executed, so
you do not need to worry about that.
\item \texttt{*queue*}: this command will send your job(s) to the queue, so it should be
the last command in your submit file. In previous versions of HTCondor it
was quite limited, only allowing the number of jobs as argument. But since
version 8.4.0, this command is very powerful and flexible, and you can use
it to specify variables, iterations over other commands, files to be
processed, list of arguments, etc. \textbf{see complete syntax and examples}.
\end{itemize}

\item \textbf{Highly recommended commands:}
\begin{itemize}
\item \texttt{*output*}: it will copy the standard output printed on the screen
(\texttt{stdout}) of the remote machines when executing your program to the local
file you specify here. Since all the jobs will use the same name, the
filename should include some variable parts that change depending on the job
to avoid overwritten the same file, like \texttt{\$(Process)} (and also \texttt{\$(Cluster)}
if you do not want that different submissions ruin your output files). Even
if your program does not print any useful results on screen, it is very
recommended you save the screen output to check if there were errors, debug
them if any, etc.
\item \texttt{*error*}: the same as previous command, but for standard error output
(\texttt{stderr}).
\item \texttt{*log*}: it will save a log of your submission that later can be analysed
with HTCondor tools. This is very useful when there is any problem with your
job(s) to find the problem and fix it.  The log should be the same for all
jobs submitted in the same cluster, so you should \textbf{not} use \texttt{\$(Process)} in
the filename (but including \texttt{\$(Cluster)} is recommended).
\item \texttt{universe}: there are several \textbf{runtime environments} in HTCondor called
''universes'', we will mostly use the one named \texttt{vanilla} since it is the
easiest one. This is the universe by default, so if you miss this command,
your jobs will also go to \texttt{vanilla} universe.
\end{itemize}

\item \textbf{Useful commands when working with inputs and outputs (arguments, files,
keyboard, etc.)}:
\begin{itemize}
\item \texttt{*arguments*}: it is used to specify options and flags for your executable
file, like when using it in command line.
\item \texttt{*should\_transfer\_files*}: assign \texttt{YES} to it in order to activate HTCondor
file transfer system (needed when working with files).
\item \texttt{*when\_to\_transfer\_output*}: it will usually have a value of \texttt{ON\_EXIT} to
only copy output files when your job is finished, avoiding the copy of
temporary or incomplete files if your job fails or it is moved to another
machine.
\item \texttt{*transfer\_input\_files*}: it is used to specify where the needed input files
are located. We can use a comma-separated list of files (with absolute or
relative paths, as mentioned in \texttt{executable} command). Local path will be
ignored, and HTCondor will copy all files to the root directory of a virtual
location on the remote machine (your executable will be also copy to the
same place, so input files will be in the same directory). If you specify a
directory in this command, you can choose if you want to copy only the
content of the directory (add a slash "\texttt{*/*}" at the end, for instance
\texttt{myInputDir*/*}) or the directory itself and its content (do not add a
slash).
\item \texttt{*transfer\_output\_files*}: a comma-separated list of result files to be
copied back to our machine. If this command is omitted, HTCondor will
automatically copy all files that have been created or modified on the
remote machine. Sometimes omitting this command is useful, but other times
our program creates many temporary or useless files and we only want to get
the ones we specify with this command.
\item More commands for input/output files:
\begin{itemize}
\item \texttt{transfer\_output\_remaps}: it changes the name of the output files when
copying them to your machine. That is useful when your executable
generates result file(s) with the same name, so changing the filename to
include a variable part (like \texttt{\$(Process)} and maybe also \texttt{\$(Cluster)})
will avoid overwritten them.
\item \texttt{initialdir}: this command is used to specify the base directory for input
and output files, instead of the directory where the submission was
performed from. If this command include a variable part (like
\texttt{\$(Process)}), you can use this command to specify a different base
directory for each job.
\item \texttt{input}: if your program needs some data from keyboard, you can specify a
file or a comma-separated list of files containing it (each end of line in
the file will have the same behaviour as pressing \texttt{Intro} key in the
keyboard, like when using \texttt{stdin} redirection in command line with
\texttt{*<*}). As other similar commands, you can use absolute or relative paths.
\item \texttt{transfer\_executable}: by default its value is \texttt{True}, but if it is set to
\texttt{False}, HTCondor will not copy the executable file to the remote
machine(s). This is useful when the executable is a system command or a
program that is installed in all machines, so it is not needed to copy it.
\end{itemize}
\end{itemize}
\end{itemize}


\begin{itemize}
\item \textbf{Other useful commands:}
\begin{itemize}
\item \texttt{request\_memory}, \texttt{request\_disk}: if your program needs a certain amount of
total RAM memory or free disk space, you can use these commands to force
that your jobs will be only executed on machines with at least the requested
memory/free disk space \textbf{HowTo}
\item \texttt{requirements}: this is a very useful command if your program has any
special needs. With it you can specify that your job can be only executed on
some machines (or some machines cannot run your program) according to a wide
set of parameters (machine name, operative system and version and a large
etc.) \textbf{HowTo}
\item \texttt{rank}: you can specify some values or combination of them (total memory,
free disk space, MIPS, etc.) and HTCondor will choose the best machines for
your jobs according to your specifications, where the higher the value, the
better (this command is used to specify preferences, not requirements)
\textbf{HowTo}
\item \texttt{getenv}: if it is set to \texttt{True}, all your environment variables will be
copied at submission time and they will be available when your program is
executed on remote machines (if you do not use this command or it is set to
\texttt{False}, then your jobs will have no environment variables). This is useful
when running some programs that need a special environment, like python,
etc. \textbf{HowTo}
\item \texttt{nice\_user}: if it is set to \texttt{True}, your jobs will be executed with a fake
user with very low priority, what could be very useful when the queue is
(almost) empty, so you can run your jobs without wasting your real user
priority (you can activate and deactivate this feature when your jobs are
being executed, so you can begin running your jobs as nice user if the queue
is empty and change to normal user when the queue has many other jobs, or
vice versa) \textbf{HowTo}
\item \texttt{concurrency\_limits}: you can limit the maximum number of your jobs that
could be executed at the same time. You should use this command if your
program needs licences and there are a few of them (like \texttt{IDL}, see also
\textbf{CondorAndidlvirtualmachine}) or if for any reason you cannot use the
HTCondor file transfer system and all your jobs access to the same shared
resource (\texttt{/scratch}, \texttt{/net/nas}, etc.), in order to avoid that too many
concurrent access can stress the network \textbf{CondorHowTo\#howto\(_{\text{limit}}\)}
\item \texttt{include}: since HTCondor v8.4.0, it is possible to \textbf{include externally
defined submit commands} using syntax: \texttt{*include :* ''<myfile>''}. You can
even include the output of external scripts that will be executed at
submission time, adding a pipe symbol after the file: \texttt{*include :*
    ''<myscript.sh>'' *|*}
\item More useful commands:
\begin{itemize}
\item \texttt{environment}: this command will allow you to set/unset/change any
environment variable(s) \textbf{CondorHowTo\#howto\(_{\text{env}}\)}
\item \texttt{priority}: if some of your jobs/clusters are more important than others
and you want to execute them first, you can use \texttt{priority} command to
assign them a priority (the higher the value, the higher priority). This
command only have an effect on your own jobs, and it is not related to
users priority \textbf{CondorHowTo\#howto\(_{\text{priority}}\)}.
\item \texttt{job\_machine\_attrs}, \texttt{job\_machine\_attrs\_history\_length}: use these
commands to reduce the effects of ''black holes'' in HTCondor, what causes
that many of your jobs could fail in a short time
\textbf{CondorHowTo\#howto\(_{\text{failing}}\)}
\item \texttt{noop\_job}: you specify a condition and those jobs that evaluate it to
true will not be executed. This is useful when some of your jobs failed
and you want to repeat only the failing jobs, not all of them
\textbf{CondorHowTo\#howto\(_{\text{failing}}\)}
\item \texttt{+PreCmd}, \texttt{+PreArguments}, \texttt{+PostCmd}, \texttt{+PostArguments}: These commands
allow you to run some scripts before and/or after your executable. That is
useful to prepare, convert, decompress, etc. your inputs and outputs if
needed, or debug your executions \textbf{CondorHowTo\#howto\(_{\text{prepostcmd}}\)}
\item \texttt{notify\_user}, \texttt{notification}: use these commands if you want to receive a
notification (an email) when your jobs begin, fail and/or finish
\textbf{CondorHowTo\#howto\_\(_{\text{notify}}\)}
\item \texttt{if} \ldots{} \texttt{elif} \ldots{} \texttt{else} \ldots{}  \texttt{endif}: since HTCondor version 8.4.0, a
\textbf{limited conditional semantic} is available. You can use it to specify
different commands or options depending on the defined/undefined
variables, HTCondor version, etc.
\item \texttt{on\_exit\_hold}, \texttt{on\_exit\_remove}, \texttt{periodic\_hold}, \texttt{periodic\_remove},
\texttt{periodic\_release}, etc.: you can modify the default behaviour of your
jobs and the associated status. These commands can be used in a wide set
of circumstances. For instance, you can force that jobs that are running
for more than X minutes or hours will be deleted or get a ''on hold''
status (with this you can prevent that failing jobs will be running
forever, since they will be stopped or deleted if they run for a much
longer while than expected) or the opposite, hold those jobs that finish
in an abnormal short time to check later what happened. Or you can also
periodically release your held jobs, to run them on other machines if for
any reason your jobs work fine on some machines, but fail on others
\textbf{CondorHowTo\#howto\(_{\text{failing}}\)}
\item \texttt{deferrall\_time}, \texttt{deferral\_window}, \texttt{deferral\_prep\_time}: you can force
your jobs begin at a given date and time. That is useful when the input
data is not ready when submitting and your jobs have to wait till a
certain time \textbf{CondorHowTo\#howto\(_{\text{runintime}}\)}
\end{itemize}
\end{itemize}
\end{itemize}



\subsection{Templates and examples}
\label{sec:org2760f33}

Here you can find basic templates of submit files, you can use them as starting
point and then do the customizations needed for your executions. Check the
examples in following sections for details and explanations.

\subsubsection{Common Template}
\label{sec:org560dfb2}

\begin{verbatim}
######################################################
# HTCondor Submit Description File. COMMON TEMPLATE   
# Next commands should be added to all your submit files   
######################################################
if !defined FNAME
  FNAME = condor_exec
endif
ID      = $(Cluster).$(Process)

output  = $(FNAME).$(ID).out
error   = $(FNAME).$(ID).err
log     = $(FNAME).$(Cluster).log

universe                = vanilla
should_transfer_files   = YES
when_to_transfer_output = ON_EXIT
\end{verbatim}

\begin{itemize}
\item \textbf{Explanation:}

Let's analyse the common template: 
\begin{itemize}
\item First block:
\begin{itemize}
\item Here we will define some variables that will be used later. The first of
them is \texttt{FNAME} and first we ask with the \texttt{if defined} condition whether
that variable is not already defined (if so, we will use the previous
value). This variable will contain the base name for the files where
HTCondor will save the information displayed on the screen (\texttt{stdout} and
\texttt{stderr}) and the log file. It is interesting to give a common name to
those files generated by HTCondor so later we can identify and manage them
together. Since all jobs will use the name specified there, we have to
include a variable part that has to be different in each job, in order to
avoid overwriting the files. We recommend you use a combination of
\texttt{\$(Process)} (it contains the process ID that is different for each job)
and \texttt{\$(Cluster)} (it contains the cluster ID that is different for each
submission), as we have done when defining \texttt{\$(ID)}. In this way, different
jobs and different submission will use different filenames and none of
them will be overwritten.
\end{itemize}
\item Second block:
\begin{itemize}
\item With \texttt{output} command we force HTCondor to write in the specified file all
the screen output (\texttt{stdout}) generated by each job. We have used the
variables \texttt{\$(FNAME)} and \texttt{\$(ID)} defined above.
\item With \texttt{error} command we manage \texttt{stderr} in the same way we did with
\texttt{output}.
\item Then we have also specified a HTCondor log file with \texttt{log} command. You
should not use \texttt{\$(Process)} in the filename of the log since all jobs
should share the same log.
\end{itemize}
\item Third block:
\begin{itemize}
\item \texttt{universe}: there are \textbf{runtime environments}
in HTCondor called ''universes'', we will mostly use the one named
\texttt{vanilla} since it is the easiest one. This is the universe by default, so
if you miss this command, your jobs will go also to \texttt{vanilla} universe.
\item \texttt{should\_transfer\_files=YES} and \texttt{when\_to\_transfer\_output=ON\_EXIT} commands
are used to specify that input files have to be copied to the remote
machines and output files must be copied back to your machine only when
our program is finished. Although these commands are only needed when
working with files, we recommend you always use them unless you are
totally sure you can omit them.
\end{itemize}
\end{itemize}
\end{itemize}


\subsubsection{Examples when working with input/output files and arguments}
\label{sec:org3e713b5}

Most times you will want to run applications that deal with input and/or output
files. Commonly, the input files will be located on your local machine, but
since your application will be executed on other machine(s), it will be needed
to copy your input files there, and then copy the result files back to your
computer once your program is done. HTCondor have some commands to automatically
do both operations in an easy way, so you do not need to worry about the file
transfers: you just need to specify where your files are and HTCondor will copy
them.

\textbf{Note:} All these examples will begin defining a specific variable \texttt{FNAME} that
contains the base name of the files that HTCondor will generate to save the
\texttt{stdout}, \texttt{stderr} and log. Next, the common template explained above with be
included using command \texttt{include} (we assume that the common template filename is
\texttt{condor\_common.tmpl}).

\paragraph{\textbf{Example A} (arbitrary filenames)}
\label{sec:orgaea4694}

Process all input files with extension \texttt{.in} in a given directory with next
program: \texttt{./myprogram -i inputFile -o outputFile}

\begin{verbatim}
# Including Common Template
FNAME = exampleA
include : /path/to/condor_common.tmpl

transfer_input_files    = $(mydata)
transfer_output_files   = $Fn(mydata).out

executable    = myprogram
arguments     = "-i $Fnx(mydata) -o $Fn(mydata).out"

queue *mydata* matching files /path/to/inputs/*.in
\end{verbatim}

\begin{itemize}
\item \textbf{Explanation:} 
We use \texttt{transfer\_input\_files} to specify where the needed input files are
located. We can use a comma-separated list of files, but since we do not know
the name of the files, we will use the variable \texttt{mydata} to specify them. That
variable is defined in the last line, with the \texttt{queue} command: there, we choose
to process all files in \texttt{/path/to/inputs} with extension \texttt{.in}. When submitting,
HTCondor will check that directory and it will automatically create a job for
each \texttt{.in} file found there, assigning the complete filename to \texttt{mydata} (in
this way, each job will work with a different file). We have used the \texttt{matching
  files} to specify that we only want files matching the condition, but we can
also select only directories (\texttt{matching dirs}) or both of them (just
\texttt{matching}).

With \texttt{transfer\_output\_files} we set the name of the output files, that is the
same as the input file with \texttt{.out} extension. To remove the old extension we use
the \texttt{\$Fn} macro, that is one of the \textbf{new Function Macros}
available since version 8.4.0, used to operate the filename and extract the
path, name without extension, extension, etc.

Then we use \texttt{executable} to specify the name of the executable (it can be a
system command, your own application, a script, etc). We can use a absolute path
or a relative one to the directory where we will perform the submission. This
executable will be copied to all remote machines automatically. Finally,
\texttt{arguments} is used to specify the options for the program. We have to employ
again \texttt{Fpdnxq} macros, first \texttt{Fnx} to remove the original path (file we be
copied to the root of a virtual location where HTCondor will run the executable
on the remote machine) and then \texttt{Fn} to remove path and change extension of the
output file.
\end{itemize}


\paragraph{\textbf{Example B} (based on ProcessID, old system before HTCondor v8.4.0)}
\label{sec:org3d8d020}

Process 50 input files with consecutive names (from data0.in to data49.out)
using the same program as previous example

\begin{verbatim}
# Including Common Template
FNAME = example2
include : /path/to/condor_common.tmpl

transfer_input_files    = /path/to/inputs/data$(Process).in
transfer_output_files   = data$(Process).out

N             = 50
executable    = myprogram
arguments     = "-i data$(Process).in -o data$(Process).out"

queue $(N)
\end{verbatim}

\begin{itemize}
\item \textbf{Explanation:}
\texttt{transfer\_input\_files} command allows a comma-separated list of files or
directories that will be copied to the remote machine. Local path will be
ignored, and HTCondor will copy all files to the root directory of a virtual
location on the remote machine (your executable will be also copy to the same
place, so input files will be in the same directory). If you specify a directory
in this command, you can choose if you want to copy only the content of the
directory (add a slash "\texttt{*/*}" at the end, for instance \texttt{myInputDir*/*}) or the
directory itself and its content (do not add a slash). In this case, each job
will process a different input file, and since they have a consecutive name
beginning from \texttt{0}, we will use HTCondor macro \texttt{\$(Process)} to build the proper
name, since the process ID will be \texttt{0} from the first job to \texttt{N-1} for the last
job.

With \texttt{transfer\_output\_files} we specify a comma-separated list of result files
to be copied back to our machine. In this case, we specify just one file, with
the same name as the input file, but with \texttt{.out} extension.

Then we define the variable \texttt{N} to specify the number of jobs to be
executed. Our program is set using \texttt{executable} command and with \texttt{arguments}
command we specify all the needed options (here the name of the input and output
file with the corresponding flags).

At the end, we send all jobs to the queue with \texttt{queue} command, specifying how
many jobs we want (we have used the variable \texttt{N}).
\end{itemize}


\paragraph{\textbf{Example C} (lists of files and arguments written in submit file)}
\label{sec:orgf129954}

Process all arbitrary files and arguments of a given list. Executable is
 \texttt{myprogram} and it needs an input file with extension \texttt{.dat} and some
 arguments. Results will be printed on screen (\texttt{stdout}). 

\begin{verbatim}
# Including Common Template
FNAME = exampleC
include : /path/to/condor_common.tmpl

executable    = myprogram

queue transfer_input_files,arguments *from* (
  xray434.dat, -d 345 -p f034
  sunf37.dat,  -d 2   -p f302
  light67.dat, -d 62  -p f473
) 
\end{verbatim}

\begin{itemize}
\item \textbf{Explanation:}
\end{itemize}

We will use the flexibility of \texttt{queue} command to assign values of a list to
several commands. We must specify which files must be transferred and which
arguments are needed by each file. We specify then \texttt{transfer\_input\_files} and
\texttt{arguments} commands using the \texttt{from} option, and then we add a list of pairs
''file,argument''.

At submission time, HTCondor will iterate over the list and expand the
assignations. For instance, our jobs will have next values:

\begin{itemize}
\item \texttt{transfer\_input\_files = xray434.dat, arguments = -d 345 -p f034-}
\item \texttt{transfer\_input\_files = sunf37.dat, arguments = -d 2   -p f302-}
\item \texttt{transfer\_input\_files = light67.dat, arguments = -d 62  -p f473-}
\end{itemize}

When using this format you can specify as many commands separated by commas as
needed between \texttt{queue} and \texttt{from}, but check that each line in the list has the
right number of elements also separated by commas.

Writing the list of items in the submit file can be a little bit tedious, but it
may be easily done in an external file using scripts. Then you can directly
specify the file. For instance, suppose you have all items in a file named
\texttt{data.lst}, then you can use next \texttt{queue} command: 
\texttt{queue transfer\_input\_files,arguments from /path/to/data.lst}


\paragraph{Example D (lists of files and arguments in external file)}
\label{sec:org4b36e4f}

Process arbitrary files and arguments stored in file \texttt{data.lst} (process only
 lines from 28 to 43, both inclusive, with step 5). Executable is \texttt{myprogram} as
 in previous example, but this time it saves the result in a file named
 \texttt{output.out}. 

\begin{verbatim}
# Including Common Template
FNAME = exampleD
include : /path/to/condor_common.tmpl

transfer_output_files  = output.out
line                   = $(Row)+1
transfer_output_remaps = "output.out=output$INT(line).out"

executable    = myprogram

queue transfer_input_files,arguments *from* [27:43:5] data.lst
\end{verbatim}

\begin{itemize}
\item \textbf{Explanation:}
\end{itemize}

This example is similar to the previous one, but this time the list of input
files and arguments is written in a file with the following format:

\begin{verbatim}
[input_file1,args1]
[input_file2,args2]
[input_file3,args3]
...
\end{verbatim}

To illustrate the \textbf{slice} feature, we have been asked to process only items
(lines) from 28 to 43 with step 5 (28, 33, 38 and 43), this could be useful when
we want to run only certain experiments. The syntax for the slices is very easy,
the same as Python: \texttt{[init:end:step]}. Since the first index is 0, but we do not
use line 0 but line 1, the \texttt{init} should be 27. Then the \texttt{end} is 43 (it should
be 42, but we need to add 1 because the upper limit is included according to our
example). So we specify the slice using \texttt{[27:43:5]} in the \texttt{queue} command,
between the \texttt{from} clause and the file.

We have to be careful with the results. Our program writes them in a file named
\texttt{output.out}. We cannot get all files with the same name because they will be
overwritten, so we need to use \texttt{transfer\_output\_remaps} to change names when
copying from remote machines to our. We can add the \texttt{\$(Process)} variable to the
new name, so all of them will be different, but then it could be a little bit
complicated to identify each result. Instead, we will use another of the
\textbf{automatic variables}, called \texttt{\$(Row)}. It stores the number of the row in the
list that is being processed, that is, almost the number of the line: since
\texttt{\$(Row)} begins in 0, we need to add 1 to get the line number. We do that in
variable \texttt{\$(line)}. Then, HTCondor will process rows 27, 32, 37 and 42, and our
output files will be \texttt{output28.out}, \texttt{output33.out}, \texttt{output38.out} and
\texttt{output43.out}.

\paragraph{Example E (\texttt{stdin}, \texttt{initialdir} external scripts and lists)}
\label{sec:orgc345e80}

Our program \texttt{myprogram} works with \texttt{stdin} (keyboard is used to specify input
data). We have written that input data in 4 files (\texttt{dataFeH.in}, \texttt{dataOFe.in},
\texttt{dataOH.in} and \texttt{dataHe.in}) and there is a set of 3 different experiments in
directories (\texttt{dir000}, \texttt{dir001} and \texttt{dir002}). Output files will be generated
with the same name as inputs and extension \texttt{.out} (use \texttt{-o} argument) and they
must be located in the same directory where the respective input file
is. Program also needs all \texttt{*.tbl} files located in \texttt{/path/to/tables}.

\begin{verbatim}
# Including Common Template
FNAME = exampleE
include : /path/to/condor_common.tmpl

N            = 3
input        = data$(met).in
initialdir   = /path/to/dir$INT(Step,%03d)
include      : input_tables.sh |
transfer_output_files = data$(met).out

executable   = myprogram
arguments    = "-o data$(met).out"

queue $(N) *met* *in* FeH, OFe, OH, He
\end{verbatim}

\begin{itemize}
\item \textbf{Explanation:}
\end{itemize}

The key of this example is the \texttt{queue} command in last line. We are using the
clause \texttt{*in*} to specify a list of values. HTCondor will create a job for each
element in the list and the current value will be assigned to the variable \texttt{met}
that we have declared (this variable is optional, you can omit it and use the
automatic variable \texttt{Item}). We have 3 set of experiments, so we need to go over
the list 3 times, that is why we have defined \texttt{N = 3} and we are using \texttt{\$(N)} in
the \texttt{queue} command. So, at the end, HTCondor will execute 12 jobs (3 runs * 4
elements in the list): we will use automatic variable \texttt{\$(Step)} to get the
number of the present run (0, 1 or 2) and \texttt{\$(met)} (or \texttt{\$(Item)} if we omit the
variable) to get the value of the current element in the list.

\texttt{input} command is used to specify a file that will be used as \texttt{stdin}, using
variable \texttt{\$(met)} to get the proper filename. That variable will be also used
when building the name of the output files (\texttt{transfer\_output\_files} command) and
the arguments (\texttt{arguments} command).

We use \texttt{initialdir} to specify a base directory that changes according to the
current job, using the automatic variable \texttt{\$(Step)}. HTCondor will use this
directory as base for the relative paths, so it will affect the input and output
files, including the \texttt{stdout}, \texttt{stderr} and log files created by HTCondor (see
common template). We use \texttt{\$INT(Step,\%03d)} to get a 3-digit number (000, 001
and 002) to build the proper path for each experiment, then HTCondor will go to
the right directory to get the input files and to place later the respective
output files there.

Last thing we have to solve is the problem with the required input files (all
\texttt{*.tbl} files located in \texttt{/path/to/tables}). HTCondor does not allow globbing in
\texttt{transfer\_input\_files}, but instead we can use the new feature of \textbf{including
external files} with \texttt{include} command. This command not only include other
files, but also invoke them if the command finish with a \textbf{bar} \texttt{*|*}. Then we
can easily make a external script to get the list of needed files with linux
command \texttt{ls} and options \texttt{-m} (commas are used to separate elements) and \texttt{-w}
(used to specify the wide of the screen before adding a new line. Since we need
all elements in the same line, we should specify a number big enough). In this
case, our external script \texttt{input\_tables.sh} is the following one:

\begin{verbatim}
#!/bin/bash
echo "transfer_input_files = `ls -w 400 -m /path/to/tables/*.tbl`"
\end{verbatim}

\paragraph{Example F (loops)}
\label{sec:orga3a6a0b}

Execute each iteration of a 3-level nested loop using: \texttt{myprogram -dim1 i -dim2
j -dim3 k = with the following ranges: =i:[0,20)}, \texttt{j:[0,15)} and
\texttt{k:[0,35)}. Output will be written on screen, no input files are needed.

\begin{verbatim}
# Including Common Template
FNAME = exampleF
include : /path/to/condor_common.tmpl
 
MAX_I = 20
MAX_J = 15
MAX_K = 35

N = $(MAX_I) * $(MAX_J) * $(MAX_K)

I = ( $(Process) / ($(MAX_K)  * $(MAX_J)))
J = (($(Process) /  $(MAX_K)) % $(MAX_J))
K = ( $(Process) %  $(MAX_K))

executable = myprogram
arguments  = "-dim1 $INT(I) -dim2 $INT(J) -dim3 $INT(K)"

queue $(N) 
\end{verbatim}

\begin{itemize}
\item \textbf{Explanation:}
\end{itemize}

In this example we only need to ''simulate'' a 3 nested loops from a 1-level
loop (we will use \texttt{\$(Process)} as main loop counter). The 3-level loop will be
the next ones, and HTCondor will create a job for each iteration:

\begin{verbatim}
for (i = 0; i < MAX_I; i++)
  for (j = 0; j < MAX_J; j++)
    for (k = 0; k < MAX_K; k++)
      ./myprogram  -dim1 i -dim2 j -dim3 k
\end{verbatim}

Then we only need to set the limits (\texttt{MAX\_I}, \texttt{MAX\_J}, \texttt{MAX\_K}), the number of
total iterations (\texttt{N = \$(MAX\_I) * \$(MAX\_J) * \$(MAX\_K)}) and use some maths to
get the values of \texttt{I}, \texttt{J} and \texttt{K} according the value of \texttt{\$(Process)}, as we
have done above (just a few multiplications, integer divisions and remeinders
are needed). 

For a 2-level loop, you can use next code:

\begin{verbatim}
I = ($(Process) / $(MAX_J))
J = ($(Process) % $(MAX_J))
\end{verbatim}

\paragraph{Example G}
\label{sec:org122f673}

This example shows the use of several useful commands for specific
conditions. It is also a summary of the \textbf{CondorHowTo}, you can find
further details and explanation about the submit commands there. 

\begin{itemize}
\item Execute \texttt{myprogram} with argument "=-run =" from 0 to 99 by default.
\item \textbf{BLOCK A}: Execute only on machines with at least 4GB RAM and 2GB of free
disk space. The higher memory and the faster calculations, the better (we can
use KFLOPS to choose the faster machines doing floating point operations, but
since memory and kflops have different units, we need to weight them, for
instance, multiplying memory by 200).
\item \textbf{BLOCK B}: Execute only on machines with Linux Fedora21 or upper and avoid
executing on \texttt{cata}, \texttt{miel} and those with hostname beginning with letter \texttt{m}
or \texttt{d}.
\item \textbf{BLOCK C}: It is needed to run script \texttt{processData.sh} before (argument:
\texttt{-decompress}) and after (argument: \texttt{-compress}) to prepare our data.
\item \textbf{BLOCK D}: Our executable needs the environment variables and variable \texttt{OUT}
has to be set with the argument.
\item \textbf{BLOCK E}: Avoid \textbf{black holes} (when your jobs do not execute correctly on
a machine, and since they finish quickly, that machine is getting most of the
jobs).
\item \textbf{BLOCK F}: Get a notification via email when errors in the job. If the job
finishes before 5 minutes or takes more than 2 hours to be done, there was a
problem: hold it to check later what happened.
\item \textbf{BLOCK G}: Our program needs licenses, so we cannot run more than 20 jobs at
the same time. Execute jobs as \textbf{nice user} to save priority since there are
no other jobs running at this moment.
\end{itemize}

\begin{verbatim}
# Including Common Template
FNAME = exampleG
include : /path/to/condor_common.tmpl

if !defined N
  N = 100
endif

#BLOCK A
requested_memory = 4 GB
requested_disk   = 2 GB
rank             = (200 * Memory) + KFLOPS

#BLOCK B
letter           = substr(toLower(Target.Machine),0,1)
requirements     = (UtsnameSysname == "Linux") 
        && (OpSysName == "Fedora") && (OpSysMajorVer >= 21) 
        && !stringListMember(UtsnameNodename, "cata,miel")
        && !stringListMember($(letter), "m,d")


#BLOCK C
transfer_input_data = processData.sh
+PreCmd             = "processData.sh"
+PreArguments       = "-decompress"
+PostCmd            = "processData.sh"
+PostArguments      = "-compress"

#BLOCK D
getenv              = True
environment         = "OUT$(Process)"

#BLOCK E
job_machine_attrs = Machine  
job_machine_attrs_history_length = 5           
requirements = $(requirements) 
      && (target.machine =!= MachineAttrMachine1)  
      && (target.machine =!= MachineAttrMachine2)

#BLOCK F
notify_user       = myuser@iac.es
notification      = Error

on_exit_hold = ((CurrentTime - JobStartDate) < (5 * 60)
periodic_hold = ((JobStatus == 2) 
         && (time() - EnteredCurrentStatus) >  (2  $(HOUR)))

#BLOCK G
concurrency_limits = myuser$(Cluster):50
nice_user = True

executable = myprogram
arguments  = "-run $(Process)"

queue $(N) 
\end{verbatim}


\begin{mdframed}
\textbf{IMPORTANT}: Although your program could use shared locations
(\texttt{/net/XXXX/scratch}, \texttt{/net/nasX}, etc.) to read/write files from any machine so
there is no need to copy files, we highly recommend \textbf{you always use the HTCondor
file transfer system} to avoid network congestion since files will be accessed
locally on the remote machines. Bear in mind that HTCondor can execute hundreds
of your jobs at the same time, and if all of them concurrently access to the
same shared location, network could experience a huge stress and fail. If for
any reason you cannot copy files and you have to use shared locations -you are
using huge files of several GB, etc.-, then contact us before submitting to
adapt your jobs in order to avoid network congestion. 
\end{mdframed}
\end{document}
